<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">All About SSLs</h1>
                </header>
            
            <article>
                
<p>In this chapter, we will cover the following recipes:</p>
<ul>
<li>Basic SSL certificates</li>
<li>Enabling HTTP/2 on NGINX</li>
<li>Configuring HSTS in NGINX</li>
<li>Easy SSL certificates with Let's Encrypt</li>
<li>Making NGINX PCI-DSS compliant</li>
<li>OCSP stapling with NGINX</li>
<li>Achieving full A+ Qualys rating</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction</h1>
                </header>
            
            <article>
                
<p>The <strong>Secure Sockets Layer</strong> (<strong>SSL</strong>) standard has been traditionally used to encrypt web traffic that needs to be protected, such as financial transactions (for example, credit card numbers) and sensitive information. Recently, however, we have seen an ever-increasing trend of encrypting whole sites and all related services. The use of SSLs ensures that the whole transport of information is encrypted and therefore can't be intercepted, especially, now that Google has given a small <strong>Search Engine Optimization</strong> (<strong>SEO</strong>) ranking boost to sites that have an SSL enabled by default. While the boost is small, Google's focus on encouraging the safe transmission of data means that this will likely increase in the future.</p>
<p>Thankfully, NGINX's support for the latest SSL standards and the latest transport standards, such as HTTP/2 (covered in detail later), means that it's getting easier to efficiently deploy SSL-encrypted sites.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Basic SSL certificates</h1>
                </header>
            
            <article>
                
<p>Before we get started, let's just have a refresher on how the browser-to-server encryption works and what we need to consider. This is a very brief overview specific to a basic web server scenario, so the process can vary for different scenarios:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="466" src="assets/7b3f1da1-1d38-4070-bc38-5988fe4ce1da.png" width="391"/></div>
<p>Following are the steps that happen in a web server scenario:</p>
<ol>
<li>First, the browser communicates with the web server and requests the start of an SSL handshake. This is also where the browser can let the server know what cipher (encryption) algorithms it will allow.</li>
<li>Next, the server responds to the browser. At this stage, the server will confirm which cipher (based on the list provided by the browser) will be used. The server will also send a copy of the public certificate to the client. The browser will then communicate with the <strong>Certificate Authority</strong> (<strong>CA</strong>) to authenticate the certificate.</li>
<li>Next, the key exchange is kicked off. A session key is established. This key is based on the public key on the client side and decoded by the private key on the server side.</li>
</ol>
<div class="packt_tip">It's important to note that the private key is <em>never</em> transmitted; it always remains on the server.</div>
<ol start="4">
<li>Once the session key is complete, the client will send a final confirmation to complete the handshake and await a reciprocal finalization from the server side.</li>
<li>Finally, we have a secure tunnel in which encrypted data can now be transmitted. This is where the actual web content can now be sent.</li>
</ol>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>To install an SSL, there are three components we need to start with. The first is <strong>Certificate Signing Request</strong> (<strong>CSR</strong>). This defines the information which will be contained within the certificate and includes things such as the organization name and domain name. The CSR is then sent to a CA or used to generate a self-signed certificate.</p>
<p>To make it easy for this recipe, we'll use a self-signed certificate. We can easily generate the CSR and then the private key and public certificate with one command. For example, here's how to generate a CSR with a 2048 bit key and 600 day expiry:</p>
<pre><strong>openssl req -x509 -new -newkey rsa:2048 -nodes -keyout private.key -out public.pem -days 600</strong>  </pre>
<p>This example will ask a series of questions for the CSR and then automatically generate the private key (<kbd>private.key</kbd>) and the public certificate (<kbd>public.pem</kbd>). Consider the following example:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="219" src="assets/f21e29d3-e0d3-427e-aa16-4c72f89e2296.png" width="454"/></div>
<div class="packt_tip">Self-signed certificates aren't validated by browsers and are not intended for production. They should be used for internal and testing purposes only.</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>Now that we have a certificate and private key, we can update our NGINX configuration to serve SSL-based sites. Here's our NGINX <kbd>server</kbd> directive block:</p>
<pre>server { 
    listen              443 ssl; 
    server_name         ssl.nginxcookbook.com; 
    ssl_certificate     /etc/ssl/public.pem; 
    ssl_certificate_key /etc/ssl/private.key; 
    ssl_protocols       TLSv1 TLSv1.1 TLSv1.2; 
    ssl_ciphers         HIGH:!aNULL:!MD5; 
 
    access_log  /var/log/nginx/ssl-access.log  combined; 
 
    location  /favicon.ico { access_log off; log_not_found off; } 
    root  /var/www; 
} </pre>
<p>If you have a basic <kbd>index.html</kbd> or similar in <kbd>/var/www</kbd>, you should see something like the following:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="129" src="assets/a10ae483-5973-4c0c-96ac-cd4b0be50bb8.png" width="394"/></div>
<p>The error message will vary between browsers, but they're all simply letting you know that the certificate presented couldn't be validated and therefore can't be intrinsically trusted. For testing, add an exception here; you should see the SSL site served by NGINX:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="178" src="assets/12d166db-1c29-4a00-a046-ae67df365d1e.png" width="340"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>Here's what the directives do:</p>
<ul>
<li><kbd>listen 443 ssl</kbd>: Firstly, we tell NGINX to listen on port <kbd>443</kbd> (the HTTPS standard) using the SSL protocol. Previously, we'd simply told NGINX to listen on port <kbd>80</kbd>, and it used HTTP by default.</li>
<li><kbd>ssl_certificate</kbd>: This is the location of the public key, which needs to be in the PEM format. If your CA also provided intermediate certificates, then they also need to be in this file.</li>
<li><kbd>ssl_certificate_key</kbd>: This is the location of the private key, and it also needs to be in PEM format. This key needs to be kept safe to ensure the integrity of your certificate<span class="_Tgc">â€”</span>it should only reside on the server.</li>
<li><kbd>ssl_protocols</kbd>: Here, we specify what variants of the SSL protocols we want to make available. The easiest default is to support <strong>Transport Layer Security</strong> (<strong>TLS</strong>), which is the successor to the older SSL protocol. As both SSLv2 and SSLv3 have had significant flaws exposed in recent years, they should only be enabled as a last resort.</li>
<li><kbd>ssl_ciphers</kbd>: The ciphers dictate the type of encryption used and at what level. The default of <kbd>HIGH:!aNULL:!MD5</kbd> means that we use only high grade (128-bit and higher), authenticated (the exclamation means NOT) encryption and not MD5 hashing. The defaults are secure and shouldn't be changed without a good reason.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Enabling HTTP/2 on NGINX</h1>
                </header>
            
            <article>
                
<p>The now ratified HTTP/2 standard is based on SPDY, an experimental protocol that Google developed internally. As shown in the diagram in the previous recipe, establishing an HTTPS connection can be quite time consuming. With HTTP/1.1, each connection to the web server must follow this process and wait for the handshake to complete.</p>
<p>In HTTP/2, this handshake time is reduced, but more importantly the requests are multiplexed over a single TCP connection. This means that the handshake only has to occur once, significantly reducing the latency of a site for the end user. In fact, it means that an HTTP/2-based site can actually be quicker than a standard HTTP-based one.</p>
<p>There are a number of other benefits that HTTP/2 also provides, such as header compression, a new binary protocol, and a server-based push. All of these further increase the efficiency of HTTP/2, yet it also remains backwards compatible with HTTP/1.1:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="201" src="assets/ebe0b455-8082-40cd-a29a-eec2725f6e0d.png" width="662"/></div>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign">HTTP/2 support</div>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign">Source: caniuse.com (April 2017)</div>
<p>All modern browsers (as shown in the preceding figure) support HTTP/2 natively, so it's ready to deploy in production. NGINX officially supported HTTP/2 starting with version 1.9.5.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>Based on our previous example, we only need to make one key change. Instead of just specifying <kbd>ssl</kbd> as the listening protocol, we add <kbd>http2</kbd>:</p>
<pre>server { 
    listen              443 ssl http2; 
    server_name         http2.nginxcookbook.com; 
    ssl_certificate     /etc/ssl/public.pem; 
    ssl_certificate_key /etc/ssl/private.key; 
    ssl_protocols       TLSv1 TLSv1.1 TLSv1.2; 
    ssl_ciphers         HIGH:!aNULL:!MD5; 
 
    access_log  /var/log/nginx/ssl-access.log  combined; 
 
    location  /favicon.ico { access_log off; log_not_found off; } 
    root  /var/www; 
} </pre>
<div class="packt_tip">No changes to protocols or ciphers are necessary. To verify that HTTP/2 is working, you can use Chrome <strong>Developer Tools</strong> (<strong>DevTools</strong>) to show the protocol, or an external tool, such as the one KeyCDN provides:</div>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" src="assets/8095424f-dc1d-43eb-ab9c-2af5fe1325fb.png"/></div>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign">Source: https://tools.keycdn.com/http2-test</div>
<p>While a simple page won't show the performance difference, with the average page demand of around 50â€“70 requests we should see about 20 percent improvement. For more complex sites (for example, e-commerce sites) where there are more than 200 requests, the difference is even more dramatic.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>NGINX HTTP/2 white paper: <a href="https://assets.wp.nginx.com/wp-content/uploads/2015/09/NGINX_HTTP2_White_Paper_v4.pdf" target="_blank"><span class="URLPACKT">https://assets.wp.nginx.com/wp-content/uploads/2015/09/NGINX_HTTP2_White_Paper_v4.pdf</span></a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Configuring HSTS in NGINX</h1>
                </header>
            
            <article>
                
<p><strong>HTTP Strict Transport Security</strong> (<strong>HSTS</strong>) is an enhancement to the HTTP protocol that is designed to enforce strict security standards to help protect your site and users. HSTS does a number of things. Firstly, it ensures that all requests must be made via HTTPS. This ensures that data isn't accidentally sent via HTTP and, therefore, left unencrypted.</p>
<p>Secondly, it ensures that only a valid certificate can be accepted. In our previous examples, we used a self-signed certificate and the browser allowed us to bypass the security check. With HSTS enabled, this is no longer possible. This means that attempts to emulate your site or man-in-the-middle attacks where a different certificate is used are now no longer possible.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>To enable the use of HSTS, we add an additional header to our <kbd>server</kbd> directive:</p>
<pre>server { 
    listen              443 ssl http2; 
    server_name         http2.nginxcookbook.com; 
    ssl_certificate     /etc/ssl/public.pem; 
    ssl_certificate_key /etc/ssl/private.key; 
    ssl_protocols       TLSv1 TLSv1.1 TLSv1.2; 
    ssl_ciphers         HIGH:!aNULL:!MD5; 
 
    add_header Strict-Transport-Security "max-age=31536000; 
 
    access_log  /var/log/nginx/ssl-access.log  combined; 
 
    location  /favicon.ico { access_log off; log_not_found off; } 
    root  /var/www; 
} </pre>
<p>This header specifies the <kbd>max-age</kbd>, which in our case we have set to <kbd>31536000</kbd> seconds (which is 365 days). This means that the browser will cache the HSTS settings for an entire year and ensure that all requests for the next 365 days will be HTTPS only for your domain. It will also only accept the official certificate.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>There's only a small point to remember: If you specify adding a header elsewhere (for example, a <kbd>location</kbd> block), you will need to redeclare the HSTS header. Consider the following example:</p>
<pre>add_header Strict-Transport-Security "max-age=31536000;"; 
 
location  /api/ { 
    add_header 'Access-Control-Allow-Origin' '*'; 
    add_header 'Access-Control-Allow-Methods' 'GET, POST, <br/>     OPTIONS'; 
    add_header Strict-Transport-Security "max-age=31536000;"; 
} </pre>
<p>As we added access control headers, we needed to redeclare the HSTS header.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Easy SSL certificates with Let's Encrypt</h1>
                </header>
            
            <article>
                
<p>Let's Encrypt is a free, automated CA, which is made possible due to the sponsorship from companies such as the <strong>Electronic Frontier Foundation</strong> (<strong>EFF</strong>), Mozilla, Cisco, Akamai, University of Michigan, and over a dozen others. Organized by the <strong>Internet Security Research Group</strong> (<strong>ISRG</strong>), Let's Encrypt has already issued over 4 million certificates (as of May 2016), and the rate is growing exponentially.</p>
<p>While the free component may see the biggest drawcard, it's the automation that is the key point. For those who have previously gone through SSL generation through a traditional CA, it needs to have either file-based or email-based validation of the domain. If you have multiple domains, this process becomes quite time consuming to do over and over.</p>
<p>Thankfully, the Let's Encrypt CA is fully API-driven, and they even include a client to automate everything from the validation to the update of the NGINX configuration. There are also extensions for popular web control panels to automate the process as well, such as Plesk and CPanel.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The official Let's Encrypt client, recently renamed Certbot, is easy to use and install. The installation is the same for most distributions, and has been greatly simplified compared to the Let's Encrypt beta phase. Here's how to install it:</p>
<pre><strong>wget https://dl.eff.org/certbot-auto</strong>
<strong>chmod a+x certbot-auto</strong>
<strong>./certbot-auto</strong></pre>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="116" src="assets/1a9ec682-9cc6-4929-9039-13f3b78afcf3.png" width="337"/></div>
<p>This will download and install all of the required Python packages for your system, then create the Certbot-specific <strong>Virtual Environment</strong> (<strong>Virtualenv</strong>). Depending on the speed of your system, this may take up to five minutes to complete.</p>
<p>Unfortunately, the NGINX plugin to automatically create the configuration isn't complete yet, so we need to manually edit our configuration. First, let's generate the certificate:</p>
<pre><strong>./certbot-auto certonly</strong>  </pre>
<p>This will present us with two options for domain validation: It can be achieved either by placing files within your existing <kbd>webroot</kbd> directory or by running a temporary web server:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="303" src="assets/e4c24310-6a84-4a6d-a042-2c024ff9179c.png" width="489"/></div>
<p>I find that the standalone web server is the most flexible option, especially if your NGINX configuration doesn't serve static files. However, it does require you to stop any services using port <kbd>80</kbd> first.</p>
<p>Next, the wizard will ask you for an email account. This is used to notify you when your certificate is about to expire or to notify you if it has been revoked. You'll then need to enter the domain name to generate the SSL certificate.</p>
<div class="packt_tip">This domain has to be valid and the DNS pointed at the server for it to validate correctly.</div>
<p>If Certbot was able to validate, you should see a notice letting you know your certificate is ready:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" src="assets/4c37b571-5660-4dbc-838b-b2a8f1164598.png"/></div>
<p>It's worth noting that while the expiry date looks short (90 days), it's designed to be automated for renewal. We can run the renewal process with the following command:</p>
<pre><strong>./certbot-auto renew</strong> </pre>
<p>As this can be run noninteractively, you can set it to autorenew via a Cron call or similar.</p>
<p>Now, we have a certificate pair (located in <kbd>/etc/letsencrypt/live/</kbd>), we can now create an NGINX configuration to use them:</p>
<pre>server { 
    listen              443 http2; 
    server_name         letsencrypt.nginxcookbook.com; 
    ssl_certificate     <br/>     /etc/letsencrypt/live/letsencrypt.nginxcookbook.com<br/>     /fullchain.pem; 
    ssl_certificate_key <br/>     /etc/letsencrypt/live/letsencrypt.nginxcookbook.com<br/>     /privkey.pem; 
    ssl_protocols       TLSv1 TLSv1.1 TLSv1.2; 
    ssl_ciphers         HIGH:!aNULL:!MD5; 
 
    access_log  /var/log/nginx/letsencrypt-access.log  combined; 
 
    location /favicon.ico { access_log off; log_not_found off; } 
    root /var/www; 
} </pre>
<p>With our new configuration loaded, we can verify that the certificate is valid:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="389" src="assets/e01cc8d7-6886-4b12-ae09-7a1e9e53c0e7.png" width="586"/></div>
<p>As the Chrome DevTools show, the certificate used is validated by the browser and gives the green lock for confirmation. There's no difference in this certificate compared to other CAs, except you can automate the generation and renewal!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<p>The official Certbot site: <a href="https://certbot.eff.org/" target="_blank"><span class="URLPACKT">https://certbot.eff.org/</span></a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Making NGINX PCI DSS compliant</h1>
                </header>
            
            <article>
                
<p>The <strong>Payment Card Industry Data Security Standard</strong> (<strong>PCI DSS</strong>) is a set of 12 security standards designed to ensure the secure transmission and storage of payment-related information. These standards set out a stringent set of rules covering everything from server security to policy and business standards.</p>
<p>We'll focus only on one part of Requirement 4, which is entitled <em>Encrypt transmission of cardholder data across open, public networks</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>For the secure transmission of PCI DSS data with NGINX, there are a few tweaks required to achieve a standard configuration. As of version 3.2 of the standards, the use of the SSL protocol or TLS 1.0 requires additional checks and assessment. Unless it's absolutely necessary for the backwards compatibility of old equipment, we highly recommend that you disable them. Here's our working configuration:</p>
<pre>server { 
    listen              443 http2 default_server; 
    server_name         pcidss.nginxcookbook.com; 
    ssl_certificate     <br/>     /etc/letsencrypt/live/pcidss.nginxcookbook.com/<br/>     fullchain.pem; 
    ssl_certificate_key <br/>     /etc/letsencrypt/live/pcidss.nginxcookbook.com/<br/>     privkey.pem; 
 
    ssl_protocols       TLSv1.1 TLSv1.2; 
    ssl_ciphers         HIGH:!aNULL:!MD5:!kEDH; 
    ssl_prefer_server_ciphers on; 
    ssl_session_cache shared:SSL:10m; 
 
    add_header Strict-Transport-Security "max-age 31536000"; 
 
    access_log  /var/log/nginx/pcidss-access.log  combined; 
 
    location /favicon.ico { access_log off; log_not_found off; } 
    root /var/www; 
} </pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>Let's look at some of the differences:</p>
<ul>
<li><kbd>listen 443 http2 default_server;</kbd>: We add the <kbd>default_server</kbd> so that NGINX has a default configuration it will use during the negotiation phase. This is because the <strong>Server Name Indication</strong> (<strong>SNI</strong>) only occurs after the connection has been negotiated. Without specifying the <kbd>default_server</kbd> directive, the initial handshake would revert to TLS 1.0 (the NGINX default).</li>
<li><kbd>ssl_protocols TLSv1.1 TLSv1.2;</kbd>: We specify only the TLS 1.1 and 1.2 protocols, which disables the older 1.0 (vulnerable to POODLE attacks). This also ensures that the older SSLv2 and SSLv3 remain disabled as well.</li>
<li><kbd>ssl_ciphers HIGH:!aNULL:!MD5:!kEDH;</kbd>: While this doesn't look much different to our previous examples, we have added the <kbd>!kEDH</kbd> parameter to the end. This disables the basic Diffie Hellman key exchange (vulnerable to LOGJAM) while still allowing the more efficient, <strong>Elliptic curve Diffie-Hellman</strong> (<strong>EECDH</strong>).</li>
</ul>
<p>With this combination, we're able to achieve an A+ rating with the High-Tech Bridge SSL Server Test, along with a confirmation that the settings are PCI DSS compliant:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" src="assets/aa252fc8-5f2f-4e79-a247-c1b01a170623.png"/></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li>The official PCI-DSS site: <a href="https://www.pcisecuritystandards.org" target="_blank"><span class="URLPACKT">https://www.pcisecuritystandards.org</span></a></li>
<li>High-Tech Bridge SSL Server Test: <a href="https://www.htbridge.com/ssl/" target="_blank"><span class="URLPACKT">https://www.htbridge.com/ssl/</span></a></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">OCSP stapling with NGINX</h1>
                </header>
            
            <article>
                
<p><strong>Online Certificate Status Protocol</strong> (<strong>OCSP</strong>) is one of the main protocols used for checking for revoked certificates. This is important in order to ensure that if a server or certificate was compromised, the certificates can be replaced and the old ones revoked to prevent fraudulent use.</p>
<p>These checks can be time consuming, as the browser has to validate the certificate the first time it's used. OCSP stapling is an alternative to OCSP, and alleviates some of the latency issues associated with OCSP. It does this by stapling a cached result directly to the main request. As this result is still signed by the CA, it means that the results are just as secure, yet with no additional latency.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>In order to use OCSP stapling, we need to add two additional lines to our <kbd>server</kbd> directive:</p>
<pre>ssl_stapling on; 
ssl_stapling_verify on; </pre>
<p>This means that the server is now responsible for the initial OCSP lookup and will then send every subsequent request with the cached result.</p>
<p>We can verify that this is working with the Qualys SSL Server Test, and we should be looking for the following:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" src="assets/a4887118-8874-4a9f-b811-bac36cd0e1fc.png"/></div>
<p>CloudFlare (a content distribution and website performance platform) claims that OCSP stapling saves up to 30 percent of the SSL negotiation time, so enabling this is key for maximizing website performance.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li>The OCSP stapling Wikipedia page: <a href="https://en.wikipedia.org/wiki/OCSP_stapling" target="_blank"><span class="URLPACKT">https://en.wikipedia.org/wiki/OCSP_stapling</span></a></li>
<li>Qualys SSL Server Test: <a href="https://www.ssllabs.com/ssltest" target="_blank"><span class="URLPACKT">https://www.ssllabs.com/ssltest</span></a></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Achieving full A+ Qualys rating</h1>
                </header>
            
            <article>
                
<p>One of the benchmarks for configuring an SSL-based site is to achieve an A+ rating using the Qualys Server SSL Test. This is because Qualys has set a stringent set of expected results and minimum standards, designed to ensure that your website is as secure as possible.</p>
<p>Achieving this requires you to disable old protocols and ciphers, much in the way we do for PCI-DSS configurations. In fact, the basic PCI-DSS configuration we tested earlier already achieves an A+ rating. We're going to take it and go a bit further to give the ultimate SSL configuration for NGINX.</p>
<div class="packt_tip">Some of these changes can cause backwards compatibility issues with older devices and browsers. Ensure you test it against your intended target audience thoroughly before using it in production.</div>
<p>Before we start, here's what a basic configuration (for example, our Let's Encrypt recipe) achieves:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" src="assets/ddc1856b-1a13-40c0-9107-756a447f1aea.png"/></div>
<p>A <kbd>B</kbd> score isn't bad, and the main area it's downgraded for is the weak Diffie-Hellman key exchange. We'll ensure this isn't an issue in this recipe.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The first thing we need to do is regenerate our certificate to ensure that it's 4096-bit for the RSA key. Most CAs issue a 2048-bit certificate, which will only give us 90 percent for the <span class="packt_screen">Key Exchange</span> evaluation. If you're using Let's Encrypt, you'll need to generate the certificate with the <kbd>--rsa-key-size 4096</kbd> parameter.</p>
<p>Here's our <kbd>server</kbd> directive, which has been based on the PCI-DSS configuration and tweaked further:</p>
<pre>server { 
    listen              443 http2 default_server; 
    server_name         ultimate.nginxcookbook.com; 
    ssl_certificate     <br/>     /etc/letsencrypt/live/ultimate.nginxcookbook.com<br/>     /fullchain.pem; 
    ssl_certificate_key <br/>     /etc/letsencrypt/live/ultimate.nginxcookbook.com<br/>     /privkey.pem; 
 
    ssl_protocols    TLSv1.2; 
    ssl_ciphers         EECDH+CHACHA20:EECDH+CHACHA20-<br/>     draft:EECDH+AES128:RSA+AES128:EECDH+AES256:<br/>     RSA+AES256:EECDH+3DES:RSA+3DES:!MD5; 
    ssl_prefer_server_ciphers on; 
    ssl_session_cache shared:SSL:10m; 
 
    ssl_stapling on; 
    ssl_stapling_verify on; 
 
    ssl_dhparam /etc/ssl/dhparam.pem; 
 
    add_header Strict-Transport-Security "max-age=31536000"; 
 
    access_log  /var/log/nginx/ultimate-access.log  combined; 
 
    location /favicon.ico { access_log off; log_not_found off; } 
    root /var/www; 
} </pre>
<p>With this set, we achieve A+, as shown in the following image:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" src="assets/cd128382-08dc-4abf-af1c-6d15768ccf03.png"/></div>
<p>Using the High-Tech Bridge SSL Server Test we also achieve full NIST-recommendation compliance as well:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img class=" image-border" height="128" src="assets/eecb7308-a43d-455b-b140-186631e5bef5.png" width="336"/></div>
<p>To restate the note at the start, the more stringent the security rules, the greater the chance of issues with older systems and browsers.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>Firstly, we only allow TLS 1.2. Qualys to require this for the 100 percent protocol grading.</p>
<p>Next, we set a very limited number of ciphers, all of which are 256 bit or higher. We've also set it to use EECDH only, to enforce forward secrecy. This is combined with the 384-bit curve (<kbd>secp384r1</kbd>), which is the grade that the NSA mandate for top-secret graded documents. This is roughly the equivalent of a 7680-bit RSA key, so don't be fooled by the lower bit count.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li>Qualys SSL Server Test: <a href="https://www.ssllabs.com/ssltest" target="_blank"><span class="URLPACKT">https://www.ssllabs.com/ssltest</span></a></li>
<li>Qualys Server Rating Guide:Â <a href="https://github.com/ssllabs/research/wiki/SSL-Server-Rating-Guide">https://github.com/ssllabs/research/wiki/SSL-Server-Rating-Guide</a></li>
</ul>


            </article>

            
        </section>
    </body></html>