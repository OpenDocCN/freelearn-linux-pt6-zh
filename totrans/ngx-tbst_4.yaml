- en: Chapter 4. Optimizing Website Performance
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章：优化网站性能
- en: 'One of the most popular reasons to migrate to Nginx is striving for better
    performance. Over the years, Nginx has acquired a certain reputation of being
    a silver bullet, a speed beast. Sometimes, this reputation may harm the project,
    but it is definitely earned. In many situations, that is exactly what happens:
    you *add* Nginx to a website setup as if it is a concoction ingredient and the
    website magically becomes faster. We will not explain the basics of how to set
    up Nginx because you probably know it all pretty well. In this chapter, we are
    going to delve a little into why this happens and what are the less-known options
    that will help you squeeze more out of your website.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移到 Nginx 最受欢迎的原因之一是追求更好的性能。多年来，Nginx 因其卓越的性能而获得了一定的声誉，被誉为“银弹”和“速度怪兽”。有时，这种声誉可能会对项目产生负面影响，但它无疑是实至名归的。在许多情况下，确实会发生这样的事情：你*添加*
    Nginx 到网站配置中，就像添加配料一样，网站就奇迹般地变得更快。我们不会解释如何设置 Nginx 的基础知识，因为你可能已经很熟悉这些内容了。在本章中，我们将深入探讨为什么会发生这种情况，以及有哪些不太为人所知的选项可以帮助你从网站中挤出更多性能。
- en: 'We will cover these topics in the chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: How Nginx processes the requests
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nginx 如何处理请求
- en: Nginx caching subsystems
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nginx 缓存子系统
- en: Optimizing the upstreams
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化上游服务器
- en: Some new Nginx features such as thread pools
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些新特性，例如线程池
- en: Other performance issues
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他性能问题
- en: The overwhelming majority of all performance problems people have with Nginx-powered
    websites are actually on the upstreams. We will try to at least mention some of
    the methods you may use to tackle the challenge of optimizing your upstream application
    servers, but we will concentrate on the Nginx itself mostly. You will have to
    understand the inner workings of Nginx and reverse proxying in general, and we
    are devoting a good part of the chapter to explain the principles implemented
    in Nginx that let it run around other older web servers in terms of performance.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数使用 Nginx 的网站在性能上遇到的问题，其实大多出现在上游服务器上。我们会尽量提到一些你可以用来优化上游应用服务器的办法，但我们主要会集中讨论
    Nginx 本身。你需要理解 Nginx 内部的工作原理以及反向代理的一般原理，我们将花费章节的一大部分来解释 Nginx 中的原理，正是这些原理让 Nginx
    在性能上超越了其他一些较旧的 Web 服务器。
- en: The bad news is that you probably won't be able to optimize Nginx very much.
    If you embarked on a project of making your website sufficiently, significantly
    faster, and started with inserting Nginx between the application and the users,
    then you have probably already done the most important steps in moving towards
    your goal. Nginx is extremely optimal in the sense of avoiding doing extra, unneeded
    work, and that is the core of any optimization.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 坏消息是，你可能无法对 Nginx 做太多优化。如果你已经着手通过在应用程序与用户之间插入 Nginx 来显著加速网站，那么你可能已经走完了实现目标的最重要步骤。Nginx
    在避免做额外、不必要的工作方面极为高效，而这正是任何优化的核心。
- en: Still, some of the configuration defaults may be too conservative for the sake
    of compatibility, and we will try to talk about this.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 仍然，一些默认配置可能为了兼容性而显得过于保守，我们将尝试讨论这一点。
- en: Why Nginx is so fast?
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么 Nginx 如此快速？
- en: 'The question is intentionally formulated in an oversimplified way. This is
    what you might hear from your boss or client—let us migrate from old technologies
    to Nginx because it will make our website faster and users happier. The migration
    process is described in thousands of online articles and even some books, and
    we will not write about it here. Many of our readers have probably gone down that
    path several times and know the facts: first, it is usually true that websites
    get faster and second, no, it is not usually a full migration. You will rarely
    dispose of Apache completely and plug Nginx in its place. Although this "total
    conversion" also happens, most of the time you start with inserting Nginx between
    Apache and the Internet. To understand why this is okay, why this helps at all,
    and how to move forward from there, read on.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题故意以过于简化的方式提出来。这就是你可能从老板或客户那里听到的话——让我们从旧技术迁移到 Nginx，因为它会让我们的网站更快，用户更开心。迁移过程在成千上万的在线文章甚至一些书籍中都有描述，我们在这里不会再写这部分内容了。我们很多读者可能已经走过这条路很多次，并且知道事实：首先，网站通常变得更快；其次，不，通常不是完全的迁移。你很少会完全弃用
    Apache，直接用 Nginx 替换。虽然这种“完全转换”也会发生，但大多数情况下，你是将 Nginx 插入到 Apache 和互联网之间。要理解为什么这样做是可行的，为什么这会有帮助，并且如何从这里继续推进，继续阅读。
- en: To describe the main conceptual change that is implemented by using Nginx as
    a reverse proxy we will use, for simplicity, the processing model of Apache 1.x,
    that is, a very old piece of software written in premultithreading traditions.
    The latest Apache version, which is 2.x, may use another, slightly more efficient
    model, which is based on threads instead of processes. But in comparison to Nginx,
    those two models look very similar, and the older one is easier to understand.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了描述使用 Nginx 作为反向代理所实现的主要概念性变化，我们将简单地使用 Apache 1.x 的处理模型，也就是一种非常古老的软件，采用了预多线程传统。最新的
    Apache 版本，即 2.x，可能使用另一种稍微更高效的模型，它是基于线程而不是进程的。但与 Nginx 相比，这两种模型看起来非常相似，而且较老的模型更容易理解。
- en: 'This is a simple diagram of how one HTTP request-response pair is processed:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的图示，展示了一个 HTTP 请求-响应对是如何被处理的：
- en: '![Why Nginx is so fast?](img/B04329_04_01.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![为什么 Nginx 如此快速？](img/B04329_04_01.jpg)'
- en: 'Here is an explanation of the diagram:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是图表的解释：
- en: A user's browser opens a connection to your server using TCP.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户的浏览器使用 TCP 打开与服务器的连接。
- en: A web server software that runs on your server and listens to a particular set
    of TCP ports, accepts the connection, dedicates a part of itself to processing
    this connection, separates this part, and returns to listening and accepting other
    incoming connections. In the case of the Apache 1.x model, the separated part
    is a child process that has been forked beforehand and is waiting in the pool.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一款在你的服务器上运行并监听特定 TCP 端口的 web 服务器软件，它接受连接，将一部分资源分配给该连接进行处理，处理完后再返回继续监听并接受其他传入的连接。对于
    Apache 1.x 模型而言，这部分被分离出的资源是一个已经提前创建的子进程，并在进程池中等待。
- en: There are usually some limits in place on how many concurrent connections may
    be processed and they are enforced on this step. It is very important to understand
    that this is the part where scaling happens.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通常会对并发连接的处理数量设置一些限制，并在此步骤进行强制执行。理解这一点非常重要，因为这是扩展的关键所在。
- en: This dedicated part of the web server software reads the actual request URI,
    interprets it, and finds the relevant file or any other way to generate the response.
    Maybe that would even be an error message; it doesn't matter. It starts sending
    this response into the connection.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这部分专门的 web 服务器软件读取实际的请求 URI，解析它，并找到相关的文件或其他方式生成响应。也许生成的响应会是一个错误信息，但这并不重要。它开始将响应数据发送到连接中。
- en: The user's browser receives the bytes of the response one by one and generates
    pixels on the user's screen. This is actually a real job and a long one. Data
    is sent over hundreds of kilometers of wires and optical fiber, emitted into the
    air as electromagnetic waves and then "condensed" by induction into current again.
    From the viewpoint of your server, most of your users are on excruciatingly slow
    networks. The web server is literally feeding those browsers large amounts of
    data through a straw.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户的浏览器逐个接收响应字节，并在用户的屏幕上生成像素。这实际上是一个很长的工作。数据要通过数百公里的电线和光纤传输，转换为电磁波传播到空中，再通过感应转化为电流。从服务器的角度看，绝大多数用户都处于极其缓慢的网络环境中。Web
    服务器实际上是在通过一根吸管向这些浏览器输送大量数据。
- en: There is nothing that could be done to solve the fifth point. The last mile
    will always be the slowest link in the chain between your server and the user.
    Nginx makes a conceptual optimization on step 2 and scales much better this way.
    Let us explain that at a greater length.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 第五点是无法解决的。最后一公里总是你服务器与用户之间链路中最慢的环节。Nginx 在第二步进行了概念性的优化，从而能够更好地进行扩展。让我们详细解释一下这一点。
- en: 'Due to slow client connections, a snapshot of any popular website server software
    at any particular moment in time looks like this: a couple of requests that are
    actually processed in the sense that there is some important work being done by
    the CPU, memory, and disks and then a couple of thousands of requests for which
    all processing is done, responses are already generated and are very slowly, piece
    by piece inserted into the narrow connections to the users'' browsers. Again,
    this is a simplified model, but still very adequate to explain what actually happens.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 由于客户端连接较慢，在任何特定时间点，任何流行网站的服务器软件快照看起来大致是这样的：几个请求实际上已经在处理，即 CPU、内存和磁盘正在进行一些重要工作；然后是几千个请求，所有处理都已经完成，响应已生成，但响应会非常慢地、逐步地通过狭窄的连接发送到用户的浏览器。再次强调，这是一个简化模型，但足以说明实际发生的情况。
- en: 'To implement scaling on step 2, the original Apache 1.x uses a mechanism that
    is very natural for all UNIX-based systems—it forks. There are some optimizations,
    for example, in the form of having a pool of processes forked beforehand (hence,
    the "prefork" model), and Apache 2.x may use threads instead of processes (also
    with pregenerated pools and all), but the idea is the same: scaling is achieved
    by handling individual requests to a group of some OS-level entities, each of
    which is able to work on a request and then send the data to the client. The problem
    is that those entities are rather big; you don''t just need a group, but more
    like a horde of them, and most of the time, they do a very simple thing: they
    send bytes from a buffer into a TCP connection.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在第二步中实现扩展，原始的 Apache 1.x 使用了一种非常适合所有 UNIX 系统的机制——它进行 fork 操作。有一些优化，比如通过预先创建一组已经
    fork 出来的进程池（因此有了“预先 fork”模型），而 Apache 2.x 可能使用线程代替进程（同样带有预生成的池等），但核心思想是相同的：通过将单个请求分配给一组操作系统级的实体来实现扩展，每个实体都能处理一个请求，然后将数据发送到客户端。问题在于这些实体相对庞大；你不仅仅需要一组，而是需要一大群，而且大多数时候它们执行的任务非常简单：将字节从缓冲区发送到
    TCP 连接。
- en: Nginx and other state machine-based servers significantly optimize step 2 by
    not making big, complex OS-level processes or threads do a simple job while hogging
    the memory at the same time. This is the essence of why Nginx suddenly makes your
    website faster—it manages to slowly feed all those thousands of very bandwidth-limited
    client connections using very little memory, saving on RAM.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Nginx 和其他基于状态机的服务器通过不让大而复杂的操作系统级进程或线程执行简单任务，同时又占用大量内存，显著优化了第二步的处理。这就是 Nginx
    突然能让你的网站变得更快的本质——它能够用极少的内存慢慢地处理成千上万带宽受限的客户端连接，节省了大量的 RAM。
- en: 'An inquisitive reader may ask the question here about why adding Nginx as a
    reverse proxy without removing Apache still saves memory and speeds up websites.
    We believe that you already should have all the knowledge to come up with the
    correct answer for that. We will mention the most important part as a hint: the
    horde of Apaches is not needed anymore because Apache only does the response generation—the
    smartest and hardest thing—while offloading the dumb job of pushing bytes to thousands
    of slow connections. The reverse proxy is acting as a proxy client on behalf of
    all the users'' browsers with the very important distinction: this client is sitting
    very close to the server and is capable of receiving the bytes of the response
    lightning fast.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 好奇的读者可能会问，为什么在不移除 Apache 的情况下，添加 Nginx 作为反向代理仍然能节省内存并加速网站。我们相信，你应该已经具备足够的知识来得出正确的答案。我们将提到最重要的部分作为提示：不再需要一大堆
    Apache，因为 Apache 只负责生成响应——最聪明、最复杂的部分——而将将字节推送到成千上万慢速连接的简单任务交给反向代理。反向代理充当所有用户浏览器的代理客户端，且有一个非常重要的区别：这个客户端离服务器非常近，能够以闪电般的速度接收响应的字节。
- en: So, the secret sauce to Nginx's performance is not its magical code quality
    (although it is written very well), but the fact that it saves up on system resources,
    mostly memory, by not making huge copies of data for each individual request it
    is processing. Interestingly enough, modern operating systems all have different
    low-level mechanisms to avoid excessive copying of data. Long gone are times when
    `fork()` literally created a whole copy of all code and data. As virtual memory
    and network subsystems get more and more sophisticated, we may end up with a system
    where the state machine as a model to code tight event-processing loops won't
    be needed any more. As of now, they still bring noticeable improvements.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，Nginx 性能的秘诀并非其神奇的代码质量（尽管它写得非常好），而在于它通过不为每个单独的请求复制大量数据，从而节省了系统资源，主要是内存。有趣的是，现代操作系统都有不同的低级机制来避免过度复制数据。早已不再是
    `fork()`  literally 创建一个代码和数据的完整副本的时候了。随着虚拟内存和网络子系统的不断发展，我们最终可能会遇到一种系统，其中不再需要将状态机作为模型来编写紧凑的事件处理循环。目前，它们仍然能带来显著的性能提升。
- en: Optimizing individual upstreams
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化单个上游
- en: You may remember from previous chapters that Nginx has two main methods of generating
    a response to a request, one being very specific—reading a static file from the
    filesystem, and the other including a whole family of the so-called upstream modules.
    An upstream is an external server to which Nginx proxies the request. The most
    popular upstream is `ngx_proxy`, others are `ngx_fastcgi`, `ngx_memcached`, `ngx_scgi`,
    and so on. Because serving only static files is not usually enough for a modern
    website, upstreams are an essential part of any comprehensive setup. As we mentioned
    in the beginning of this chapter, upstreams themselves are usually the reason
    why your website has performance troubles. Your developers are responsible for
    this part because this is where all the web application processing happens. In
    the following sections, we are going to briefly describe the major stacks or platforms
    used to implement business logic on the upstream behind Nginx and the directions
    you should at least look in for clues about what to optimize.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能还记得前几章提到过，Nginx 有两种主要的生成响应请求的方法，一种非常具体，从文件系统读取静态文件，另一种包括一整套所谓的上游模块。上游是 Nginx
    代理请求的外部服务器。最流行的上游是 `ngx_proxy`，其他还有 `ngx_fastcgi`，`ngx_memcached`，`ngx_scgi` 等等。因为仅提供静态文件通常对现代网站来说不足够，上游是任何综合设置的重要部分。正如本章开头提到的，上游本身通常是您的网站性能问题的原因。您的开发人员对此负责，因为这是所有
    Web 应用程序处理发生的地方。在接下来的几节中，我们将简要描述用于在 Nginx 后面实现业务逻辑的主要堆栈或平台以及您至少应该寻找优化线索的方向。
- en: Optimizing static files
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化静态文件
- en: Any web application will contain static resources that do not change and do
    not depend on the user currently using the application. Those are usually known
    as static files in webmaster parlance and consist of all the static images, CSS,
    JavaScript, and some other extra data, for example, `cross-domain.xml` files that
    are used by access control policies of the browsers. Serving the data directly
    from the application is usually supported to facilitate simple setups without
    any frontend, intermediate, accelerating server such as Nginx. Nginx's built-in
    HTTP proxy will happily serve them, and in the case of local caching, may even
    do that without any noticeable performance loss. However, such a setup is not
    recommended as a long-term solution if you strive for maximum performance.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 任何 Web 应用程序都将包含静态资源，这些资源不会改变也不依赖于当前使用应用程序的用户。这些通常在网络管理员术语中称为静态文件，并包括所有静态图像、CSS、JavaScript
    以及例如 `cross-domain.xml` 这样的其他额外数据，它们用于浏览器的访问控制策略。通常支持直接从应用程序中提供数据，以促进没有任何前端、中间加速服务器（如
    Nginx）的简单设置。Nginx 内置的 HTTP 代理将乐意为其提供服务，并且在本地缓存的情况下，甚至可能在没有任何可察觉的性能损失的情况下完成。然而，如果您追求最大性能，长期采用这样的设置并不推荐。
- en: One universal step that we feel the need to recommend (or remind of) is moving
    as much of the static data from the upstream under the control of Nginx. It will
    make your application more fragmented, but it will also be a very good performance
    optimization method trumping many of other potential and much harder to implement
    methods. If your upstreams serve static files, then you need to make them available
    as files to Nginx and serve them directly. This might be the first thing you do
    when you receive a new legacy upstream to optimize. It is also a very easy task
    to accomplish yourself or implement as a part of the whole deployment process.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们强烈建议（或提醒）的一个普遍步骤是将尽可能多的静态数据从上游移到 Nginx 的控制之下。这将使您的应用程序更加分散，但也将是一种非常好的性能优化方法，胜过许多其他潜在且难以实现的方法。如果您的上游服务器提供静态文件，则需要将它们作为文件提供给
    Nginx 并直接提供服务。当您收到一个新的遗留上游以进行优化时，这可能是您首先要做的事情。这也是一个非常容易自己完成或作为整个部署过程的一部分实现的任务。
- en: Optimizing PHP backends
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化 PHP 后端
- en: For several years, the modern way to run PHP applications behind Nginx front
    is the PHP-FPM or FastCGI Process Manager. As you may guess, it uses the FastCGI
    protocol and will require FastCGI upstream module in Nginx. However, when dealing
    with inherited legacy PHP websites, you may still meet the older ways of running
    the code, which will be your first candidates for optimizations.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 多年来，运行 PHP 应用程序在 Nginx 前端的现代方式是使用 PHP-FPM 或 FastCGI 进程管理器。正如您可能猜到的那样，它使用 FastCGI
    协议，并且需要在 Nginx 中使用 FastCGI 上游模块。然而，当处理继承的遗留 PHP 网站时，您可能仍然会遇到运行代码的旧方式，这将是您首先要优化的候选方案。
- en: There is the official Apache way using the `mod_php` Apache module. This module
    embeds PHP interpreter directly into (each and every!) Apache process. Most of
    the time, you will inherit Apache websites configured to run in this way. The
    main good side of embedded interpreters is well known—the code may be saved in
    some intermediate form between requests and not reinterpreted every time. The
    `mod_php` Apache module does that wonderfully and some people call it the single
    reason why PHP gained popularity on the Web in the first place. Well, the way
    to deal with `mod_php` in 2016 is getting rid of it, together with Apache.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用官方 Apache 方式，通过`mod_php` Apache 模块。该模块将 PHP 解释器直接嵌入到（每一个！）Apache 进程中。大多数情况下，你将继承配置为以这种方式运行的
    Apache 网站。嵌入式解释器的主要优点是显而易见的——代码可以在请求之间以某种中间形式保存，而不是每次都重新解释。`mod_php` Apache 模块做得非常好，一些人称它为
    PHP 在 Web 上获得流行的唯一原因。嗯，2016 年处理`mod_php`的方式是摆脱它，连同 Apache 一起。
- en: Many PHP codebases can be moved from `mod_php` to PHP-FPM almost effortlessly.
    After this, you will change your main Nginx upstream from HTTP proxying to directly
    speaking FastCGI protocol with your PHP scripts that are kept running and ready
    by the FPM.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 许多 PHP 代码库可以几乎毫不费力地从`mod_php`迁移到 PHP-FPM。之后，你将改变主 Nginx 上游，从 HTTP 代理转变为直接使用
    FastCGI 协议与通过 FPM 保持运行并随时准备好的 PHP 脚本通信。
- en: Sometimes, your developers will need to invest some resources into mostly restructuring
    and refactoring code to be runnable in a separate process without any help from
    Apache. One particularly difficult case is a code that relies heavily on calling
    into the Apache internals. Fortunately, this is not nearly as common in PHP codebases
    as it was in the `mod_perl` codebases. I will mention dealing with Perl-based
    websites later.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，你的开发人员需要投入一些资源，主要是重构和调整代码，使其能够在没有 Apache 帮助的情况下在独立进程中运行。一个特别困难的情况是，代码严重依赖于调用
    Apache 内部功能。幸运的是，这在 PHP 代码库中不像在`mod_perl`代码库中那样常见。稍后我会提到如何处理基于 Perl 的网站。
- en: Another really old (and odd) way to run PHP is CGI scripts. Each and every web
    administrator did or will write a fair amount of temporary CGI scripts. You know,
    the kind of temporary scripts that live on and on through generations of hardware,
    managers, and business models. They rarely power parts of production that are
    user-oriented. Anyway, CGI was not popular with PHP at all because of the ubiquity
    and rather good quality of `mod_php` and Apache. Nevertheless, you may have some
    in your legacy, especially if that code had or has some chances to run on Windows.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种非常古老（且奇怪）的方法是运行 PHP 的 CGI 脚本。每一个网站管理员都做过或将会做大量的临时 CGI 脚本。你知道的，那种通过一代又一代的硬件、管理者和商业模式延续下去的临时脚本。它们很少用于面向用户的生产部分。总之，CGI
    在 PHP 中并不受欢迎，因为`mod_php`和 Apache 的普及以及相当不错的质量。然而，你的遗留代码中可能会有一些 CGI 脚本，特别是如果这些代码曾经或现在有可能在
    Windows 上运行的话。
- en: CGI scripts are executed as separate processes for each request/response pair
    and therefore are prohibitively expensive. The only upsides of using CGI are increased
    compatibility with other Apache modules and another degree of privilege separation.
    Those are trumped by the performance compromises in all but the most exotic scenarios.
    By the way, Nginx will make a CGI-powered portion of your website significantly
    better by buffering the output and releasing the resources on the backend. You
    still have to plan the rewrite of those parts to be run as FastCGI under FPM as
    soon as possible.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: CGI 脚本作为每个请求/响应对的独立进程执行，因此成本非常高。使用 CGI 的唯一好处是提高了与其他 Apache 模块的兼容性和另外一种特权分离的程度。除了在最特殊的情况下，性能的折衷完全超越了这些优点。顺便说一句，Nginx
    会通过缓存输出并释放后端资源，显著提升你网站的 CGI 功能部分。你仍然需要尽早规划重写这些部分，使其能作为 FastCGI 在 FPM 下运行。
- en: PHP-FPM uses the same prefork model as does Apache 1.x and that renders some
    of the familiar knobs under your control. For example, you may configure the number
    of working processes FPM starts, the upper limit of the requests that may be processed
    by one child, and also the size of the available child processes pool. All those
    parameters may be set via the `php-fpm.conf` file, which is usually installed
    directly in `/etc` and following a good convention includes `/etc/php-fpm.d/*.conf`.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: PHP-FPM 使用与 Apache 1.x 相同的预分叉（prefork）模型，这使得你可以控制一些熟悉的参数。例如，你可以配置 FPM 启动的工作进程数、每个子进程可以处理的请求上限，以及可用的子进程池大小。所有这些参数都可以通过`php-fpm.conf`文件进行设置，该文件通常直接安装在`/etc`目录下，并遵循良好的约定，包含`/etc/php-fpm.d/*.conf`。
- en: Java backends
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Java 后端
- en: 'The Java ecosystem is so huge that there is a whole bookshelf devoted solely
    to different Java web servers. We cannot delve deeper into such a topic. If you
    as an administrator have never had any experience with Java web applications,
    you will be happy to know that most of the time, those apps run their own web
    servers that do not depend on Apache. This is a list of popular Java web servers
    that you may encounter inside your upstreams: Apache Tomcat, Jetty, and Jboss/WildFly.
    Java applications are usually built on top of huge and comprehensive frameworks
    that employ a web server as one of the components. Your Nginx web accelerator
    will talk to the Java upstream via normal HTTP protocol using the `ngx_proxy`
    module. All the usual `ngx_proxy` optimizations apply, therefore. See a note on
    caching later in this chapter for examples.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Java 生态系统如此庞大，专门讨论各种 Java Web 服务器的书架几乎都有一整本。我们无法深入探讨这个话题。如果你作为管理员从未接触过 Java
    Web 应用，你会很高兴地知道，大多数情况下，这些应用程序运行着自己独立的 Web 服务器，并不依赖 Apache。这是你可能在上游遇到的流行 Java Web
    服务器的列表：Apache Tomcat、Jetty 和 Jboss/WildFly。Java 应用通常基于庞大且全面的框架构建，其中 Web 服务器只是一个组成部分。你的
    Nginx Web 加速器将通过正常的 HTTP 协议与 Java 上游进行通信，使用 `ngx_proxy` 模块。因此，所有常见的 `ngx_proxy`
    优化都会适用。稍后在本章中，关于缓存的说明会提供更多示例。
- en: 'There is little you can do to make a Java application perform better without
    getting your hands dirty deep inside the code. Some of the steps available from
    the level of system administration are:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不深入到代码内部，几乎无法做任何事情来提高 Java 应用程序的性能。系统管理员层面可以采取的一些步骤包括：
- en: Choosing the right JVM. Many Java web servers support several different Java
    Virtual Machine implementations. The HotSpot JVM from Oracle (Sun) is considered
    one of the best, and you will probably start with that. But there are others;
    some of them are commercially available, for example, Azul Zing VM. They might
    provide you with a little performance boost. Unfortunately, changing JVM vendor
    is a huge step prone to incompatibility errors.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择合适的 JVM。许多 Java Web 服务器支持几种不同的 Java 虚拟机实现。Oracle（Sun）提供的 HotSpot JVM 被认为是最好的之一，你可能会从这个开始。但也有其他的虚拟机实现，其中一些是商业化的，比如
    Azul Zing VM。它们可能会为你提供一些性能提升。不幸的是，更换 JVM 供应商是一个重大步骤，容易导致不兼容错误。
- en: Tuning threading parameters. Java code is traditionally written using threads
    that are a native and natural feature of the language. JVMs are free to implement
    threads using whatever resources they have. Usually, you will have a choice of
    using either operating system-level threads or the so-called "green threads,"
    which are implemented in userland. Both approaches have advantages and disadvantages.
    Threads are usually grouped into pools, which are preforked in a fashion that
    is very similar to what Apache 1.x does with processes. There are a number of
    models that thread pools use to optimize both memory and performance, and you,
    as administrator, will be able to tune them up.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调整线程参数。Java 代码通常使用线程来编写，这是该语言的一个本地且自然的特性。JVM 可以自由地使用任何资源来实现线程。通常，你可以选择使用操作系统级别的线程，或者所谓的“绿色线程”，它们是在用户空间实现的。这两种方法各有优缺点。线程通常会被分组到线程池中，这些线程池的预启动方式与
    Apache 1.x 在进程上所做的类似。线程池使用多种模型来优化内存和性能，作为管理员的你将能够对它们进行调整。
- en: Optimizing Python and Ruby backends
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化 Python 和 Ruby 后端
- en: Python and Ruby both built their strength as more open and clear alternatives
    to Perl and PHP in the age when web applications were already one of the dominant
    way to deploy business logic. They both started late and with a clear goal of
    being very web-friendly. There were both the `mod_python` and `mod_ruby` Apache
    modules that embedded interpreters into the Apache web server processes, but they
    quickly went out of fashion. The Python community developed the **Web Server Gateway
    Interface** (**WSGI**) protocol as a generic interface to write web applications
    regardless of deployment options. This allowed free innovation in the actual web
    server space that mostly converged on a couple of standalone WSGI servers or containers
    (such as gunicorn and uWSGI) and `mod_wsgi` Apache module. They all may be used
    to run a Python web application without changing any code.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Python 和 Ruby 都是在 Web 应用已经成为部署业务逻辑的主要方式时，作为比 Perl 和 PHP 更开放、更清晰的替代方案而崛起的。它们都是后来才起步，并且有一个明确的目标——成为非常适合
    Web 的语言。曾经有 `mod_python` 和 `mod_ruby` 这样的 Apache 模块，它们将解释器嵌入到 Apache Web 服务器进程中，但它们很快就过时了。Python
    社区开发了**Web 服务器网关接口**（**WSGI**）协议，作为一种通用的接口，可以编写与部署选项无关的 Web 应用程序。这使得在实际 Web 服务器领域的创新得以自由进行，最终大多集中在几个独立的
    WSGI 服务器或容器上（例如 gunicorn 和 uWSGI）以及 `mod_wsgi` Apache 模块。它们都可以用来运行 Python Web
    应用，而无需修改任何代码。
- en: So, it was very natural that Nginx developed its own WSGI upstream module, `ngx_wsgi`,
    which you should use to replace any other WSGI implementation. The actual migration
    path may be a little bit more complex. If the backend application used to run
    under Apache + `mod_wsgi`, then, by all means, switch to `ngx_wsgi` immediately
    and ditch Apache. Otherwise, for the sake of smoothness and stability, you may
    start with a simpler `ngx_proxy` configuration and then move to `ngx_wsgi`.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，Nginx 开发了自己的 WSGI 上游模块 `ngx_wsgi`，这是你应该使用的模块，替代任何其他的 WSGI 实现。实际的迁移路径可能会更复杂。如果后端应用曾经在
    Apache + `mod_wsgi` 下运行，那么，毫不犹豫地切换到 `ngx_wsgi` 并放弃 Apache。否则，为了平滑和稳定，你可以从更简单的
    `ngx_proxy` 配置开始，然后再转向 `ngx_wsgi`。
- en: You may also encounter an application that uses long-polling (named Comet sometimes)
    and WebSockets, and runs on a special web server, for example, Tornado (of the
    FriendFeed fame). These are problems mostly because synchronous communication
    between the web server and the clients defeats the main advantage of Nginx as
    an accelerating reverse proxy—the part of the server that processes a request
    won't be made available quickly for another request by handling the byte pushing
    to the Nginx frontend. Modern Nginx supports proxying both Comet requests and
    Web Sockets, of course, but without any acceleration that you may have gotten
    used to.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可能遇到使用长轮询（有时称为 Comet）和 WebSockets 的应用程序，并且运行在一个特殊的 Web 服务器上，例如 Tornado（因 FriendFeed
    而闻名）。这些问题主要在于 Web 服务器与客户端之间的同步通信，阻碍了 Nginx 作为加速反向代理的主要优势——处理请求的服务器部分无法通过处理字节推送到
    Nginx 前端迅速为另一个请求提供服务。当然，现代的 Nginx 支持代理 Comet 请求和 WebSockets，但没有你可能已经习惯的加速效果。
- en: The Ruby ecosystem went a slightly different way because there was (and still
    is) a so-called killer app for Ruby, that is, the Ruby on Rails web application
    framework. Most of the Ruby web applications are built on Ruby on Rails, and there
    was even a joke that it is high time to rename the whole language Ruby on Rails
    because nobody uses Ruby without those Rails. It is a wonderfully designed and
    executed web framework with many revolutionary ideas that inspired a whole wave
    of rapid application development techniques throughout the industry. It also decoupled
    the application developers from the problems of deploying their work by providing
    the web server that could be shared on the Internet right away.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Ruby 生态系统走了一条略有不同的道路，因为 Ruby 有一个所谓的“杀手级应用”，那就是 Ruby on Rails Web 应用框架。大多数 Ruby
    Web 应用都是基于 Ruby on Rails 构建的，甚至有人开玩笑说该把整个语言改名为 Ruby on Rails，因为没有 Rails，没人会用 Ruby。它是一个设计精妙、执行出色的
    Web 框架，拥有许多革命性的理念，启发了整个行业的快速应用开发技术浪潮。它还通过提供可以立即在互联网上共享的 Web 服务器，将应用开发人员与部署工作中的问题解耦。
- en: The current Ruby on Rails preferred deployment options are either using Phusion
    Passenger or running a cluster of Unicorn web servers. Both options are fine for
    your task of migrating to Nginx. Phusion Passenger is a mature example of providing
    its own in-process code as it contains modules for both Apache and Nginx web servers.
    So, if you are lucky, you will switch from one to the other effortlessly. Passenger
    will still run worker processes outside of your main Nginx workers, but the module
    allows Nginx to communicate freely. It is a good example of a custom upstream
    module. See [https://www.phusionpassenger.com/library/deploy/nginx/deploy/ruby/](https://www.phusionpassenger.com/library/deploy/nginx/deploy/ruby/)
    Passenger guide for the actual instructions. Passenger may also run in the standalone
    mode exposing HTTP to the world. That is also the way Unicorn deploys Ruby applications.
    You know the way to deal with that—the universal helper `ngx_proxy`.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当前 Ruby on Rails 推荐的部署选项是使用 Phusion Passenger 或者运行一组 Unicorn web 服务器。两种方式都适用于将系统迁移到
    Nginx 的任务。Phusion Passenger 是一个成熟的例子，它提供了自己的内嵌代码，包含了 Apache 和 Nginx web 服务器的模块。所以，如果运气好，你可以毫不费力地在两者之间切换。Passenger
    会在你的主 Nginx 工作进程外运行工作进程，但该模块允许 Nginx 自由地进行通信。这是一个自定义上游模块的好例子。查看 [https://www.phusionpassenger.com/library/deploy/nginx/deploy/ruby/](https://www.phusionpassenger.com/library/deploy/nginx/deploy/ruby/)
    Passenger 指南获取实际的部署说明。Passenger 还可以以独立模式运行，向外暴露 HTTP 服务。这也是 Unicorn 部署 Ruby 应用的方式。你知道如何处理这个问题——通用助手
    `ngx_proxy`。
- en: Optimizing Perl backends
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化 Perl 后端
- en: Perl was the first widely used server-side programming language for the Web.
    We may say that it is Perl that brought the notion of dynamically generated web
    pages to popularity and paved the way for the web applications galore we experience
    today. There are still plenty of Perl-powered web businesses of various sizes,
    from the behemoths such as [https://www.booking.com](https://www.booking.com)
    to smaller, feisty, ambitious startups such as DuckDuckGo. You might also have
    seen a couple of MovableType-powered blogs. This is a professional blogging platform
    developed by SixApart and then resold several times.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Perl 是第一个广泛用于 Web 服务器端编程的语言。我们可以说，正是 Perl 将动态生成网页的概念推广开来，为今天的 Web 应用程序的蓬勃发展铺平了道路。如今仍然有许多
    Perl 支持的 Web 企业，规模不等，从像 [https://www.booking.com](https://www.booking.com) 这样的大型公司，到像
    DuckDuckGo 这样的小型、充满活力且雄心勃勃的初创公司。你可能也见过几个 MovableType 支持的博客。这是一个由 SixApart 开发的专业博客平台，后来被多次转售。
- en: Perl is also the most popular language to write CGI scripts, and that is also
    the single reason why it is considered slow. CGI is a simple interface to run
    external programs from inside a web server. It is rather inefficient because it
    usually involves forking an operating system-level process and then shutting it
    down after a single request. This model plus the interpreting nature of Perl means
    that Perl CGI scripts are so suboptimal that they are used as a model of inefficient
    web development platforms.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Perl 也是编写 CGI 脚本最流行的语言，这也是它被认为较慢的唯一原因。CGI 是一个简单的接口，用于从 Web 服务器内部运行外部程序。它相当低效，因为通常涉及到分叉一个操作系统级进程，然后在处理完一个请求后关闭它。这种模式加上
    Perl 的解释性特性意味着 Perl CGI 脚本效率低下，成为低效 Web 开发平台的代表。
- en: If you have a user-facing, dynamic web page generated by a CGI script run from
    Apache, you have to get rid of it. See below for details.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个由 CGI 脚本生成的面向用户的动态网页，并且该脚本是由 Apache 运行的，那么你必须将其移除。具体细节请见下文。
- en: There are a number of more advanced ways to run Perl code in production. Partly
    inspired by the `mod_php` success, there is a long-running project named `mod_perl`,
    which is an Apache module embedding the Perl interpreter into Apache processes.
    It is also highly successful because it is stable and robust, and powers a lot
    of heavily loaded websites. Alas, it is also rather complex, both for the developer
    and the administrator. Another difference from the `mod_php` Apache module is
    that `mod_perl` failed to provide strong separation of environments, which is
    vital for the virtual hosting businesses.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种更先进的方法可以在生产环境中运行 Perl 代码。部分受到`mod_php`成功的启发，有一个长期运行的项目叫做`mod_perl`，它是一个将
    Perl 解释器嵌入 Apache 进程中的 Apache 模块。它同样非常成功，因为它稳定且健壮，支持许多高负载网站的运行。然而，它也相当复杂，对于开发者和管理员来说都不容易。与
    `mod_php` Apache 模块的另一个不同之处在于，`mod_perl`未能提供强有力的环境隔离，而这对于虚拟主机业务至关重要。
- en: Anyway, if you have inherited a website based on `mod_perl`, you have several
    options. First, there might be a cheap way to move to the PSGI or FastCGI models
    that will allow you to get rid of Apache. The module Apache::Registry,which emulates
    a CGI environment inside `mod_perl,` may be a great sign of such situation. Second,
    the code may be written in a way that couples it tightly with Apache. The `mod_perl`
    module provides an interface to hook deeply into Apache's internals, which while
    providing several interesting capabilities for the developer, also makes it much
    harder to migrate. The developers will have to investigate the methods used in
    the software and make a final decision. They may decide to leave Apache + `mod_perl`
    alone and continue to use it as a heavy and over-capable process manager.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，如果你继承了一个基于`mod_perl`的网站，你有几个选择。首先，可能有一种便宜的方式可以迁移到PSGI或FastCGI模型，这将使你能够摆脱Apache。模块Apache::Registry，它在`mod_perl`中模拟了CGI环境，可能是这种情况的一个良好迹象。其次，代码可能是以与Apache紧密耦合的方式编写的。`mod_perl`模块提供了一个接口，可以深入钩入Apache的内部，尽管为开发者提供了几个有趣的功能，但也使得迁移变得更加困难。开发者将不得不调查软件中使用的方法，并做出最终决定。他们可能决定保留Apache
    + `mod_perl`并继续使用它作为一个重型且功能过剩的进程管理器。
- en: Moving CGI to `mod_perl` nowadays is never a good way forward, we do not recommend
    it.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如今将CGI迁移到`mod_perl`从来不是一个好的选择，我们不推荐这样做。
- en: There are a number of FastCGI managers for Perl that are similar to PHP-FPM
    described earlier. They all are very lucky options for you as the Nginx administrator
    because most of the time the migration will be smooth and easy.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多类似于PHP-FPM的Perl FastCGI管理器。作为Nginx管理员，这些选项对你来说是非常幸运的，因为大多数情况下迁移会非常顺利且简单。
- en: One of the interesting recent modes to run Perl code in web servers is the so-called
    **Perl Server Gateway Interface** (**PSGI**). It is more or less a direct port
    of Rack architecture from the Ruby stack to Perl. It is interesting that PSGI
    was invented and implemented in the world where Nginx was already popular. Therefore,
    if you have a web application that uses PSGI, it was most probably tested and
    run behind Nginx. No need to port anything. PSGI might be the most important target
    architecture to upgrade CGI or the `mod_perl` applications.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 运行Perl代码在Web服务器中的一种有趣的最新方式是所谓的**Perl服务器网关接口**（**PSGI**）。它或多或少是将Ruby堆栈中的Rack架构直接移植到Perl的版本。有趣的是，PSGI是在Nginx已经流行的世界中发明并实现的。因此，如果你有一个使用PSGI的Web应用程序，它很可能已经在Nginx后面进行了测试和运行。无需移植任何东西。PSGI可能是升级CGI或`mod_perl`应用程序的最重要的目标架构。
- en: Bigger Perl web frameworks usually have a number of ways to run the applications.
    For example, both Dancer and the older Catalyst provide the glue scripts to run
    the same application as a separate web server (which you might expose to the world
    with the help of the Nginx `ngx_proxy` upstream), as a `mod_perl` application
    or even as a CGI script. Not all of those methods are suitable for production,
    but they will definitely help in migration. Never accept "we should rewrite everything
    from scratch" as a recommendation from the developers before weighing other options.
    If the application was written during the last 3–4 years, it should definitely
    have PSGI implemented directly or via its framework.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 较大的Perl Web框架通常提供多种方式来运行应用程序。例如，Dancer和较早的Catalyst都提供了将同一个应用程序作为独立Web服务器运行的连接脚本（你可以借助Nginx的`ngx_proxy`上游将其暴露给外部），也可以作为`mod_perl`应用程序，甚至作为CGI脚本运行。并非所有这些方法都适合生产环境，但它们肯定会在迁移过程中有所帮助。在权衡其他选择之前，永远不要接受开发者的“我们应该从头重写所有内容”这一建议。如果应用程序是在过去3至4年内编写的，它应该直接或通过其框架实现了PSGI。
- en: PSGI applications are run with the help of special PSGI servers, such as Starman
    or Starlet, that speak simple HTTP to the outside world. Nginx will use the `ngx_proxy`
    upstream for such applications.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: PSGI应用程序通过特殊的PSGI服务器运行，如Starman或Starlet，这些服务器对外使用简单的HTTP协议。Nginx将使用`ngx_proxy`上游来处理这些应用程序。
- en: Using thread pools in Nginx
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Nginx中使用线程池
- en: Using asynchronous, event-driven architecture serves Nginx well as it allows
    to save up on the precious RAM and CPU context switches while processing thousands
    and millions of slow clients in separate connections. Unfortunately, event loops,
    such as the one that power Nginx, easily fail when facing blocking operations.
    Nginx was born on FreeBSD, which has several advantages over Linux, and one of
    the relevant ones is a robust, asynchronous input/output implementation. Basically,
    the OS kernel is able to not block on traditionally blocking operations like reading
    data from disks by having its own kernel-level background threads. Linux, on the
    other hand, requires more work from the application side, and very recently, in
    version 1.7.11, the Nginx team released its own thread pools feature to work better
    on Linux. You may find a good introduction into the problem and the solution in
    this official Nginx blog post at [https://www.nginx.com/blog/thread-pools-boost-performance-9x/](https://www.nginx.com/blog/thread-pools-boost-performance-9x/).
    We will provide an example of the configuration you may use to turn on thread
    pools on your web server. Remember that you will only need this on Linux.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 使用异步事件驱动架构非常适合 Nginx，因为它可以在处理成千上万、甚至数百万个慢速客户端的独立连接时节省宝贵的内存和 CPU 上下文切换。不幸的是，像
    Nginx 这样的事件循环，在面对阻塞操作时很容易失败。Nginx 最初诞生于 FreeBSD，它相对于 Linux 有几个优势，其中之一就是强大的异步输入/输出实现。基本上，操作系统内核通过拥有自己的内核级后台线程，能够避免在传统的阻塞操作（如从磁盘读取数据）上发生阻塞。而
    Linux 需要更多来自应用程序的工作，最近在版本 1.7.11 中，Nginx 团队发布了自己的线程池功能，以便更好地在 Linux 上运行。你可以在这篇官方
    Nginx 博客文章中找到问题和解决方案的详细介绍：[https://www.nginx.com/blog/thread-pools-boost-performance-9x/](https://www.nginx.com/blog/thread-pools-boost-performance-9x/)。我们将提供一个你可以在
    Web 服务器上启用线程池的配置示例。记住，只有在 Linux 上你才需要这个功能。
- en: 'To turn on background threads that will perform blocking input/output operations
    without stalling the main loop you use the directive `aio` in this way:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了启用后台线程，这些线程将在不阻塞主事件循环的情况下执行阻塞的输入/输出操作，你可以这样使用 `aio` 指令：
- en: '[PRE0]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: You may know the `aio` directive that is used to turn on the Async IO interface,
    so it is a natural fit for its use to be extended this way.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能知道 `aio` 指令，它用来启用异步 I/O 接口，因此它的使用扩展成这样是非常自然的。
- en: The implementation is rather simple to explain from a very high level. Transparently
    to you, Nginx will run a number (pool) of background, userland-level threads that
    fulfill the input/output tasks. Nginx will continue to run the main event loop
    in parallel to waiting for the slow disk or the network.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 从一个非常高的层面来看，Nginx 的实现非常简单易懂。对你来说，Nginx 会运行一组后台的、用户级的线程来完成输入/输出任务，而主事件循环则会继续运行，并等待慢速磁盘或网络。
- en: The caching layer of Nginx
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Nginx 的缓存层
- en: If there is one universally known and acclaimed algorithm to speed things up,
    it is caching. Pragmatically speaking, caching is a process of not doing the same
    work many times. Ideally, each distinct computational unit should be executed
    once. This, of course, never happens in the real world. Still, techniques to minimize
    repetitions by rearranging work or using saved results are very popular. They
    form a huge discipline named "dynamic programming."
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有一种被普遍认可并推崇的加速算法，那就是缓存。实用来说，缓存是一个避免多次重复做相同工作过程。理想情况下，每个独立的计算单元应该只执行一次。当然，这在现实世界中从未发生过。不过，通过重新安排工作或使用已保存的结果来减少重复的技术是非常流行的，它们形成了一个庞大的学科，名为“动态规划”。
- en: In the context of a web server, caching usually means saving the generated response
    in a file so that the next time when the same request is received; it could be
    processed by reading this file and not computing the response again. Now please
    refer to the steps outlined in the first section of this chapter. For many of
    the real-world websites, the actual computing of the responses is not the bottleneck;
    transferring those responses to the slow clients is. That's why the most efficient
    caching happens right in the browser, or as developers prefer to say, on the client
    side.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Web 服务器的上下文中，缓存通常意味着将生成的响应保存在文件中，这样下次收到相同请求时，就可以通过读取该文件来处理，而不需要再次计算响应。现在请参考本章第一部分概述的步骤。对于许多实际的网页，响应的实际计算并不是瓶颈；将这些响应传输到慢速客户端才是瓶颈。这就是为什么最有效的缓存通常发生在浏览器端，或者开发者更喜欢说的，是在客户端。
- en: Emitting caching headers
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 发出缓存头
- en: All browsers (and even many non-browser HTTP clients) support client-side caching.
    It is a part of the HTTP standards, albeit one of the most complex to understand.
    Web servers do not control client-side caching to full extent, obviously, but
    they may issue recommendations about what to cache and how, in the form of special
    HTTP response headers. This is a topic thoroughly discussed in many great articles
    and guides, so we will mention it shortly, and with a lean towards problems you
    may face and how to troubleshoot them.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 所有浏览器（甚至许多非浏览器的HTTP客户端）都支持客户端缓存。它是HTTP标准的一部分，尽管它是最复杂的部分之一。显然，Web服务器不能完全控制客户端缓存，但它们可以通过特殊的HTTP响应头以推荐的方式告诉客户端缓存什么以及如何缓存。这是一个在许多优秀文章和指南中深入讨论的话题，因此我们将在此简要提及，重点是您可能面临的问题以及如何进行故障排除。
- en: In spite of the fact that browsers have been supporting caching on their side
    for at least 20 years, configuring cache headers was always a little confusing,
    mostly due to the fact that there are two sets of headers designed for the same
    purpose, but having different scopes and totally different formats.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管浏览器至少在过去20年里就已支持客户端缓存，但配置缓存头总是有些令人困惑，主要是因为有两套为相同目的设计的头部，它们的作用范围不同，格式也完全不同。
- en: There is the `Expires:` header, which was designed as a quick and dirty solution
    and also the new (relatively) almost omnipotent `Cache-Control:` header, which
    tries to support all the different ways an HTTP cache could work.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个`Expires:`头，它被设计为一个快速且粗糙的解决方案，还有一个新的（相对来说）几乎全能的`Cache-Control:`头，它试图支持所有可能的HTTP缓存工作方式。
- en: 'This is an example of a modern HTTP request-response pair containing the caching
    headers. These are the request headers sent from the browser (here Firefox 41,
    but it does not matter):'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个现代HTTP请求-响应对的示例，包含了缓存头。这些是从浏览器（此处为Firefox 41，但版本无关紧要）发送的请求头：
- en: '[PRE1]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Then, the response headers are:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，响应头为：
- en: '[PRE2]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We highlighted the parts that are relevant. Note that some directives may be
    sent by both sides of the conversation. The browser sent the `Cache-Control: max-age=0`
    header because the user pressed the *F5* key. This is an indication that the user
    wants to receive a response that is fresh. Normally, the request will not contain
    this header and will allow any intermediate cache to respond with a stale but
    still nonexpired response.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '我们已经突出了相关部分。请注意，某些指令可能由对话的双方发送。浏览器发送了`Cache-Control: max-age=0`头，因为用户按下了*F5*键。这表示用户希望接收一个新的响应。通常，请求不会包含此头，而是允许任何中间缓存返回一个过时但尚未过期的响应。'
- en: In this case, the server we talked to responded with a gzipped HTML page encoded
    in UTF-8 and indicated that the response is okay to use for half an hour. It used
    both mechanisms available, the modern `Cache-Control:max-age=1800` header and
    the very old `Expires:Sun, 10 Oct 2015 14:12:34 GMT` header.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们与之交互的服务器返回了一个经过gzip压缩并采用UTF-8编码的HTML页面，并指出该响应可以使用半小时。它使用了两种可用的机制，现代的`Cache-Control:max-age=1800`头和非常老旧的`Expires:Sun,
    10 Oct 2015 14:12:34 GMT`头。
- en: 'The `X-Cache: "EXPIRED"` header is not a standard HTTP header, but was also
    probably (there is no way to know for sure from the outside) emitted by Nginx.
    It may be an indication that there are, indeed, intermediate caching proxies between
    the client and the server, and one of them added this header for debugging purposes.
    The header may also show that the backend software uses some internal caching.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '`X-Cache: "EXPIRED"`头不是一个标准的HTTP头，但很可能（无法从外部确认）由Nginx发出的。它可能表示客户端和服务器之间确实有中间缓存代理，其中之一为调试目的添加了此头。该头也可能表明后端软件使用了某些内部缓存。'
- en: 'Another possible source of this header is a debugging technique used to find
    problems in the Nginx cache configuration. The idea is to use the cache hit or
    miss status, which is available in one of the handy internal Nginx variables as
    a value for an extra header, and then you are able to monitor the status from
    the client side. This is the code that will add such a header:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个可能的来源是用于调试技术，帮助找出Nginx缓存配置中的问题。其思路是使用缓存命中或未命中的状态，这些状态可以通过Nginx内部的某些变量获取，作为额外头的一部分，然后您可以从客户端监控这一状态。这段代码将添加这样一个头：
- en: '[PRE3]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Nginx has a special directive that transparently sets up both standard cache
    control headers, and it is named `expires`. This is a piece of the `nginx.conf`
    file using the `expires` directive:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Nginx有一个特殊的指令，可以透明地设置标准的缓存控制头，它的名称是`expires`。这是使用`expires`指令的`nginx.conf`文件的一部分：
- en: '[PRE4]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The pattern uses the so-called noncapturing parentheses, which is a feature
    first appeared in Perl regular expressions. The effect of this regexp is the same
    as that of a simpler `\.(css|js)$` pattern, but the regular expression engine
    is specifically instructed not to create a variable containing the actual string
    from inside the parentheses. This is a simple optimization.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 该模式使用了所谓的非捕获括号，这是 Perl 正则表达式中首次出现的特性。这个正则表达式的效果与更简单的 `\.(css|js)$` 模式相同，但正则表达式引擎被特别指示不创建包含括号内实际字符串的变量。这是一个简单的优化。
- en: 'Then, the `expires` directive declares that the content of the `css` and `js`
    files will expire after a year of storage. The actual headers as received by the
    client will look like this:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，`expires` 指令声明 `css` 和 `js` 文件的内容将在存储一年后过期。客户端接收到的实际头部将如下所示：
- en: '[PRE5]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The last two lines contain the same information in wildly different forms. The
    `Expires:` header is exactly one year after the date in the `Date:` header, whereas
    `Cache-Control:` specifies the age in seconds so that the client can do the date
    arithmetics itself.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的两行包含相同的信息，但形式上大相径庭。`Expires:` 头的时间是 `Date:` 头时间的恰好一年后，而 `Cache-Control:`
    则指定了以秒为单位的年龄，这样客户端就可以自行进行日期运算。
- en: 'The last directive in the provided configuration extract adds another `Cache-Control:`
    header with a value of `public`. What this means is that the content of the HTTP
    resource is not access-controlled and therefore may be cached not only for one
    particular user but also anywhere else. A simple and effective strategy that was
    used in offices to minimize consumed bandwidth was to have an office-wide caching
    proxy server. When one user requested a resource from a website on the Internet
    and that resource had a `Cache-Control: public` designation, the company cache
    server would store that to serve to other users on the office network.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '提供的配置片段中的最后一个指令添加了另一个 `Cache-Control:` 头部，值为 `public`。这意味着 HTTP 资源的内容没有访问控制，因此不仅可以为特定用户缓存，还可以在其他地方缓存。这是一种简单且有效的策略，在办公室中广泛使用，以最小化带宽消耗：设立一个办公室范围的缓存代理服务器。当一个用户请求一个来自互联网的资源并且该资源有
    `Cache-Control: public` 标记时，公司缓存服务器将会存储该资源，以便其他用户在办公室网络中使用。'
- en: 'This may not be as popular today due to cheap bandwidth, but because history
    has a tendency to repeat itself, you need to know how and why `Cache-Control:
    public` works.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '今天，由于廉价带宽的普及，这种做法可能不再那么流行，但由于历史往往会重演，你需要了解 `Cache-Control: public` 是如何以及为何起作用的。'
- en: 'The Nginx `expires` directive is surprisingly expressive. It may take a number
    of different values. See this table:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Nginx 的 `expires` 指令出奇地表达力强。它可以接受多种不同的值。请参阅此表：
- en: '| `off` | This value turns off the Nginx cache headers logic. Nothing will
    be added, and more importantly, the existing headers received from upstreams will
    not be modified. |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| `off` | 该值关闭 Nginx 缓存头部逻辑。不会添加任何内容，更重要的是，来自上游的现有头部将不会被修改。|'
- en: '| `epoch` | This is an artificial value used to purge a stored resource from
    all caches by setting the `Expires` header to **"1 January, 1970 00:00:01 GMT"**.
    |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| `epoch` | 这是一个人为的值，用于通过将 `Expires` 头设置为 **"1970年1月1日 00:00:01 GMT"** 来从所有缓存中清除存储的资源。|'
- en: '| `max` | This is the opposite of the "epoch" value. The **Expires** header
    will be equal to **"31 December 2037 23:59:59 GMT"**, and the **Cache-Control
    max-age** set to 10 years. This basically means that the HTTP responses are guaranteed
    to never change, so clients are free to never request the same thing twice and
    may use their own stored values. |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| `max` | 这是“epoch”值的相反。**Expires** 头将设置为 **"2037年12月31日 23:59:59 GMT"**，并且
    **Cache-Control max-age** 设置为 10 年。这基本上意味着 HTTP 响应保证永远不会改变，因此客户端可以自由地不再请求相同的内容，并可以使用其自己存储的值。|'
- en: '| Specific duration | An actual specific duration value means an expiry deadline
    from the time of the respective request. For example, `expires 10w`. A negative
    value for this directive will emit a special header `Cache-Control: no-cache`.
    |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 特定持续时间 | 实际的特定持续时间值意味着从相关请求时间起的到期时间。例如，`expires 10w`。该指令的负值会发出一个特殊的头部 `Cache-Control:
    no-cache`。|'
- en: '| `"modified" specific time` | If you add the keyword "modified" before the
    time value, then the expiration moment will be computed relatively to the modification
    time of the file that is served. |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| `"modified" 特定时间` | 如果在时间值之前添加关键字 "modified"，则过期时间将相对于提供文件的修改时间来计算。|'
- en: '| `"@" specific time` | A time with an @ prefix specifies an absolute time-of-day
    expiry. This should be less than 24 hours. For example, Expires @17h;. |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| `"@" 具体时间` | 带有 @ 前缀的时间指定的是绝对的时间到期。这应该少于 24 小时。例如，Expires @17h;。'
- en: Many web applications choose to emit the caching headers themselves, and this
    is a good thing. They have more information about which resources change often
    and which never change. Tampering with the headers that you receive from the upstream
    may or may not be a thing you want to do. Sometimes, adding headers to a response
    while proxying it may produce a conflicting set of headers and therefore create
    unpredictable behavior.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 许多 Web 应用程序选择自行发出缓存头部，这是件好事。它们对哪些资源经常变化、哪些资源永不变化有更多的了解。篡改你从上游收到的头部可能是你希望做的事，也可能不是。有时，在代理响应时添加头部可能会产生冲突的头部集合，从而导致不可预测的行为。
- en: The static files that you serve with Nginx should have the `expires` directive
    in place. However, the general advice about upstreams is to always examine the
    caching headers you get and refrain from overoptimizing by setting up a more aggressive
    caching policy.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 你通过 Nginx 提供的静态文件应该设置 `expires` 指令。然而，关于上游的普遍建议是，始终检查你收到的缓存头部，并避免通过设置更激进的缓存策略来进行过度优化。
- en: The corporate caching proxy configuration that we described earlier in this
    chapter together with an erroneous `public` caching policy on nonpublic resources
    may result in a situation where some users will see pages that were generated
    for other users behind the same caching proxy. The way to make that happen is
    surprisingly easy. Imagine that your client is a book shop. Their web application
    serves both public pages with book details, cover images, and so on and private
    resources with recommendation pages and the shopping cart. Those will probably
    have the same URL for all users and once, by mistake, declared as `public` with
    the expiration date in the distant future, they may freely be cached by intermediate
    proxies. Some more intelligent proxies will automatically notice cookies and either
    add them to the cache key or refrain from caching. But then again, less sophisticated
    proxies do exist, and there are a number of reports when they do show pages that
    belong to other people.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章前面描述的企业缓存代理配置，再加上对非公开资源错误的`public`缓存策略，可能会导致某些用户看到为其他用户生成的页面，这些页面通过相同的缓存代理缓存。使这种情况发生的方式出奇的简单。假设你的客户是一个书店，他们的
    Web 应用程序既提供包含书籍详情、封面图片等的公共页面，也提供包含推荐页面和购物车等的私人资源。它们可能会有相同的 URL，且一旦由于错误被声明为`public`并设置了很远未来的过期时间，它们可能会被中间代理自由缓存。一些更智能的代理会自动注意到
    cookies，并将其添加到缓存键中，或者避免缓存。但也存在一些不那么智能的代理，因此有不少报告显示它们会展示属于其他用户的页面。
- en: There are even techniques such as adding a random number to all URLs to defeat
    such caching configurations by making all URLs unique.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 甚至有技术方法，比如给所有 URL 添加随机数，通过让所有 URL 唯一来击败这样的缓存配置。
- en: We would also like to describe a combination of unique URLs and long expiration
    dates, which are widely used today. Modern websites are very dynamic, both in
    the sense of what happens to the document after it is loaded and how often the
    client-side code changes. It is not unusual to have not only daily but even hourly
    releases. This is a luxury of the web as an application delivery mechanism, and
    people seize the opportunity. How to combine rapid releases with caching? The
    first idea was to code the version into the URLs. It works surprisingly well.
    After each release, all the URLs change; the old ones start to slowly expire in
    the cache stores of different levels, whereas the new ones are requested directly
    from the origin server.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还想描述一种当前广泛使用的独特 URL 和长过期时间的组合。现代网站非常动态，既体现在文档加载后发生的变化，也体现在客户端代码的更新频率上。每天甚至每小时发布的情况并不罕见。这是
    Web 作为应用程序交付机制的奢侈之处，人们正在抓住这一机会。那么，如何将快速发布与缓存结合起来呢？最初的想法是将版本编码到 URL 中。这种方法出奇地有效。每次发布后，所有的
    URL 都会变化；旧的 URL 会开始在不同层级的缓存存储中慢慢过期，而新的 URL 会直接从源服务器请求。
- en: One clever trick was developed upon this scheme, and it uses a hash of the content
    of the resource instead of the version number as a unique element of the URL.
    This reduces extra cache misses when a new release does not change all the files.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这个方案，开发了一种聪明的技巧，它使用资源内容的哈希值而不是版本号作为 URL 的唯一元素。这样可以减少在新版本发布时，某些文件未更改而导致的额外缓存失效。
- en: Implementing this trick is done on the application side. Nginx administrator
    is only responsible for setting up long expiration date by using, for example,
    the `expires max` directive.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 实现这个技巧是在应用层进行的。Nginx 管理员只需负责通过使用 `expires max` 指令等方式设置长时间的过期日期。
- en: The one obvious thing that limits the effect of the client-side caching is that
    many different users may issue the same or similar requests, and those will all
    reach the web server. The next step to never doing the same work many times is
    caching on the server.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 限制客户端缓存效果的一个显而易见的因素是，许多不同的用户可能会发出相同或类似的请求，这些请求都会到达 Web 服务器。避免重复劳动的下一步是服务器端的缓存。
- en: Caching in Nginx upstream modules
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Nginx 上游模块中的缓存
- en: Caching infrastructure is implemented as a part of the upstream interface if
    you excuse us to use object-oriented programming terminology. Each of those upstream
    modules has a group of very similar directives, which allow you to configure the
    local caching of responses from that particular upstream.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存基础设施作为上游接口的一部分来实现，如果你允许我们使用面向对象编程的术语的话。每一个上游模块都有一组非常相似的指令，这些指令允许你配置该特定上游的响应本地缓存。
- en: The basic scheme is very simple—once a request is determined as an upstream
    material, it is rerouted to the relevant module. If there's caching configured
    for that upstream, the cache is first searched for an existing response to this
    request. Only when a cached response is not found, the actual proxying is performed.
    After this, the newly generated response is saved into the cache while being sent
    to the client.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 基本的工作原理非常简单——一旦一个请求被确定为上游请求，它就会被重定向到相关模块。如果该上游模块已配置缓存，首先会检查缓存中是否有此请求的响应。如果缓存中没有找到响应，才会执行实际的代理操作。之后，生成的新的响应会在发送给客户端时保存到缓存中。
- en: It is interesting that while caching on the reverse proxy is known for a while,
    Nginx gained its fame as a magical accelerator without implementing it. The reason
    should be evident from the first section—radical changes in RAM consumption alone
    brought a lot of performance gains. Until the introduction of version 0.7.44,
    Nginx did not have any caching facilities built in. At that time, web administrators
    used either the famous squid HTTP proxy for caching or the `mod_accel` module
    for Apache. By the way, `mod_accel` module was created by Nginx's author Igor
    Sysoev and turned out to be the testbed for all the ideas about proper reverse
    proxying that were later implemented in Nginx.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，虽然反向代理上的缓存已经被知道了一段时间，但 Nginx 却因其作为一个神奇的加速器而声名鹊起，而并没有实现这一点。原因应该从第一部分中就能看出——仅仅是
    RAM 消耗的根本性变化，就带来了大量的性能提升。直到 0.7.44 版本的发布，Nginx 才内置了任何缓存功能。在那时，网站管理员要么使用著名的 squid
    HTTP 代理来进行缓存，要么使用 Apache 的 `mod_accel` 模块。顺便提一下，`mod_accel` 模块是由 Nginx 的作者 Igor
    Sysoev 创建的，并且最终成为了所有关于正确反向代理思想的试验平台，这些思想后来在 Nginx 中得到了实现。
- en: Let us examine the caching directives of the most popular upstream module, `ngx_proxy`.
    Just to remind, this module hands over the request to another HTTP server. This
    is exactly how Nginx is run as a reverse proxy in front of Apache, for example.
    The full description is available in the great Nginx documentation at [http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache](http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache).
    We won't repeat the documentation, but we will provide additional facts and ideas
    instead.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下最流行的上游模块 `ngx_proxy` 的缓存指令。提醒一下，这个模块将请求转发到另一个 HTTP 服务器。这正是 Nginx 作为反向代理位于
    Apache 前面时的工作方式。完整的描述可以在优秀的 Nginx 文档中找到，网址是 [http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache](http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache)。我们不会重复文档内容，而是提供一些额外的事实和想法。
- en: '| Directive | Additional information |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 指令 | 附加信息 |'
- en: '| --- | --- |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `proxy_cache_path` | This directive is clearly the main one of the whole
    caching family. It specifies the storage parameters of the cache store starting
    with the path on the filesystem. You should definitely familiarize yourself with
    all the options. The most important are the `inactive` and `max_size` options,
    which control how the Nginx cache manager removes unused data from the cache store.
    One required parameter in this directive is the `keys_zone`, which links the cache
    store to the "zone". See in the later text. |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| `proxy_cache_path` | 该指令显然是整个缓存系列中的主要指令。它指定了缓存存储的路径参数，从文件系统中的路径开始。您应当熟悉所有选项。最重要的选项是`inactive`和`max_size`，它们控制Nginx缓存管理器如何从缓存存储中删除未使用的数据。此指令中的一个必需参数是`keys_zone`，它将缓存存储与“zone”关联。详情见后文。
    |'
- en: '| `proxy_cache` | This is the main switch directive. It is required if you
    want any caching. It has a single somewhat cryptic parameter named "zone," which
    will be explained in detail further on. The value "off" will switch the caching
    off. It may be needed in cases when there is a `proxy_cache` directive further
    up the scope stack. |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| `proxy_cache` | 这是主开关指令。如果您希望启用缓存，它是必需的。它有一个稍显晦涩的参数，名为“zone”，稍后会详细解释。“off”值将禁用缓存。当在作用域栈上方有`proxy_cache`指令时，可能需要使用此指令。
    |'
- en: '| `proxy_cache_bypass` | This directive allows you to easily specify conditions
    on which some responses will never be cached. |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| `proxy_cache_bypass` | 该指令允许您轻松指定一些响应永远不被缓存的条件。 |'
- en: '| `proxy_cache_key` | This directive creates a key that is used to identify
    objects in the cache. By default, the URL is used, but people add things to it
    quite commonly. Different responses should never have equal keys. Anything that
    may change the content of the page should be in the key. Besides obvious cookie
    values, you may want to add the client IP address if your pages depend on it (for
    example, use some form of geotargeting via the GeoIP database). |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| `proxy_cache_key` | 该指令创建一个用于识别缓存中对象的键。默认情况下，使用的是URL，但人们通常会添加一些其他内容。不同的响应不应拥有相同的键。任何可能改变页面内容的内容都应该包含在键中。除了明显的Cookie值，您还可能希望在键中添加客户端IP地址，如果您的页面依赖于此（例如，通过GeoIP数据库进行地理定位）。
    |'
- en: '| `proxy_cache_lock` | This is a binary on/off switch defaulting to off. If
    you turn it on, then simultaneous requests for the same ("same" here means "having
    the same cache key") resource will not be run in parallel. Only the first request
    will be executed while the rest are blocked waiting.The `proxy_cache_lock_*` family
    of directives might be interesting when you have some very expensive responses
    to generate. |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| `proxy_cache_lock` | 这是一个开/关的二进制开关，默认为关闭。如果开启它，那么对相同（这里的“相同”是指“具有相同缓存键”）资源的并发请求将不会并行执行。只有第一个请求会被执行，其他请求会被阻塞并等待。`proxy_cache_lock_*`系列指令在生成一些非常耗费资源的响应时可能会很有用。
    |'
- en: '| `proxy_cache_lock_age``proxy_cache_lock_timeout` | These two specify additional
    lock parameters. Refer to the documentation for details. |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| `proxy_cache_lock_age``proxy_cache_lock_timeout` | 这两个指令指定了额外的锁定参数。详情请参考文档。
    |'
- en: '| `proxy_cache_methods` | This is a list of HTTP methods that are cacheable.
    Besides the obvious "GET" and "HEAD" methods, you might want to sometimes cache
    less popular methods such as "OPTIONS" or "PROPFIND" from WebDAV. There might
    be cases when you want to cache responses even to "POST", "PUT," and "DELETE"
    although that would be a very serious bending of the rules and you should really
    know what you are doing. |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| `proxy_cache_methods` | 这是一个可缓存的HTTP方法列表。除了明显的“GET”和“HEAD”方法外，您有时可能希望缓存一些不太常用的方法，如WebDAV中的“OPTIONS”或“PROPFIND”。在某些情况下，您可能希望缓存对“POST”，“PUT”和“DELETE”的响应，尽管那将是对规则的严重弯曲，您需要非常清楚自己在做什么。
    |'
- en: '| `proxy_cache_min_uses` | This numeric parameter with a default value of "1"
    may be useful to optimize huge cache stores by not caching responses to rare requests.
    Remember that the effective cache is not the one that stores more but the one
    that stores useful things that get requested again and again. |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| `proxy_cache_min_uses` | 这个数字参数的默认值为“1”，在优化庞大的缓存存储时可能会有用，它可以避免缓存稀有请求的响应。记住，真正有效的缓存不是存储更多内容的缓存，而是存储那些被反复请求的有用内容。
    |'
- en: '| `proxy_cache_purge` | This directive specifies the additional conditions
    on which objects are deleted from the cache store before expiration. It may be
    used as a way to forcefully invalidate a cache entry. A good cache key design
    should not require invalidation, but we all know how often good designs of anything
    happen in real life. |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| `proxy_cache_purge` | 此指令指定了在对象过期之前从缓存存储中删除对象的额外条件。它可以作为强制使缓存条目无效的方式。一个好的缓存键设计应该不需要使其无效，但我们都知道在现实生活中，好的设计有时是多么罕见。
    |'
- en: '| `proxy_cache_revalidate` | This is also a Boolean directive. HTTP conditional
    requests with headers "If-None-Match" or "If-Modified-Since" may update the validity
    of objects in the cache even if they do not return any new content to the requesting
    client. For this, specify "on". |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| `proxy_cache_revalidate` | 这也是一个布尔值指令。带有“If-None-Match”或“If-Modified-Since”头的
    HTTP 条件请求即使没有返回任何新内容，也可以更新缓存中对象的有效性。如果需要这样做，请指定“on”。 |'
- en: '| `proxy_cache_use_stale` | This is an interesting directive that sometimes
    allows responding with an expired response from the cache. The main case to do
    this is an upstream failure. Sometimes, responding with a stale content is better
    than rejecting the request on the basis of the famous "Internal server error".
    From the user''s point of view, this is very often the case. |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| `proxy_cache_use_stale` | 这是一个有趣的指令，它有时允许用缓存中的过期响应来回应请求。这样做的主要情况是上游失败。有时，返回过期内容比基于著名的“内部服务器错误”拒绝请求要好。从用户的角度来看，这种情况非常常见。
    |'
- en: '| `proxy_cache_valid` | This is a very rough cache expiration specification.
    Usually, you should control the validity of the cached data via response headers.
    However, if you need something quick or something broad, this directive will help
    you. |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| `proxy_cache_valid` | 这是一个非常粗略的缓存过期规范。通常，您应该通过响应头来控制缓存数据的有效性。但是，如果你需要一些快速或广泛的设置，这个指令会帮助你。
    |'
- en: One very important concept that is used in caching subsystems throughout all
    the upstream modules is that of the cache zone. A zone is a named memory region,
    which is accessible by its name from all Nginx processes. Readers familiar with
    the concept of System V-shared memory or IPC via mmap-ed regions will instantly
    see the similarity. Zones were chosen as an abstraction for the cache state storage,
    which should be shared between all the worker processes. You may configure many
    caches inside your Nginx instance, but you will always specify a zone for each
    cache. You may link different caches to the same zone, and the information about
    the cached objects will be shared. Zones also act as objects encapsulating the
    actual cache storage configuration such as where on the filesystem the cached
    objects will persist, how the storage hierarchy will be organized, when to purge
    the expired objects, and how to load the objects from disk into memory on restart.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有上游模块中使用的一个非常重要的概念是缓存子系统中的缓存区域。一个区域是一个命名的内存区域，可以通过名称从所有 Nginx 进程中访问。熟悉 System
    V 共享内存或通过 mmap 映射区域进行 IPC 的读者将立刻看出其中的相似性。选择区域作为缓存状态存储的抽象层，因为它应该在所有工作进程之间共享。你可以在
    Nginx 实例中配置多个缓存，但你始终需要为每个缓存指定一个区域。你可以将不同的缓存链接到同一个区域，关于缓存对象的信息将会被共享。区域还充当封装实际缓存存储配置的对象，配置内容包括缓存对象将在文件系统中的何处持久化，存储层次结构如何组织，何时清除过期对象，以及如何在重启时从磁盘加载对象到内存中。
- en: To summarize, an administrator first sets up at least one zone with all the
    relevant storage parameters with the directive `*_cache_path` and then plugs subtrees
    of the whole URL space into those zones with the directive `*_cache`.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，管理员首先使用指令`*_cache_path`设置至少一个包含所有相关存储参数的区域，然后通过指令`*_cache`将整个 URL 空间的子树连接到这些区域。
- en: Zones are set up globally, usually in the `http` scope while individual caches
    are linked to zones with the simple `*_cache` directive in the relevant contexts,
    for example, locations down the path tree or the whole server blocks.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 区域通常在全局范围内设置，通常在 `http` 范围内，而单个缓存则通过相关上下文中的简单 `*_cache` 指令链接到区域，例如，路径树下的定位或整个服务器块。
- en: We should remind you that the described caching subsystem directives' family
    exists for all the upstream modules of Nginx. You will substitute `proxy_` for
    the other upstream moniker to end up with a whole other family of directives that
    do exactly the same, maybe with some slight variations for responses generated
    by upstreams of another type. For example, here for the information on how to
    cache FastCGI responses at [http://nginx.org/en/docs/http/ngx_http_fastcgi_module.html#fastcgi_cache](http://nginx.org/en/docs/http/ngx_http_fastcgi_module.html#fastcgi_cache).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要提醒你，所描述的缓存子系统指令家族适用于所有 Nginx 的上游模块。你将用 `proxy_` 替换其他上游标识符，从而得到另一个完全相同的指令家族，可能会对不同类型上游生成的响应有些许变化。例如，关于如何缓存
    FastCGI 响应的详细信息可以参考[http://nginx.org/en/docs/http/ngx_http_fastcgi_module.html#fastcgi_cache](http://nginx.org/en/docs/http/ngx_http_fastcgi_module.html#fastcgi_cache)。
- en: 'Let us provide some real-world caching configuration examples that will help
    you grasp the idea better:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们提供一些现实世界的缓存配置示例，帮助你更好地理解这个概念：
- en: '[PRE6]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This is a canonically simple cache configuration with one zone named `cache1`
    and one cache configured under location `/` in one server. Several important details
    are worth mentioning. The temporary files directory configured with the `proxy_temp_path`
    directive is highly recommended to be on the same filesystem as the main cache
    storage because otherwise, Nginx will not be able to quickly move files between
    the temporary and permanent storage and will instead perform an expensive file
    copy operation.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个规范的简单缓存配置，包含一个名为 `cache1` 的区域和在一个服务器中的 `/` 路径下配置的缓存。值得提到几个重要细节。使用 `proxy_temp_path`
    指令配置的临时文件目录，强烈建议与主缓存存储在同一文件系统上，否则，Nginx 将无法快速地在临时存储和永久存储之间移动文件，而是会执行耗费资源的文件复制操作。
- en: The `key_zone` size specifies the amount of memory dedicated to the zone. This
    memory is used to store the keys and metainformation about the objects in the
    cache and not the actual cached responses (objects). The limit on the object storage
    is specified in the `max_size` parameter. Nginx spawns a separate process named
    `cache manager`, which will constantly scan all the cache zones and remove the
    least used objects when the `max_size` is exceeded.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '`key_zone` 大小指定了分配给该区域的内存量。此内存用于存储缓存中对象的键及元数据信息，而不是实际的缓存响应（对象）。对象存储的限制由 `max_size`
    参数指定。Nginx 会启动一个名为 `cache manager` 的独立进程，该进程会不断扫描所有缓存区域，当 `max_size` 超过时，删除最少使用的对象。'
- en: The `proxy_cache_valid` directive combination specifies a much shorter period
    of validity for the negative 404 results. The idea behind it is that 404 might
    actually be fixed, at least some of them may appear due to some misconfiguration.
    It makes sense to retry such requests more frequently. You should also consider
    the load on the upstream when making decisions about validity periods. Many computationally
    heavy search algorithms require much more resources to give a negative answer.
    It is quite understandable that to make sure that a looked for entity is absent
    may require checking everywhere instead of stopping after the first found instance.
    This is a very simplified description of a search algorithm, but it is short enough
    so that you will remember to always check the request processing time in the logs
    for negative responses and their relative amount before shortening the cache validity
    interval.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '`proxy_cache_valid` 指令组合指定了负面 404 结果的更短有效期。其背后的理念是，404 错误实际上可能被修复，至少其中一些可能由于配置错误而出现。因此，频繁地重试这些请求是有意义的。在决定有效期时，你还应考虑上游的负载。许多计算密集型的搜索算法需要更多资源来给出负面答案。为了确保查找的实体不存在，可能需要在所有地方进行检查，而不仅仅是在找到第一个实例后就停止。虽然这是对搜索算法的简化描述，但它足够简短，你应该记得在缩短缓存有效期之前，始终检查日志中负面响应的请求处理时间及其相对数量。'
- en: Two important parameters of the cache are left out in the above configuration,
    and this means that you will fly with default values. The `proxy_cache_methods`
    defaults to only caching GET and HEAD requests, which may not be optimal for your
    web application. And `proxy_cache_key` defaults to `$scheme$proxy_host$request_uri,`
    which may be dangerous if your web application make similar requests for different
    users. Read about these directives and either add uniqueness to the key or fall
    back to uncached behavior via `proxy_cache_bypass`.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Another example that we would like to present is much more complex. Let us devote
    a separate section to it.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: Caching static files
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When scaling a website horizontally, you will inevitably find yourself in the
    situation of having many identical Nginx-powered servers behind a low-level balancer.
    All of them will proxy the requests to the same upstream server farm, and there
    will be no problems with synchronizing the active, dynamic content served by your
    website. But if you follow the advice about having all the static content present
    locally to allow Nginx to serve it in the most native and efficient way possible,
    you will end up with a task of having many identical copies of the same files
    everywhere.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: The other way to do the same task is a setup where a farm of Nginx instances
    is used to serve a huge library of static files, for example, video or music.
    Having a copy of that library on each Nginx node is out of the question because
    it is too big.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: As usual, there are many possible solutions for these two cases. One choice
    is having a secondary smaller farm of Nginx servers serving the files to the main
    farm, which will employ caching inside the `ngx_proxy` upstream.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: Another interesting solution uses a network filesystem mounted on the nodes.
    The traditional Unix NFS has a bad reputation, but in reality, on current Linux
    kernels, it is stable enough to be used in production. Two of the alternatives
    are AFS and SMBFS. The files under the mount point will look local to Nginx, but
    they will still be downloaded over the network, which is much slower than reading
    a good, local SSD. Luckily, modern Linux kernels have the ability to locally cache
    files from the NFS and AFS. It is named FS-Cache and uses a separate userland
    daemon, `cachefilesd`, to store local copies of files from a network filesystem.
    You may read about FS-Cache at [https://people.redhat.com/dhowells/fscache/FS-Cache.pdf](https://people.redhat.com/dhowells/fscache/FS-Cache.pdf).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: FS-Cache configuration is rather straightforward, and we will not focus on it.
    There is another way to do it, which follows the philosophy of Nginx much more
    closely. SlowFS is a third-party, upstream-like module for Nginx, which provides
    a simple interface to a filesystem subtree. The interface includes caching capabilities,
    which are standard to all other Nginx upstreams.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '**SlowFS** is open source under a very permissive license and is available
    either from the author''s website or directly from GitHub as a repository. Refer
    to [http://labs.frickle.com/nginx_ngx_slowfs_cache](http://labs.frickle.com/nginx_ngx_slowfs_cache).'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example SlowFS configuration:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This configuration installs a transparent caching layer over files available
    locally in `/var/www/nfs`. It does not matter how these files are actually stored,
    they still will be cached according to the parameters specified with the `slowfs_*`
    family of directives. But obviously, you will only note any speed-up if `/var/db/cache`
    is much faster than `/var/www/nfs`.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: Replacing external redirects with internal ones
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As modern frontend frameworks grow more and more complex, there is an alarming
    rise in the number of the so-called client-side redirects. Nginx has a great facility
    that will allow you to save some traffic and precious client waiting time on client
    redirects. First, let us briefly refresh your knowledge of those redirects.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: 'All the HTTP responses are documents consisting of three principal parts:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: 'There''s the HTTP code (200: Ok, 404: Not found, and so on)'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are a number of loosely structured key-value pairs in the form of headers
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is a relatively large, opaque, optional body
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is a lot of good HTTP response codes documentation on the Internet (and
    also some hilarious pieces given at [http://httpstatusdogs.com/](http://httpstatusdogs.com/))—the
    ones that are relevant to our discussion are in the fourth hundred, that is, between
    300 and 399.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: Responses with those codes are indications that a browser should immediately
    make another request instead of the original one. This is why they are called
    redirects. The semantic differences between various 3xx codes are less important
    here.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: What is important is that many redirects are superfluous. HTTP clients (for
    example, browsers) spend time on redirects that serve no particular reason besides
    cleaning up the URL in the address bar. Does Yahoo really need to redirect me
    from `yahoo.de` to `ru.yahoo.com`, `www.yahoo.com`, and [https://www.yahoo.com](https://www.yahoo.com)
    by making my browser issue three additional requests that could easily be avoided?
    If a website under your control does such things, you may address the question
    to the respective developers. You may also suggest an easy fix; see later in the
    text.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: There is a cool, little web service that allows you to see the redirects chain
    as well as some other metainformation that may be useful for debugging. It may
    be referred to at [https://httpstatus.io/](https://httpstatus.io/).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: You may go and check whether some of your websites make unneeded redirects,
    which may cost your slow mobile users' precious seconds before they actually get
    to the content of your site.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '![Replacing external redirects with internal ones](img/B04329_04_02.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
- en: Nginx has a feature named "internal redirects". The idea is that all the intermediate
    HTTP request-response pairs are processed right inside the server. The client
    gets the content from the end of the chain in response to the original request.
    There are a number of methods to enable internal redirects in Nginx, but probably
    the most flexible is the `X-Accel-Redirect` response header that an upstream behind
    Nginx may generate.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: For the internal redirects to work with this method, you will have to change
    the configuration of your upstream software. Instead of generating true redirects
    via HTTP 3xx response codes coupled with the `Location:` response header, you
    will have to generate the earlier-mentioned `X-Accel-Redirect:` header. This is
    literally the only change you will have to make. There are a number of places
    where you need to be careful; all of them concerning the security model of the
    browsers. The geographic redirects as shown with the Yahoo! example are actually
    quite rare nowadays, so optimizing them may not be worth the troubles you will
    get by issuing cookies on the wrong domain. But the `example.com` to `www.example.com`
    redirects are still very popular and look like perfect candidates for internal
    redirects.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed several approaches to finding performance problems
    in your Nginx installation. We mostly focused on working with legacy websites
    that you might have inherited and are optimizing. The reason for this is that
    Nginx in itself rarely has any specific problems with being fast enough.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: As an operations specialist, you increased your value for the business by gaining
    knowledge on how to speed up existing working websites having load and customers
    but based on some pre-Nginx technologies that were a limiting factor.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
