<html><head></head><body><div class="chapter" title="Chapter&#xA0;1.&#xA0;Instant Nginx Starter"><div class="titlepage"><div><div><h1 class="title"><a id="ch01"/>Chapter 1. Instant Nginx Starter</h1></div></div></div><p>Welcome to <span class="emphasis"><em>Instant Nginx Starter</em></span>. With this book I aim to give you a solid start to your nginx adventure. You will learn the basic features of nginx and be guided through your first virtual host to a point where you will know how to build on top of the basics to get to advanced features.</p><p>This book contains the following sections:</p><p>
<span class="emphasis"><em>So, what is nginx?</em></span> teaches you what nginx actually is, how it can be used, and how it fares against similar technologies.</p><p>
<span class="emphasis"><em>Installation</em></span> helps us learn the procedure to download and install nginx with different methods, and the cons and pros of each.</p><p>
<span class="emphasis"><em>Quick start</em></span> covers nginx configuration syntax while creating our first virtual host through some simple steps. After this section you will be comfortable with the working of an nginx configuration.</p><p>
<span class="emphasis"><em>Top 9 features you need to know about</em></span> helps you learn to perform nine useful tasks that the nginx modules offer. By the end of this section, you will be able to:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">G-zip assets for optimal page load time</li><li class="listitem" style="list-style-type: disc">Pre-zip assets for optimal page load time</li><li class="listitem" style="list-style-type: disc">Use nginx as a micro cache</li><li class="listitem" style="list-style-type: disc">How to use WebSockets with nginx</li><li class="listitem" style="list-style-type: disc">Use nginx with other software</li><li class="listitem" style="list-style-type: disc">Set up backend authentication for nginx downloads</li><li class="listitem" style="list-style-type: disc">Do GeoIP lookups in nginx</li><li class="listitem" style="list-style-type: disc">Limiting user requests to prevent abuse</li><li class="listitem" style="list-style-type: disc">Create seekable video streaming with nginx</li></ul></div><p>
<span class="emphasis"><em>People and places you should get to know</em></span> provides you with many useful links to resources about nginx, while keeping in mind that the community is important to nginx and it's where most support happens and where a lot of module development takes place.</p><div class="section" title="So, what is nginx?"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec03"/>So, what is nginx?</h1></div></div></div><p>The best way to describe nginx (pronounced engine-x) is as an event-based multi-protocol reverse proxy. This sounds fancy, but it's not just buzz words and actually affects how we approach configuring nginx. It also highlights some of the flexibility that nginx offers. While it is often used as a web server and an HTTP reverse proxy, it can also be used as an IMAP reverse proxy or even a raw TCP reverse proxy. Thanks to the plug-in ready code structure, we can utilize a large number of first and third party modules to implement a diverse amount of features to make nginx an ideal fit for many typical use cases.</p><div class="mediaobject"><img alt="So, what is nginx?" src="graphics/5125OS_01_01.jpg"/></div><p>A more accurate description would be to say that nginx is a reverse proxy first, and a web server second. I say this because it can help us visualize the request flow through the configuration file and rationalize how to achieve the desired configuration of nginx. The core difference this creates is that nginx works with URIs instead of files and directories, and based on that determines how to process the request. This means that when we configure nginx, we tell it what should happen for a certain URI rather than what should happen for a certain file on the disk.</p><p>A beneficial part of nginx being a reverse proxy is that it fits into a large number of server setups, and can handle many things that other web servers simply aren't designed for. A popular question is "Why even bother with nginx when Apache httpd is available?"</p><p>The answer lies in the way the two programs are designed. The majority of Apache setups are done using prefork mode, where we spawn a certain amount of processes and then embed our dynamic language in each process. This setup is synchronous, meaning that each process can handle one request at a time, whether that connection is for a PHP script or an image file.</p><p>In contrast, nginx uses an asynchronous event-based design where each spawned process can handle thousands of concurrent connections. The downside here is that nginx will, for security and technical reasons, not embed programming languages into its own process - this means that to handle those we will need to reverse proxy to a backend, such as Apache, PHP-FPM, and so on. Thankfully, as nginx is a reverse proxy first and foremost, this is extremely easy to do and still allows us major benefits, even when keeping Apache in use.</p><p>Let's take a look at a use case where Apache is used as an application server described earlier rather than just a web server. We have embedded PHP, Perl, or Python into Apache, which has the primary disadvantage of each request becoming costly. This is because the Apache process is kept busy until the request has been fully served, even if it's a request for a static file. Our online service has gotten popular and we now find that our server cannot keep up with the increased demand. In this scenario introducing nginx as a spoon-feeding layer would be ideal. When an nginx server with a spoon-feeding layer will sit between our end user and Apache and a request comes in, nginx will reverse proxy it to Apache if it is for a dynamic file, while it will handle any static file requests itself. This means that we offload a lot of the request handling from the expensive Apache processes to the more lightweight nginx processes, and increase the number of end users we can serve before having to spend money on more powerful hardware.</p><p>Another example scenario is where we have an application being used from all over the world. We don't have any static files so we can't easily offload a number of requests from Apache. In this use case, our PHP process is busy from the time the request comes in until the user has finished downloading the response. Sadly, not everyone in the world has fast internet and, as a result, the sending process could be busy for a relatively significant period of time. Let's assume our visitor is on an old 56k modem and has a maximum download speed of 5 KB per second, it will take them five seconds to download a 25 KB gzipped HTML file generated by PHP. That's five seconds where our process cannot handle any other request. When we introduce nginx into this setup, we have PHP spending only microseconds generating the response but have nginx spend five seconds transferring it to the end user. Because nginx is asynchronous it will happily handle other connections in the meantime, and thus, we significantly increase the number of concurrent requests we can handle.</p><p>In the previous two examples I used scenarios where nginx was used in front of Apache, but naturally this is not a requirement. nginx is capable of reverse proxying via, for instance, FastCGI, UWSGI, SCGI, HTTP, or even TCP (through a plugin) enabling backends, such as PHP-FPM, Gunicorn, Thin, and Passenger.</p></div></div>
<div class="section" title="Installation"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec04"/>Installation</h1></div></div></div><p>There are two ways to install nginx, either by building it from source, or by installing a binary package via a package manager, such as yum or apt. Each method has its own pros and cons, and which method we choose depends on what we need nginx to do and which OS we're using.</p><p>Historically nginx, Inc has only provided the source files for nginx so that we could compile the software ourselves, and only recently have they begun distributing binary packages for the various Linux distributions. Additionally, nginx requires that third party modules are compiled statically instead of being loaded at runtime. The end result of this is that the nginx ecosystem ends up with a number of native binary packages and custom binary packages built by different people to include different modules.</p><p>Even today many of the Linux distributions ship very old versions of nginx, which means we'll have to be careful when we install nginx to make sure we get the version we need. If we need any third party modules enabled, we are almost guaranteed to have to build from source. Thankfully, nginx is easy to install from source and this book details how to do it without suffering a nervous breakdown.</p><p>A last note before we continue to the installation process. nginx has three versions available: development, stable, and legacy. Development here refers to the program API stability, not runtime stability. This means that the development version is usually just as stable, or even more stable than the stable branch. This is because bug fixes are added to the development branch before the stable branch. In general, if I personally want features in a new development version, I will give it a week or two to be tested by the community and then feel safe upgrading to it. Legacy versions should be avoided, as they are not supported by either nginx, Inc or the community, and usually bugs are fixed by simply updating to the stable or development version.</p><div class="section" title="Step 1 – Different operating systems"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec03"/>Step 1 – Different operating systems</h2></div></div></div><p>Now, we will have a look at installing nginx on different operating systems.</p><div class="section" title="Windows"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec01"/>Windows</h3></div></div></div><p>Installing on Windows is the easiest of them all, as it's really only available as a binary file unless we want to start compiling through Cygwin, for most people this is overkill. Instead, just head to the nginx download page and get one of the Windows releases as signified by <span class="strong"><strong>nginx/Windows-1.X.XX</strong></span>. Extract that anywhere and we're ready to go!</p><p>A word of warning about nginx on Windows though. Windows has a unique version of event polling called IOCP and nginx does not currently support this. This means that nginx falls back to a slower variant, which means that nginx on Windows is not at the same performance standard as nginx on Linux. Additionally, there are a number of limitations that we should be aware of. At the time of writing the following are the known limitations:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Only one worker will be used</li><li class="listitem" style="list-style-type: disc">A worker can handle no more than 1,024 concurrent connections</li><li class="listitem" style="list-style-type: disc">Cache modules do not work on Windows Vista or later</li></ul></div><p>nginx, Inc maintains an updated list of known limitations at the following URL:</p><p>
<a class="ulink" href="http://www.nginx.org/en/docs/windows.html">http://www.nginx.org/en/docs/windows.html</a>
</p></div><div class="section" title="Linux"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec02"/>Linux</h3></div></div></div><p>To install on Linux we first need to decide whether we'll compile from source or install via a binary package. To help decide, here's a brief overview of the pros and cons:</p><div class="section" title="Installation via source"><div class="titlepage"><div><div><h4 class="title"><a id="ch01lvl4sec01"/>Installation via source</h4></div></div></div><p>The pros of installing nginx on Linux via source are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">It can easily use third party modules</li><li class="listitem" style="list-style-type: disc">It can use the latest version immediately</li></ul></div><p>The cons of installing nginx on Linux via source are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">It is more difficult than installing a binary package</li><li class="listitem" style="list-style-type: disc">You have to keep on top of updates yourself</li></ul></div></div><div class="section" title="Installation via binary package"><div class="titlepage"><div><div><h4 class="title"><a id="ch01lvl4sec02"/>Installation via binary package</h4></div></div></div><p>The pros of installing nginx on Linux via binary package are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">It is very easy to install</li><li class="listitem" style="list-style-type: disc">You don't have to keep track of updates yourself</li></ul></div><p>The cons of installing nginx on Linux via binary package are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">It is difficult to find a binary package with third party modules</li><li class="listitem" style="list-style-type: disc">It is potentially lagging behind on versions</li><li class="listitem" style="list-style-type: disc">It has many different versions, need to research them</li></ul></div><p>Ultimately I personally think it comes down to whether or not you need third party modules. Finding binary packages that contain the modules you need is often difficult and you rely on external people to keep their binary package updated. Compiling from source if you need third party modules also means that we can restrict binary packages to the official nginx provided repositories. This makes it far easier and reduces the research required into the various custom repositories and <span class="strong"><strong>Ubuntu Personal Package Archives</strong></span> (<span class="strong"><strong>PPAs</strong></span>).</p></div></div><div class="section" title="Installing from source"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec03"/>Installing from source</h3></div></div></div><p>Installing nginx from source is not as daunting as it might sound, as nginx is a fairly simple piece of software and we can still utilize yum and apt-get to simplify the installation of the dependencies.</p><p>If using apt, simply run the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>sudo apt-get build-dep nginx</strong></span>
</pre></div><p>To automatically install the dependencies for their nginx package, usually these are the same as for what we will install.</p><p>If using yum, run the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>sudo yum install pcre-devel zlib-devel openssl-devel</strong></span>
</pre></div><p>At this point we have the dependencies and are ready to compile nginx. Make sure we're in the directory we want to download the source code into and then run the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>wget http://www.nginx.org/download/nginx-1.3.15.tar.gz</strong></span>
<span class="strong"><strong>tar zxf nginx-1.3.15.tar.gz</strong></span>
<span class="strong"><strong>cd nginx-1.3.15</strong></span>
<span class="strong"><strong>./configure --help</strong></span>
</pre></div><p>After running the last command we should get a large amount of text on the screen. If you're not used to compiling from source, this would probably be pretty daunting at first, but let's read through the important points.</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><tbody><tr><td style="text-align: left" valign="top">

<pre class="programlisting">
<span class="strong"><strong>--prefix</strong></span>
</pre>

</td><td style="text-align: left" valign="top">
<p>This sets the base path where nginx is installed. If not defined, this will default to <code class="literal">/usr/local/nginx</code>.</p>
</td></tr><tr><td style="text-align: left" valign="top">

<pre class="programlisting">
<span class="strong"><strong>--sbin-path</strong></span>
</pre>

</td><td style="text-align: left" valign="top">
<p>This sets the path where the binary file is installed.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<pre class="programlisting">
<span class="strong"><strong>--conf-path</strong></span>
</pre>
</td><td style="text-align: left" valign="top">
<p>This sets the path of the configuration file.</p>
</td></tr></tbody></table></div><p>Any of the other install specific switches can be configured in the configuration file, so those really aren't important to set yet. Further down we start seeing switches named as <code class="literal">—with-*</code> and <code class="literal">—without-*</code>. Each of these allow us to define which standard modules go into our compiled binary package, and the switches we use depend on which features we want. Each module we include increases the size of the binary package, which increases memory usage. Although, even if we include all the modules, the memory size won't be more than a few megabytes. Do note that some modules might have other dependencies, for instance the GeoIP module relies on external GeoIP software which will have to be installed through your package manager. To read about what each module does, please refer to the official documentation at: <a class="ulink" href="http://www.nginx.org/en/docs/">http://www.nginx.org/en/docs/</a>.</p><p>Once we have decided the modules we want to be included, simply run the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>./configure —with-foo</strong></span>
</pre></div><p>If all the dependencies are correct, a summary screen should be presented as follows:</p><div class="mediaobject"><img alt="Installing from source" src="graphics/5125OS_02_01.jpg"/></div><p>If the information there is as expected, complete the compile by running the follow commands:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>make</strong></span>
<span class="strong"><strong>make install</strong></span>
</pre></div><p>If we already have nginx installed, we can have the make script automatically and seamlessly rotate the running binary package by using the following command:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>make upgrade</strong></span>
</pre></div><p>If we did everything right, we should get the following message after running <code class="literal">make install</code>:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>make[1]: Leaving directory '/path/to/nginx-1.3.15'</strong></span>
</pre></div><p>The quickest way to install from a binary package is to simply use the native packages and run either of the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>yum install nginx</strong></span>
</pre></div><p>or</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>apt-get install nginx</strong></span>
</pre></div><p>If the version installed is fairly recent, we might want to do just that for convenience, if it's old then move on and use the nginx provided binary packages. To use these first install the repository like so.</p><p>For yum:</p><p>Create the file <code class="literal">/etc/yum.repos.d/nginx.repo</code> and add the following to it:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong> [nginx]</strong></span>
<span class="strong"><strong>name=nginx repo</strong></span>
<span class="strong"><strong>baseurl=http://nginx.org/packages/OS/OSRELEASE/$basearch/</strong></span>
<span class="strong"><strong>gpgcheck=0</strong></span>
<span class="strong"><strong>enabled=1</strong></span>
</pre></div><p>Where <code class="literal">OS</code> is <span class="emphasis"><em>centos</em></span> if CentOS is used and <span class="emphasis"><em>rhel</em></span> if RHEL, or another RHEL-based distribution is used. <code class="literal">OSRELEASE</code> is the OS version number, being either <span class="emphasis"><em>5</em></span> or <span class="emphasis"><em>6</em></span>. If unsure check <code class="literal">uname -a</code> for a clue, or use the tried and tested method of trial and error.</p><p>For apt:</p><p>Add the following to <code class="literal">/etc/apt/sources.list</code> for Debian:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>deb http://nginx.org/packages/debian/ squeezenginx</strong></span>
<span class="strong"><strong>deb-src http://nginx.org/packages/debian/ squeezenginx</strong></span>
</pre></div><p>For Ubuntu, add the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>deb http://nginx.org/packages/ubuntu/ codenamenginx</strong></span>
<span class="strong"><strong>deb-src http://nginx.org/packages/ubuntu/ codenamenginx</strong></span>
</pre></div><p>Where codename is one of lucid, oneiric, precise, or quantal, depending on which version is used and then run:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>apt-get update</strong></span>
<span class="strong"><strong>apt-get install nginx</strong></span>
</pre></div></div></div><div class="section" title="Step 2- Starting nginx"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec04"/>Step 2- Starting nginx</h2></div></div></div><p>Regardless of how nginx was installed, we will most likely want to start it by using a script. Our options are the classic <code class="literal">init.d</code> script or an <code class="literal">upstart/systemd</code> script depending on our platform. If nginx was installed via a binary package, one such script should already have been provided for us and can be used by running:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>service nginx start</strong></span>
</pre></div><p>If nginx was installed via source, we'll need to install the init script ourselves. An nginx community effort to gather <code class="literal">.init</code> scripts can be found at: <a class="ulink" href="http://wiki.nginx.org/InitScripts">http://wiki.nginx.org/InitScripts</a>, which will help us get set up quickly.</p><p>Download the <code class="literal">init</code> script for the relevant platform and save it to <code class="literal">/etc/rc.d/init.d/nginx</code>, check the paths in the <code class="literal">.init</code> file to make sure they fit the install configurations we set with the <code class="literal">./configure arguments</code> (or the defaults!), and then run the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>chmod +x /etc/rc.d/init.d/nginx</strong></span>
</pre></div><p>Now run the preceding command up above to see the options available.</p></div><div class="section" title="And that's it"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec05"/>And that's it</h2></div></div></div><p>At this point nginx should be installed and ready to be configured. It's time to experiment a bit and learn the good stuff!</p></div></div>
<div class="section" title="Quick start &#x2013; Creating your first virtual host"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec05"/>Quick start – Creating your first virtual host</h1></div></div></div><p>It's finally time to get nginx up and running. To start out, let's quickly review the configuration file. If you installed via a system package, the default configuration file location is most likely <code class="literal">/etc/nginx/nginx.conf</code>. If you installed via source and didn't change the path prefix, nginx installs itself into <code class="literal">/usr/local/nginx</code> and places <code class="literal">nginx.conf</code> in a <code class="literal">/conf</code> subdirectory. Keep this file open as a reference to help visualize many of the things described in this chapter.</p><div class="section" title="Step 1 – Directives and contexts"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec06"/>Step 1 – Directives and contexts</h2></div></div></div><p>To understand what we'll be covering in this section, let me first introduce a bit of terminology that the nginx community at large uses. Two central concepts to the nginx configuration file are those of <span class="strong"><strong>directives</strong></span> and <span class="strong"><strong>contexts</strong></span>. A directive is basically just an identifier for the various configuration options. Contexts refer to the different sections of the nginx configuration file. This term is important because the documentation often states which context a directive is allowed to have within.</p><p>A glance at the standard configuration file should reveal that nginx uses a layered configuration format where blocks are denoted by curly brackets <code class="literal">{}</code>. These blocks are what are referred to as contexts.</p><p>The topmost context is called main, and is not denoted as a block but is rather the configuration file itself. The main context has only a few directives we're really interested in, the two major ones being <code class="literal">worker_processes</code> and user. These directives handle how many worker processes nginx should run and which user/group nginx should run these under.</p><p>Within the main context there are two possible subcontexts, the first one being called <span class="strong"><strong>events</strong></span>. This block handles directives that deal with the event-polling nature of nginx. Mostly we can ignore every directive in here, as nginx can automatically configure this to be the most optimal; however, there's one directive which is interesting, namely <code class="literal">worker_connections</code>. This directive controls the number of connections each worker can handle. It's important to note here that nginx is a terminating proxy, so if you HTTP proxy to a backend, such as Apache httpd, that will use up two connections.</p><p>The second subcontext is the interesting one called <code class="literal">http</code>. This context deals with everything related to HTTP, and this is what we will be working with almost all of the time. While there are directives that are configured in the <code class="literal">http</code> context, for now we'll focus on a subcontext within <code class="literal">http</code> called <code class="literal">server</code>. The <code class="literal">server</code> context is the nginx equivalent of a virtual host. This context is used to handle configuration directives based on the host name your sites are under.</p><p>Within the <code class="literal">server</code> context, we have another subcontext called <code class="literal">location</code>. The <code class="literal">location</code> context is what we use to match the URI. Basically, a request to nginx will flow through each of our contexts, matching first the server block with the hostname provided by the client, and secondly the location context with the URI provided by the client.</p><p>Depending on the installation method, there might not be any server blocks in the <code class="literal">nginx.conf</code> file. Typically, system package managers take advantage of the include directive that allows us to do an in-place inclusion into our configuration file. This allows us to separate out each virtual host and keep our configuration file more organized. If there aren't any server blocks, check the bottom of the file for an <code class="literal">include</code> directive and check the directory from which it includes, it should have a file which contains a server block.</p></div><div class="section" title="Step 2 – Define your first virtual hosts"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec07"/>Step 2 – Define your first virtual hosts</h2></div></div></div><p>Finally, let us define our first server block!</p><div class="informalexample"><pre class="programlisting">server {
    listen 80;
    server_name example.com;

    root /var/www/website;
}</pre></div><div class="note" style="" title="Note"><div class="inner"><h3 class="title"><a id="tip01"/>Tip</h3><p>
<span class="strong"><strong>Downloading the example code</strong></span>
</p><p>You can download the example code files for all Packt books you have purchased from your account at <a class="ulink" href="http://www.packtpub.com">http://www.packtpub.com</a>. If you purchased this book elsewhere, you can visit <a class="ulink" href="http://www.packtpub.com/support">http://www.packtpub.com/support</a> and register to have the files e-mailed directly to you.</p></div></div><p>That is basically all we need, and strictly speaking, we don't even need to define which port to listen on as port 80 is default. However, it's generally a good practice to keep it in there should we want to search for all virtual hosts on port 80 later on.</p></div></div>
<div class="section" title="Quick start &#x2013; Interacting with backends"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec06"/>Quick start – Interacting with backends</h1></div></div></div><p>Obviously, this virtual host is quite boring, all it does is serve a static file, and while that is certainly useful, it's practically never all we want to do. Something more interesting would be to serve PHP requests, perhaps even for a framework with a front controller pattern and search engine friendly URLs.</p><div class="section" title="Step 1 – A quick backend communication example"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec08"/>Step 1 – A quick backend communication example</h2></div></div></div><p>Communicating with a backend is done by passing the request to the backend if certain conditions are met. For example, in the following server block:</p><div class="informalexample"><pre class="programlisting">server {
    listen 80;
    server_name example.com;

    root /var/www/website;
    index index.php;

    location / {
        try_files $uri $uri/ /index.php;
    }

    location ~ \.php$ {
        include fastcgi.conf;
        fastcgi_pass 127.0.0.1:9000;
    }
}</pre></div><p>Here we are using a regular expression location block to define what should happen when a request with a URI ending in <code class="literal">.php</code> comes in. If the URI does not end in <code class="literal">.php</code> but, for instance, <code class="literal">/contact-us/</code>, <code class="literal">location /</code> is used instead that tries to find a file on the disk using our root directive and the URI. If that's not found, it tries to search for a directory instead and uses our index directive to find an index file. If that is not found either, then it finally rewrites internally to <code class="literal">/index.php</code> and restarts location evaluation with the URI now ending in <code class="literal">.php</code> and as such the PHP location will be used and send the request to PHP.</p></div><div class="section" title="Step 2 – Location blocks"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec09"/>Step 2 – Location blocks</h2></div></div></div><p>As we'll pass requests to a backend by using location blocks, it'll be useful to understand the different types of location blocks available. Did you notice in the preceding section how the location blocks use different modifiers before the URI? In the first location there is no modifier, and in the second <code class="literal">a ~</code> is used. This modifier changes how nginx matches the location to the URI sent by the end user. The modifiers and rules are as follows:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Modifier</p>
</th><th style="text-align: left" valign="bottom">
<p>Result</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>No modifier</p>
</td><td style="text-align: left" valign="top">
<p>This will match as a prefix value. <code class="literal">location /</code> will match any URI beginning with <code class="literal">/</code>, while <code class="literal">location /foo</code> will match any URI beginning with <code class="literal">/foo</code>.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">=</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This will match as an exact value. <code class="literal">location = /foo</code> will only match the exact <code class="literal">URI /foo</code> not the <code class="literal">URI /foobar</code> or even <code class="literal">/foo/</code>.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">~</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This will match as a case sensitive regular expression using the PCRE library.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">~*</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This will match as a case insensitive regular expression using the PCRE library.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">^~</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Will match as a prefix value, which is more important than a regular expression.</p>
</td></tr></tbody></table></div><p>With all of these different location modifiers, nginx needs a way to know which one to use if multiple matches occur. To do this nginx assigns each type of modifier a certain specificity, which helps to determine how important a location is.</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Modifier</p>
</th><th style="text-align: left" valign="bottom">
<p>Specificity</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">=</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This is the most specific modifier possible, as it matches only the exact string. If this location matches, it will be chosen first.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">^~</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This modifier is used specifically when you want a prefix match to be more important than a regular expression location. If you have multiple matching locations of this type, the longest match will be used.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">~</code> and <code class="literal">~*</code>
</p>
</td><td style="text-align: left" valign="top">
<p>nginx has no way to decide how specific a regular expression is, so these are matched in the order they are defined. This means that if multiple regular expression locations match, the first one defined will be used.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>No modifier</p>
</td><td style="text-align: left" valign="top">
<p>Finally if nothing else matches, a standard prefix match is used. If multiple prefix locations match, the longest match will be used.</p>
</td></tr></tbody></table></div><p>Knowing how nginx chooses a location is quite essential because of how nginx inheritance works. The common thing with every directive is that it will only ever inherit downwards, never up and never across contexts. In effect this means that we cannot have nginx apply two locations at the same time. As soon as we internally rewrite a request and locations are re-evaluated, nginx will forget about the directives in the old location and only care about the ones in the new location.</p><p>For an illustration of this behavior, see this following server block:</p><div class="informalexample"><pre class="programlisting">server {
    root /home/bill/www;
    index index.php;

    location /phpmyadmin {
        root /var/www;
        try_files $uri /phpmyadmin/index.php;
    }

    location ~* \.php$ {
        fastcgi_pass php_upstream;
    }
}</pre></div><p>When a request comes in for <code class="literal">/phpmyadmin/image/foo.jpg</code>, the <code class="literal">/phpmyadmin</code> location will be considered most specific and <code class="literal">try_files</code> will find the image. In contrast, if a request  comes in for <code class="literal">/phpmyadmin</code>, it will first use the <code class="literal">/phpmyadmin</code> location and then <code class="literal">try_files</code> will rewrite the request into the PHP location. When this happens everything from the previous location is discarded and now the root is inherited from the server context making the <code class="literal">root /home/bill/www</code> instead, and the request results in a 404 error.</p><p>Instead, what we need to do here is use a sublocation so that nginx does not have to inherit across.</p><div class="informalexample"><pre class="programlisting">server {
    root /home/bill/www;
    index index.php;

    location ^~ /phpmyadmin {
        root /var/www;

       location ~* \.php$ {
           fastcgi_pass php_upstream;
       }
    }

    location ~* \.php$ {
        fastcgi_pass php_upstream;
    }
}</pre></div><p>In this example we don't need <code class="literal">try_files</code>, as we have no need to rewrite the request. If the URI matches <code class="literal">/phpmyadmin/</code>, it will be chosen before the PHP location at the bottom, and if it then also matches the PHP sublocation, it will flow into that one, maintaining the root directive from the parent location.</p><p>The positive aspect of the preceding scenario is that it will always be simple to tell which directives will apply to any given request, by just following the rewrites to the final location and checking directives in the parent contexts. There are no complicated inheritance paths across contexts with some values being overridden by new directives, while others persist.</p><p>Related to location blocks is something called a <span class="strong"><strong>named location</strong></span>. A named location is essentially a location that isn't reached via the URI, but rather by internal references. A named location is denoted by a <code class="literal">@</code>.</p><div class="informalexample"><pre class="programlisting">    location @error404 { … }</pre></div><p>This location is useful when you want to logically separate out some directives, but don't want that part of the config accessible through the URI. The previously named location might be used for an error page, for example, where it would only be called when a request would result in a 404 error.</p><div class="informalexample"><pre class="programlisting">    error_page 404 @error404;</pre></div></div><div class="section" title="Step 3 – Directive types"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec10"/>Step 3 – Directive types</h2></div></div></div><p>In nginx, a directive will usually inherit based on a simple <code class="literal">http</code>-<code class="literal">server</code>-<code class="literal">location</code> flow. Mostly, anyway. nginx has different types of directives and each type inherits a bit differently. How a directive inherits depends on its type. In nginx, there are three types of directives and <code class="literal">try_files</code>. The three types are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The standard directive</li><li class="listitem" style="list-style-type: disc">The array directive</li><li class="listitem" style="list-style-type: disc">The action directive</li></ul></div><p>The vast majority of directives are <span class="strong"><strong>standard directives</strong></span>. These are passive configuration directives that do nothing but configure some aspect of nginx. They follow the standard inheritance of nginx and inherit downwards unless the lower context specifies the same directive.</p><p>
<span class="strong"><strong>Array directives</strong></span> differ a bit, as multiple directives can be specified in the same context. An example of an array directive would be the <code class="literal">access_log</code> directive. If we use the array directive three times in the same location block, nginx will create all three access logs.</p><p>The possible confusion with array directives comes from the fact that while we can use the directive multiple times in the same context, when we try to use it multiple times in two different contexts, the lower context will replace the higher one, not add to it. Consider the following example:</p><div class="informalexample"><pre class="programlisting">server {
    access_log /var/log/nginx/access.log;

    location ~ ^/calendar/.+\.php$ {
        access_log /var/log/nginx/php-requests.log;
    }
}</pre></div><p>In the preceding example, there are two access logs defined but only one of them will ever be written to, depending upon whether the PHP location matches or not. If the goal is to log to both the server context access log and the PHP specific one, we need to define the server context access log twice.</p><div class="informalexample"><pre class="programlisting">server {
    access_log /var/log/nginx/access.log;

    location ~ ^/calendar/.+\.php$ {
        access_log /var/log/nginx/access.log;
        access_log /var/log/nginx/php-requests.log;
    }
}</pre></div><p>The final type of directive is the action directive. These are directives that cause an immediate action, and as such do not inherit but rather execute immediately if the relevant context becomes active. Take, for example, the <code class="literal">rewrite</code> directive in the following example:</p><div class="informalexample"><pre class="programlisting">server {
    rewrite ^/booking(.*) /calendar$1;

    location /calendar {
        rewrite ^ /index.php;
    }
}</pre></div><p>Here the <code class="literal">rewrite</code> directive in the <code class="literal">server</code> context will always execute, thus the regex parser will always start and see if the pattern <code class="literal">^/booking(.*)</code> matches the current URI; the request will then flow into the <code class="literal">/calendar</code> location and the next rewrite will trigger.</p><p>Finally, there's <code class="literal">try_files</code>, which is a bit of an outlier. This is because <code class="literal">try_files</code> does not fit any of the other directive types. It is perhaps closest to an action directive in the sense that it will not inherit, the difference is that when placed in the <code class="literal">server</code> context nginx actually creates a special pseudo-location that is the least specific location possible. This essentially means that <code class="literal">try_files</code> in the <code class="literal">server</code> context will only ever execute if no location matches the request. This if of course a possible scenario, however, if <code class="literal">location /</code> is used, this location will always match and thus <code class="literal">try_files</code> is never used. It's highly recommended that <code class="literal">try_files</code> is never placed outside a location, so as to avoid confusion if suddenly <code class="literal">try_files</code> no longer executes when the configuration is changed.</p><p>Unfortunately, this behavior only holds true when we consider the contexts <code class="literal">http</code>-<code class="literal">server</code>-<code class="literal">location</code>. Locations can have three different subcontexts of nested location, if-in-location and <code class="literal">limit_except</code>. The bad news here is that how directive inheritance works for these contexts is entirely up to the module that defines the directive. The good news is that the modules included with nginx have a standardized behavior and that standard and array directives function much like they normally do. The only real difference is with action directives which not only won't inherit, but also won't execute if a nested location matches. The following example illustrates this scenario:</p><div class="informalexample"><pre class="programlisting">server {
    location /calendar {
        rewrite ^ /static.php;

        location ~ \.php$ {
            fastcgi_pass php_upstream;
        }
    }
}</pre></div><p>The <code class="literal">rewrite</code> directive in the outer location will execute only if the inner location does not match.</p></div><div class="section" title="Step 4 – Location reevaluation"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec11"/>Step 4 – Location reevaluation</h2></div></div></div><p>A useful thing to talk about when following action directives is the effect these directives have when executed, as they cause an internal rewrite. With every internal rewrite nginx will reevaluate the locations and possibly select a new one. Keeping internal redirects simple and few in number can often result in less debugging when problems arise.</p><p>It's useful to know that while <code class="literal">try_files</code> was listed as similar to action directives, only the final argument to <code class="literal">try_files</code> will actually cause a location reevaluation. This can cause issues with <code class="literal">try_files</code> like this:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>try_files $uri $uri.php /index.php;</strong></span>
</pre></div><p>While initially this may seem to enable pretty URLs, it will actually cause nginx to potentially output the source code of PHP files to the user, as <code class="literal">$uri.php</code> is not the last argument to <code class="literal">try_files</code>, and will therefore only set the internal <code class="literal">$uri</code> pointer and not reevaluate locations.</p><p>Another useful thing to know is that rewrites can be made to not trigger location reevaluation by using the <code class="literal">break</code> flag at the end, for example, if you wish to rewrite from an old PHP script to a new one, you can avoid nginx going through the entire location evaluation process again.</p><div class="informalexample"><pre class="programlisting">location ~ \.php$ {
    rewrite ^/old.php /new.php break;
    fastcgi_pass php_upstream;
}</pre></div></div><div class="section" title="Step 5 – Dealing with backends"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec12"/>Step 5 – Dealing with backends</h2></div></div></div><p>Backends come into play once we need to use nginx for something more than just static file serving. nginx is designed to not embed anything within itself, but rather use transport protocols to talk to backends. There are multiple protocols available, such as HTTP, FastCGI, uWSGI, SCGI, and Memcached. Third party plugins may add even more possible protocols, allowing nginx to talk to more different backends.</p><p>As nginx separates itself from backends using transport protocols, the management of these backends becomes a separate issue as well.</p><p>In order to have nginx talk to a backend, we'll have to tell the backend which file to execute as well as provide it some other information. Thankfully, nginx provides configuration for this with its default install. Check for files <code class="literal">fastcgi.conf</code>, <code class="literal">uwsgi_params</code>, and <code class="literal">scgi_params</code>.</p><p>For HTTP proxying we usually need to provide the backend with some information through HTTP headers. Most backends will expect the <code class="literal">HOST</code> header to be set as well as the end user IP. Typically, a configuration for proxying would look like the following:</p><div class="informalexample"><pre class="programlisting">location /proxy {
    proxy_set_header HOST $http_host;
    proxy_set_header X-Forwarded-For $remote_addr;
    proxy_pass http://127.0.0.1:8080;
}</pre></div></div><div class="section" title="Step 6 – What can you do if you get stuck?"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec13"/>Step 6 – What can you do if you get stuck?</h2></div></div></div><p>Getting stuck is an inevitable part of dealing with servers. The information from the <span class="emphasis"><em>Step 5 – Dealing with backends</em></span> section will help us understand the flow of a request, and thus allow us to know which directives apply to the request. Sometimes, though, it's nice with a bit more information to help us debug a problem faster. For this nginx provides the error log. Most errors go in the error log, even if its a 404 error, or the backend reporting an error. Therefore, it's critical to have an error log defined with a proper log level.</p><p>The error log directive in nginx is defined as:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>error_log file | stderr [debug | info | notice | warn | error | crit | alert | emerg];</strong></span>
</pre></div><p>When faced with a problem, the first thing to do is set the log level to info and check for any entry in the error log. Usually, there will be something to give a clue, for instance if a 404 error occurs where it shouldn't, the nginx error log will explain where it's trying to find the file and that can help us visualize where in our configuration we've gone wrong.</p><p>If things still aren't making sense at this point, nginx offers one more easy way to look at a request. The return directive allows us to return a status code and a string. For instance, we use the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>return 200 $fastcgi_script_name;</strong></span>
</pre></div><p>We can get the content of that variable output. This can function as a poor man's debugger.</p></div></div>
<div class="section" title="Top 9 features you need to know about"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec07"/>Top 9 features you need to know about</h1></div></div></div><p>While nginx at the core is designed to be a standard reverse proxy and HTTP web server, we can take it much further and use nginx as a central part in our toolchain, if we look into some of the more esoteric modules as well as the ones not included in the default compile. Thankfully, these modules are very often included in the binary packages provided by repositories, so regardless of which method was used to install nginx, they should be available for us to play with.</p><p>Compressing site assets is one of the most important methods to optimize the perceived load time of a first time visitor, and even for subsequent page loads when compressing the HTML backend response.</p><div class="section" title="Gzipping"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec14"/>Gzipping</h2></div></div></div><p>Gzipping the JavaScript, CSS, and HTML responses is of utmost importance if load time is considered important, which naturally means that nginx offers this as a core feature. If we include the optional gzip static module, we can optimize this process even further by compressing the assets ahead of time, so that nginx can merely serve the static gzip file instead of having to compress it on-the-fly.</p><p>To start off with, let's look at how to enable normal on-the-fly gzip compression.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>gzip             on;</strong></span>
<span class="strong"><strong>gzip_min_length  100;</strong></span>
<span class="strong"><strong>gzip_proxied     expired no-cache no-store private auth;</strong></span>
<span class="strong"><strong>gzip_comp_level  5;</strong></span>
<span class="strong"><strong>gzip_types       text/plain text/css text/xml text/javascript application/xml application/xml+rss application/x-javascript image/x-icon;</strong></span>
<span class="strong"><strong>gzip_disable     "msie6";</strong></span>
</pre></div><p>These directives are valid in an <code class="literal">http</code> context, which means that if we specify them in the <code class="literal">http</code> block they will apply to every <code class="literal">server</code> block, thus enabling us to specify compression only once. Using our knowledge of <span class="strong"><strong>nginx inheritance</strong></span> from the <span class="emphasis"><em>Quick Start</em></span> section we can still override this on a server or location basis if required by simply setting the <code class="literal">gzip</code> directive to <code class="literal">off</code>.</p><p>The different directives are as always explained in detail in the documentation; however, here's a brief overview of what each does:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Directive</p>
</th><th style="text-align: left" valign="bottom">
<p>Description</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">gzip</code>
</p>
</td><td style="text-align: left" valign="top">
<p>On or off, that is enables or disables gzipping.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">gzip_min_length</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This is the minimum response size in bytes before nginx will compress the response. It Defaults to 20 bytes.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">gzip_proxied</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This defines if nginx should compress the response when nginx is behind other proxy software, such as Varnish or HAProxy. It defaults to off.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">gzip_comp_level</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This defines the gzip compression level, default being <code class="literal">1</code>. It gives diminishing returns past level <code class="literal">4</code>, and past level <code class="literal">5</code> there's rarely any difference at all. Higher levels use more CPU resources.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">gzip_types</code>
</p>
</td><td style="text-align: left" valign="top">
<p>The mime types to compress. Text/html is always compressed if gzipping is enabled. To compress everything use <code class="literal">*</code>, though, this also compresses resources which are already compressed, thus wasting server resources.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">gzip_disable</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Regex matched against the user agent to determine when to not compress in case the user agent is buggy. <code class="literal">msie6</code> is a special value for Internet Explorer 4 to 6, which were buggy.</p>
</td></tr></tbody></table></div></div><div class="section" title="Pre-gzipping"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec15"/>Pre-gzipping</h2></div></div></div><p>Using the pre-gzipping module has the advantage of saving CPU resources, as the site assets will already be stored in a compressed format instead of having to be compressed on each request. Making use of the pre-gzipping module is both simpler and more complicated at the same time. More complicated as we have to gzip the files ourselves, but simpler as there are far less configuration directives. To enable the precompressed gzip module we simply use the following configuration:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>gzip_static      on;</strong></span>
<span class="strong"><strong>gzip_proxied     expired no-cache no-store private auth;</strong></span>
<span class="strong"><strong>gzip_disable     "msie6";</strong></span>
</pre></div><p>Immediately, we'll see that the only new directive is really <code class="literal">gzip_static</code> which, like the <code class="literal">gzip</code> directive, takes an <code class="literal">on</code> or <code class="literal">off</code> value to enable or disable it.</p><p>Gzipping files is a bit outside the scope of this book. It can either be done by hand using the command line gzip application, or automated as part of a build process, but it has to be done outside of nginx.</p></div><div class="section" title="Using nginx as a full-page micro cache"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec16"/>Using nginx as a full-page micro cache</h2></div></div></div><p>It's noon and you've just sat down for lunch when your monitoring service sends you a text message saying your start-up's newly launched web service is down. Seconds later your cofounder texts you in a panic that the website is down, and just as his submissions to HackerNews and Reddit got on the front page too. Ars Technica and The Next Web are currently writing articles covering your start-up and the world is literally about to go under if you don't get the website online immediately.</p><p>Enter the micro cache. The concept is that any page which doesn't contain user specific information should be cached in nginx, so that the backend application isn't even touched. This relieves load on the backend and allows most applications to handle far more traffic. Normally, an application will have to be written with caching in mind to handle invalidation of cached pages whenever content updates. The micro cache concept handles this by only caching things for a short period of time. If traffic spikes to 20 requests per second, and the micro cache is set to expire after 10 seconds, that's 200 requests the backend application did not have to handle, which makes micro caching a good tool to use when in a pinch.</p><p>While the concept of micro cache is simple, the execution can be a bit more complicated depending on the application. The key aspect is to only cache pages that contain no user specific information. If no such thing exists, it's very simple, otherwise we'll need to control when to cache and when not to cache.</p><p>There are two approaches to do this. The first is to use the built-in FastCGI cache or the equivalent for the other modules, such as proxy, uWSGI, SCGI, and so on. The second is to use Memcached as a cache, which is agnostic to the proxy method.</p><p>The difference between the two methods is that the built-in FastCGI cache is read and write, while Memcached cache is read-only. Essentially, it becomes a question of where the responsibility for writing to the cache lies. With the built-in FastCGI cache the logic is placed in the nginx config, while with Memcached the logic is placed in the application, as it will need to write to the cache itself.</p><div class="section" title="Memcached micro cache"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec04"/>Memcached micro cache</h3></div></div></div><p>Lets start with the Memcached scenario, as that's simpler from an nginx point of view and largely similar in construct for us to build on later. A basic Memcached micro cache would look like the following in the nginx configuration:</p><div class="informalexample"><pre class="programlisting">server {
    root /var/www;

    location / {
        try_files $uri /index.php$is_args$args;
    }

    location ~* \.php$ {
        default_type text/html;
        charset      utf-8;

        if ($request_method = GET) {
            set $memcached_key $request_method$request_uri;

            memcached_pass host:11211;
            error_page     404 502 504 = @nocache;
        }

        if ($request_method != GET) {
            fastcgi_pass backend;
        }
    }

    location @nocache {
        fastcgi_pass backend;
    }
}</pre></div><p>In the preceding configuration, the important aspects take place inside the location to handle PHP requests. Specifically, the variable <code class="literal">$memcached_key</code> is the most important, as this defines the key to request from Memcached.</p><p>A potential complication here is if pages with user data and without user data share the same request URI. In this case, extra configuration is needed to check if a page contains user data. This is always application specific, but common methods are checking for cookies via <code class="literal">$http_cookie</code> or checking the URL arguments through <code class="literal">$args</code>.</p><p>Another thing to notice is that only <code class="literal">GET</code> requests use the cache, anything not a <code class="literal">GET</code> request will instead <code class="literal">fastcgi_pass</code> to our backend, thus bypassing the cache.</p><p>If a request passes all the validation and is sent to Memcached and Memcached returns a 404 not found status, <code class="literal">error_page</code> will send the request to the <code class="literal">@nocache</code> named location, which will <code class="literal">fastcgi_pass</code> to our backend. The backend is then responsible for populating the proper key in Memcached for the next request to use.</p><p>As the application is writing to the cache here, remember to set the cache expire time to something low enough that we won't have stale cache entries for long when the application date updates.</p></div><div class="section" title="Built-in FastCGI cache"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec05"/>Built-in FastCGI cache</h3></div></div></div><p>Using the built-in caches is very similar in construct to the previous config example. The main difference is that not only do we have to define when to read from the cache, but also when to write to it. A typical configuration would look like the following:</p><div class="informalexample"><pre class="programlisting">fastcgi_cache_path /var/cache/nginx levels=1:2 keys_zone=microcache:5m max_size=500m;

server {
    root /var/www;

    location / {
        try_files $uri /index.php$is_args$args;
    }

    location ~* \.php$ {
        set $no_cache "";

        # Verify request method is GET or HEAD.
        if ($request_method !~ ^(GET|HEAD)$) {
            set $no_cache "1";
        }

        # Check if a nocache cookie is set, for instance after handling a POST.
        if ($http_cookie ~* "_nocache") {
            set $no_cache "1";
        }

        fastcgi_no_cache $no_cache;
        fastcgi_cache_bypass $no_cache;

        fastcgi_cache microcache;
        fastcgi_cache_key $request_method$request_uri;

        fastcgi_cache_valid 200 5s;
        fastcgi_cache_use_stale updating;

        fastcgi_pass backend;
    }
}</pre></div><p>As can be seen, the concept is largely the same. Set up the cache <code class="literal">keys_zone</code>, figure out whether to cache or not and finally set the cache key. To fully explain what's going on, let's have a look at what the different directives actually do.</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Directive</p>
</th><th style="text-align: left" valign="bottom">
<p>Description</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">fastcgi_cache_path</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Sets the path to store cached responses under. Also names the key zone associated with this cache path and specifies how much metadata and data can be stored there. In this example, <code class="literal">keys_zone</code> is called micro cache.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">fastcgi_no_cache</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Specifies whether to write to the cache or not. Anything other than an empty string or the value numeric <code class="literal">0</code> will cause it to not write to the cache.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">fastcgi_bypass_cache</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Specifies whether to read from the cache or not. Anything other than an empty string or the numeric value <code class="literal">0</code> will cause it to not read from the cache.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">fastcgi_cache</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Specifies <code class="literal">keys_zone</code> to use. In this example, the <code class="literal">keys_zone</code> used is micro cache.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">fastcgi_cache_key</code>
</p>
</td><td style="text-align: left" valign="top">
<p>The key used to identify data in the cache.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">fastcgi_cache_valid</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Sets the caching time for a given response code. In this example, we want to cache only 200 responses and we will cache them for 5 seconds. Our application can override this directive using the <code class="literal">X-Accel-Expires</code> header from the X-Accel module or by using standard caching headers <code class="literal">Expires</code> and <code class="literal">Cache-Control</code>.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">fastcgi_cache_use_stale</code>
</p>
</td><td style="text-align: left" valign="top">
<p>Specifies when the cache will use a cache entry after it's expired. In this example, we use <code class="literal">updating</code> to allow us to use the cache while it's being updated, thus preventing a sudden flood of connections when a key expires.</p>
</td></tr></tbody></table></div></div></div><div class="section" title="Using nginx behind other proxies"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec17"/>Using nginx behind other proxies</h2></div></div></div><p>While nginx can certainly be used as the only reverse proxy in our stack, there are scenarios where we might want to use alternative software in front of nginx because we have in-house expertise or are already using them. Popular choices here are Varnish and HAProxy.</p><p>In this case we can have nginx handle such a scenario transparently using the optional module Real IP. With this we can have nginx transparently replace the variables referencing an IP with the IP of the proxy, thus keeping logs and the configuration of the same while giving us the ability to turn frontends on and off.</p><p>There are only three directives associated with the real IP module, thus making it fairly simple to implement and understand.</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>set_real_ip_from  192.168.1.0/24;</strong></span>
<span class="strong"><strong>set_real_ip_from  192.168.2.1;</strong></span>
<span class="strong"><strong>set_real_ip_from  2001:0db8::/32;</strong></span>
<span class="strong"><strong>real_ip_header    X-Forwarded-For;</strong></span>
<span class="strong"><strong>real_ip_recursive on;</strong></span>
</pre></div><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Directive</p>
</th><th style="text-align: left" valign="bottom">
<p>Description</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">set_real_ip_from</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This specifies an IP to enable the real IP module from. Preventing random people from pretending to be a frontend to nginx. This can be specified multiple times.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">real_ip_header</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This specifies the header to get the real IP from. X-Forwarded-For and X-Real-IP are the most commonly used. This defaults to X-Real-IP.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">real_ip_recursive</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This specifies the IP to use. If off, this will use the last address in header defined by <code class="literal">real_ip_header</code>. If on, this will search the IP list until it finds one not in the trusted IP list. This is useful when a request has been forwarded multiple times. This defaults to off.</p>
</td></tr></tbody></table></div></div><div class="section" title="Setting up secure downloads"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec18"/>Setting up secure downloads</h2></div></div></div><p>nginx has a feature called X-Accel which is meant as a replacement for the <code class="literal">mod_sendfile</code> functionality found in Apache httpd and lighttpd. The concept is mostly the same. A request is sent to a backend application, which can then do whatever it needs to do, for instance it might log a download or validate user credentials. Once the backend application is done doing its work it issues a non-standard HTTP header <code class="literal">X-Accel-Redirect</code> with a path to the file relative to the document root. nginx will detect this header and look for a matching location based on the path sent. An example of this would be a PHP backend application issuing a header X-Accel-Redirect, that is, <code class="literal">/video/birthday/dad.mp4</code>.</p><p>In nginx, we would then have the following configuration:</p><div class="informalexample"><pre class="programlisting">server {
    root /var/www;

    location /video {
        root /mnt/data;
    }
}</pre></div><p>In this scenario, nginx would then look for the file at the path <code class="literal">/mnt/data/video/birthday/dad.mp4</code>. If the file is not found it will send a 404 status error; if the file is found it will start sending the file to the end user, thus relieving the backend application of this.</p><p>nginx has a number of X-Accel headers available.</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Header</p>
</th><th style="text-align: left" valign="bottom">
<p>Description</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>X-Accel-Redirect</p>
</td><td style="text-align: left" valign="top">
<p>Specifies a URI relative to the root directive in nginx configuration to the file to send to the user.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>X-Accel-Buffering</p>
</td><td style="text-align: left" valign="top">
<p>Specifies whether to allow nginx to buffer the connection or not. Turn off if doing Comet style application. Defaults to yes.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>X-Accel-Charset</p>
</td><td style="text-align: left" valign="top">
<p>Specifies the character set of the connection. Defaults to utf-8.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>X-Accel-Expires</p>
</td><td style="text-align: left" valign="top">
<p>Used to control whether nginx will cache the application response or not. Defaults to off.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>X-Accel-Limit-Rate</p>
</td><td style="text-align: left" valign="top">
<p>Specifies a rate limit for the connection.</p>
</td></tr></tbody></table></div></div><div class="section" title="Doing GeoIP lookups"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec19"/>Doing GeoIP lookups</h2></div></div></div><p>To do a GeoIP lookup, nginx will need the MaxMind GeoIP database. Both the paid and free versions are compatible with this module. The free version can be downloaded from:</p><p>
<a class="ulink" href="http://dev.maxmind.com/geoip/geolite">http://dev.maxmind.com/geoip/geolite</a>
</p><p>Every directive in this module has to be defined in the <code class="literal">http</code> section and looks like the following:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>geoip_country         /var/data/GeoIP.dat;</strong></span>
<span class="strong"><strong>geoip_city            /var/data/GeoLiteCity.dat;</strong></span>
<span class="strong"><strong>geoip_proxy           192.168.2.0/24;</strong></span>
<span class="strong"><strong>geoip_proxy_recursive on;</strong></span>
</pre></div><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Directive</p>
</th><th style="text-align: left" valign="bottom">
<p>Description</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<pre class="programlisting">
<span class="strong"><strong>geoip_country</strong></span>
</pre>
</td><td style="text-align: left" valign="top">
<p>Specifies the path to the country level GeoIP database.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<pre class="programlisting">
<span class="strong"><strong>geoip_city</strong></span>
</pre>
</td><td style="text-align: left" valign="top">
<p>Specifies the path to the city level GeoIP database. This database also contains the data from the country database.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<pre class="programlisting">
<span class="strong"><strong>geoip_org</strong></span>
</pre>
</td><td style="text-align: left" valign="top">
<p>Specifies the path to the organization level GeoIP database. The GeoIP organization database is a paid-only database that nginx also supports.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<pre class="programlisting">
<span class="strong"><strong>geoip_proxy</strong></span>
</pre>
</td><td style="text-align: left" valign="top">
<p>When nginx is used behind other proxy software, this can be used to specify the IP of that proxy and have nginx do a lookup on the IP in X-Forwarded-For instead.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<pre class="programlisting">
<span class="strong"><strong>geoip_proxy_recursive</strong></span>
</pre>
</td><td style="text-align: left" valign="top">
<p>Functionally similar to <code class="literal">real_ip_recursive</code> from the using nginx behind other proxies example.</p>
</td></tr></tbody></table></div><p>When the proper database is loaded into nginx, the following variables will become available to be used through the config, for instance in the access log or to be passed on to a backend.</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Variable</p>
</th><th style="text-align: left" valign="bottom">
<p>Description</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<pre class="programlisting">
<span class="strong"><strong>$geoip_country_code</strong></span>
<span class="strong"><strong>$geoip_city_country_code</strong></span>
</pre>
</td><td style="text-align: left" valign="top">
<p>Variable name depends on the database specified. Contains the two letter country code.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<pre class="programlisting">
<span class="strong"><strong>$geoip_country_code3</strong></span>
<span class="strong"><strong>$geoip_city_country_code3</strong></span>
</pre>
</td><td style="text-align: left" valign="top">
<p>Variable name depends on the database specified. Contains the three letter country code.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<pre class="programlisting">
<span class="strong"><strong>$geoip_country_name</strong></span>
<span class="strong"><strong>$geoip_city_country_name</strong></span>
</pre>
</td><td style="text-align: left" valign="top">
<p>Variable name depends on the database specified. Contains the full country name.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<pre class="programlisting">
<span class="strong"><strong>$geoip_city_continent_code</strong></span>
</pre>
</td><td style="text-align: left" valign="top">
<p>Contains the two letter code for the continent. Only available in city database.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<pre class="programlisting">
<span class="strong"><strong>$geoip_dma_code</strong></span>
</pre>
</td><td style="text-align: left" valign="top">
<p>Contains US region DMA code. Only available in city database.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<pre class="programlisting">
<span class="strong"><strong>$geoip_latitude</strong></span>
</pre>
</td><td style="text-align: left" valign="top">
<p>Contains the latitude of the users location. Only available in city database.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<pre class="programlisting">
<span class="strong"><strong>$geoip_longitude</strong></span>
</pre>
</td><td style="text-align: left" valign="top">
<p>Contains the longitude of the users location. Only available in city database.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<pre class="programlisting">
<span class="strong"><strong>$geoip_region</strong></span>
</pre>
</td><td style="text-align: left" valign="top">
<p>Contains the two symbol country region code. Only available in city database.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<pre class="programlisting">
<span class="strong"><strong>$geoip_region_name</strong></span>
</pre>
</td><td style="text-align: left" valign="top">
<p>Contains the full country region name. Only available in city database.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<pre class="programlisting">
<span class="strong"><strong>$geoip_city</strong></span>
</pre>
</td><td style="text-align: left" valign="top">
<p>Contains the full city name. Only available in city database.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<pre class="programlisting">
<span class="strong"><strong>$geoip_postal_code</strong></span>
</pre>
</td><td style="text-align: left" valign="top">
<p>Contains the postal code of the city. Only available in city database.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<pre class="programlisting">
<span class="strong"><strong>$geoip_org</strong></span>
</pre>
</td><td style="text-align: left" valign="top">
<p>Contains the organization name. Could for instance be a university. Only available in organization database.</p>
</td></tr></tbody></table></div></div><div class="section" title="Limiting user requests"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec20"/>Limiting user requests</h2></div></div></div><p>There are two ways to limit requests in nginx, concurrent requests and frequency of requests. Both can be used simultaneously and multiple times on different factors. For instance, we can limit concurrent requests per IP while we limit concurrent requests per server block.</p><p>To achieve this, nginx has two modules; one which limits concurrency and the other which limits frequency.</p><div class="section" title="Limiting concurrent connections"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec06"/>Limiting concurrent connections</h3></div></div></div><p>To limit concurrent requests, we use the <span class="strong"><strong>limit conn</strong></span> module. The concept is fairly simple, we create a memory zone based on a variable and nginx will then track concurrent requests grouped by this variable. We could, for instance, use the <code class="literal">$server_name</code> variable to limit concurrent requests per vhost, or we could use <code class="literal">$binary_remote_addr</code> to limit on a users IP.</p><div class="informalexample"><pre class="programlisting">limit_conn_zone $binary_remote_addr zone=perip:5m;

server {
    location /download/ {
        limit_conn perip 1;
        limit_conn_log_level error;
    }
}</pre></div><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Directive</p>
</th><th style="text-align: left" valign="bottom">
<p>Description</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">limit_conn_zone</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This creates the memory zone. This also specifies the variable to limit based on as well as the maximum size of the memory zone.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">limit_conn</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This specifies which zone to limit by and how many concurrent connections to allow.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">limit_conn_log_level</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This specifies the log level required before the module will log that the concurrent connection limit was exceeded. This defaults to error. Generally, it is not advised to set it lower unless needed, as it can quickly flood the error log and hide more useful data.</p>
</td></tr></tbody></table></div></div><div class="section" title="Limit frequency of connections"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec07"/>Limit frequency of connections</h3></div></div></div><p>To limit the frequency of connections we can use the <span class="strong"><strong>limit req</strong></span> module. It's syntactically similar with only some minor changes to control rate instead of concurrency.</p><div class="informalexample"><pre class="programlisting">limit_req_zone $binary_remote_addr zone=one:5m rate=1r/s;

server {
    location /search/ {
        limit_req zone=one burst=5;
        limit_req_log_level error;
    }
}</pre></div><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><thead><tr><th style="text-align: left" valign="bottom">
<p>Directive</p>
</th><th style="text-align: left" valign="bottom">
<p>Description</p>
</th></tr></thead><tbody><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">limit_req_zone</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This creates the memory zone. This specifies the variable to limit based on the variable used as well as the maximum size of the memory zone and the rate at which connections should be allowed. Requests exceeding this rate will be buffered until they reach the limit set by burst at which point they will return 503 instead.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">limit_req</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This specifies which zone to limit by and the size of the request buffer, called <span class="strong"><strong>burst</strong></span>.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
<code class="literal">limit_req_log_level</code>
</p>
</td><td style="text-align: left" valign="top">
<p>This specifies the log level required before module will log that the connection frequency limit was exceeded. This defaults to error. Generally, it is not advised to set it lower unless needed, as it can quickly flood the error log and hide more useful data.</p>
</td></tr></tbody></table></div></div></div><div class="section" title="Using nginx for streaming videos"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec21"/>Using nginx for streaming videos</h2></div></div></div><p>Streaming videos with nginx is extremely easy. nginx has two optional modules for streaming videos, FLV and MP4, which enable it to stream flash video formats and MP4 containers with H.264/AAC encoding. These modules are compatible with all the traditional Flash and HTML5 players available today.</p><div class="section" title="Streaming FLV files"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec08"/>Streaming FLV files</h3></div></div></div><p>The FLV module is the simplest of the two and contains only a single directive. To enable it, simply specify <code class="literal">flv</code> in a location as follows:</p><div class="informalexample"><pre class="programlisting">location ~ \.flv$ {
    root /var/www/video;
    flv;
}</pre></div><p>That's literally everything there is to FLV streaming on the nginx side. If the <code class="literal">.flv</code> files are properly prepared with metadata and keyframes, they should stream smoothly and be seekable with this.</p></div><div class="section" title="Streaming MP4 files"><div class="titlepage"><div><div><h3 class="title"><a id="ch01lvl3sec09"/>Streaming MP4 files</h3></div></div></div><p>The MP4 module is pretty much exactly the same with only a few extra directives for additional control.</p><div class="informalexample"><pre class="programlisting">location ~ \.mp4$ {
    root /var/www/video;

    mp4;
    mp4_buffer_size     512k
    mp4_max_buffer_size 10m;
}</pre></div><p>The buffers control how much memory nginx can use to process the file. This is only limiting during metadata parsing where a large buffer may be required. For this the maximum buffer size becomes relevant. If it's set too small, nginx will output a 500 status error and log the error as:</p><div class="informalexample"><pre class="programlisting">
<span class="strong"><strong>/var/www/video/file.mp4" mp4 moov atom is too large: 12583268, you may want to increase mp4_max_buffer_size</strong></span>
</pre></div></div></div><div class="section" title="Using WebSockets with nginx"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec22"/>Using WebSockets with nginx</h2></div></div></div><p>Version 1.3.13 introduced connection upgrading support to nginx, which means WebSocket support. As WebSockets use the standard HTTP protocol for the initial handshake, nginx can make WebSocket support part of the standard proxy module. This means that all the features available to normal HTTP backends are also available to WebSocket proxying.</p><p>The configuration required for handling connection upgrading is as follows:</p><div class="informalexample"><pre class="programlisting">location /chat/ {
    proxy_pass http://backend;
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection "upgrade";
}</pre></div><p>A few things to notice about WebSocket support are that they can time out just like any other HTTP proxied request. WebSockets are affected by <code class="literal">proxy_read_timeout</code> that defaults to 60 seconds. The <span class="strong"><strong>keepalive</strong></span> feature in nginx is not of use here, as keepalive pings are empty packets and as such contain no data for nginx to pass to the backend. To combat this, you either need to raise the time out, or implement your own keepalive ping message. The added benefit of the latter solution is that it will also function as a health check for the connection itself.</p></div></div>
<div class="section" title="People and places you should get to know"><div class="titlepage"><div><div><h1 class="title"><a id="ch01lvl1sec08"/>People and places you should get to know</h1></div></div></div><p>The following links are a collection of individuals, aggregating sites, and articles that are worth following for the occasional nugget of nginx wisdom.</p><div class="section" title="Official links"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec23"/>Official links</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Website for nginx, Inc, the company behind the nginx software:<p>
<a class="ulink" href="http://nginx.com">http://nginx.com</a>
</p></li><li class="listitem" style="list-style-type: disc">Website for the nginx software, includes documentation and links to resources, such as books:<p>
<a class="ulink" href="http://nginx.org">http://nginx.org</a>
</p></li></ul></div></div><div class="section" title="Articles and tutorials"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec24"/>Articles and tutorials</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The following link is community-curated but is also the officially hosted documentation, which sometimes contains additional information compared to official documentation, not always updated, though:<p>
<a class="ulink" href="http://wiki.nginx.org">http://wiki.nginx.org</a>
</p></li></ul></div></div><div class="section" title="Community"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec25"/>Community</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">A web interface for the mailing list, the only official way to get help:<p>
<a class="ulink" href="http://forum.nginx.org">http://forum.nginx.org</a>
</p></li><li class="listitem" style="list-style-type: disc">Community supported IRC channel with high activity:<p>
<a class="ulink" href="http://Irc://irc.freenode.org/nginx">Irc://irc.freenode.org/nginx</a> (#nginx channel on <a class="ulink" href="http://irc.freenode.org">irc.freenode.org</a>)</p></li></ul></div></div><div class="section" title="Blogs"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec26"/>Blogs</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">An aggregator of various nginx blogs at:<p>
<a class="ulink" href="http://planet.ngx.cc/">http://planet.ngx.cc/</a>
</p></li><li class="listitem" style="list-style-type: disc">A community supporter who blogs about nginx:<p>
<a class="ulink" href="http://kbeezie.com/tag/nginx/">http://kbeezie.com/tag/nginx/</a>
</p></li><li class="listitem" style="list-style-type: disc">A community supporter who blogs about nginx:<p>
<a class="ulink" href="http://michael.lustfield.net/category/linux/nginx">http://michael.lustfield.net/category/linux/nginx</a>
</p></li><li class="listitem" style="list-style-type: disc">Blog of a prolific module creator; mostly writes about his own third party modules but occasionally has insights into nginx internals:<p>
<a class="ulink" href="http://agentzh.blogspot.com">http://agentzh.blogspot.com</a>
</p></li><li class="listitem" style="list-style-type: disc">Blog of a module creator, Valery Kholodkov, who also blogs about the internals of nginx:<p>
<a class="ulink" href="http://www.nginxguts.com/category/nginx/">http://www.nginxguts.com/category/nginx/</a>
</p></li><li class="listitem" style="list-style-type: disc">An editorial on the nginx code architecture by Andrew Alexeev of nginx, Inc:<p>
<a class="ulink" href="http://www.aosabook.org/en/nginx.html">http://www.aosabook.org/en/nginx.html</a>
</p></li><li class="listitem" style="list-style-type: disc">A somewhat outdated, but still relevant guide to nginx module development<p>
<a class="ulink" href="http://www.evanmiller.org/nginx-modules-guide.html">http://www.evanmiller.org/nginx-modules-guide.html</a>
</p></li><li class="listitem" style="list-style-type: disc">A somewhat outdated, but still relevant guide to advanced nginx module development<p>
<a class="ulink" href="http://www.evanmiller.org/nginx-modules-guide-advanced.html">http://www.evanmiller.org/nginx-modules-guide-advanced.html</a>
</p></li><li class="listitem" style="list-style-type: disc">As a community supporter, I blog about nginx at:<p>
<a class="ulink" href="http://blog.martinfjordvald.com/category/nginx/">http://blog.martinfjordvald.com/category/nginx/</a>
</p></li></ul></div></div><div class="section" title="Twitter"><div class="titlepage"><div><div><h2 class="title"><a id="ch01lvl2sec27"/>Twitter</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The official nginx Twitter account:<p>
<a class="ulink" href="https://twitter.com/nginxorg">https://twitter.com/nginxorg</a>
</p></li><li class="listitem" style="list-style-type: disc">Core developer of nginx; tends to be active in support channels:<p>
<a class="ulink" href="https://twitter.com/mdounin">https://twitter.com/mdounin</a>
</p></li><li class="listitem" style="list-style-type: disc">My Twitter account is:<p>
<a class="ulink" href="https://twitter.com/mfjordvald">https://twitter.com/mfjordvald</a>
</p></li><li class="listitem" style="list-style-type: disc">A Twitter search for nginx sometimes reveals some interesting articles:<p>
<a class="ulink" href="https://twitter.com/search?q=nginx">https://twitter.com/search?q=nginx</a>
</p></li></ul></div></div></div></body></html>