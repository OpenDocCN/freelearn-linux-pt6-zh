# 第二章：在日志文件中查找问题

Nginx 确实是一项突破性的技术，支撑着现代网络的很大一部分。和所有伟大的技术一样，它站在巨人的肩膀上。没有 Apache，就没有 Nginx。Nginx 完全继承了一个非常重要的 Unix 传统——详尽的日志记录。

日志是当你的 Nginx 实例出现问题时，你需要首先查看的内容。对于守护进程而言，除了日志，没有其他简单、可靠且保证有效的方式来向管理员传达其状态。

在本章中，你将找到以下内容：

+   关于如何配置 Nginx 日志记录以及配置中可能出现的错误的详细描述

+   关于如何记录 POST 请求体的特别部分

+   解释日志轮换工作原理以及为什么可能存在问题的部分

+   一系列来自日志的真实错误记录及其分析

# 配置 Nginx 日志记录

Nginx 可能会写入两种类型的日志。也可以说，由于 `log_format` 指令允许你创建自己的日志类型，所以实际上有无限多种类型。

为了帮助你回忆起配置 Nginx 日志所用的指令，下面是这些指令：

+   `error_log` 指令配置记录 Nginx 开发人员认为值得注意的异常事件的日志。通常，这些是各种错误。

    指令的格式如下：

    ```
    error_log <destination> <log level>;
    ```

    ### 注意事项

    第一个参数通常是日志文件的路径。从 1.7.1 版本开始，Nginx 支持通过 syslog 进行日志记录，发送到本地或远程的 syslog 服务器。还有一个很少使用的错误命名的特殊值 `stderr`，顺便提一下，这并不会将日志重定向到 `stderr`（即第三个标准 `stdio` 流，或者在 shell 中表示为 `&2`），因为从守护进程中将日志记录到 `stderr` 并没有太大意义——守护进程化会关闭所有标准文件描述符。`stderr` 值的含义是“将日志写入在编译时配置的文件”，而这个文件依赖于你使用的包或操作系统发行版。为了确保日志的去向，通常你会指定一个实际的文件，而不是 `stderr`。顺便说一下，为了让事情更复杂一些，确实可以在编译时指定将日志记录到实际的 `stderr`。对于守护进程来说，这并不是很有用，你也不太可能用到它。

    你通常希望拥有多个错误日志。记得在第一章中，我们讨论了名为上下文的多行配置指令。它们提供了一个主题，即为其中的指令设定一个狭窄的范围。你可以（而且通常这是个好主意）在不同的上下文中使用不同的日志文件。而使用 `stderr` 会阻止这一点，因为所有日志都会被写入同一个地方。

    `error_log` 指令的 `log level` 参数用于指定事件的严重性阈值，这些事件最终会记录到日志中。大多数情况下，你会希望将其设置为 `warn`，但当你遇到可以复现的问题并希望获得更多信息时，随时可以将其提高到 `debug`。

    `debug` 级别需要一个特殊的编译时开关。原因是 `debug` 日志会做出一些性能上的妥协，理想情况下，不应在生产系统中包含其代码。除非 Nginx 真的是你的瓶颈（这种情况比较少见），否则在编译 Nginx 时，你可以安全地使用 `--with-debug`。更多信息可以参考[`nginx.org/en/docs/debugging_log.html`](http://nginx.org/en/docs/debugging_log.html)。

+   另一个日志指令是 `access_log`。它比 `error_log` 包含更多功能，也有更多潜在的错误风险。让我们更仔细地看看它。

    这是如何配置访问日志的：

    ```
    access_log <destination> <log format> <misc arguments>
    ```

    访问日志的核心思想是记录所有由 Nginx 处理的请求-响应对。与错误日志不同，访问日志中的记录有一个明确规定的格式，通常是一个由空格分隔的值链，包含有关当前请求-响应对或 Nginx 一般状态的一些信息。所有访问日志记录都遵循此格式。访问日志和错误日志是协同工作的。如果 Nginx 对它处理的请求有异常反馈，你会在访问日志中看到一行严格格式化的数据，然后在错误日志中看到一些警告或错误，通常是自由文本的形式。

    `destination` 参数的取值与 `error_log` 指令的相应参数相同。你仍然可以将日志记录到 syslog 或文件中。

    ### 注意

    现代 Nginx 还具有一个有趣的性能特性，即缓冲访问日志。你可以在[`nginx.org/en/docs/http/ngx_http_log_module.html#access_log`](http://nginx.org/en/docs/http/ngx_http_log_module.html#access_log)上找到有关启用缓冲日志并使用 flush 或 gzip 参数的更多信息。在启用之前，请先了解缓冲的含义。所有错误报告机制的预期特性之一是实时性，而缓冲日志正好相反，日志记录不会立即写入磁盘并且无法立即检查。它们会在缓冲区中保留一段时间。你只需要在高负载场景下使用它，因为写入日志开始因磁盘等待而变得明显缓慢时，才会需要使用此功能。

    `access_log` 指令的 `log format` 参数是访问日志的核心。它期望提供一个模板名称，该模板定义日志中每条记录的格式。你可以通过 `log_format` 指令创建这样的模板。这里有一个预定义的格式，名为 `combined`，它也是一个很好的示例：

    ```
    log_format combined '$remote_addr - $remote_user [$time_local] '
                        '"$request" $status $body_bytes_sent '
                        '"$http_referer" "$http_user_agent"';
    ```

如你所见，`log_format` 指令的第二个参数是一个由“有意义”名称组成的长变量列表。变量之间及其周围的所有字符都会包含在日志中。变量会在日志记录时进行评估，并且它们的值会占据各自的位置。

让我们来看一个使用这个模板生成的日志记录的真实示例：

```
85.90.193.224 - - [01/Feb/2016:12:01:34 +0400] "GET / HTTP/1.0" 200 137426 "http://example.com/" "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:33.0) Gecko/20100101 Firefox/33.0"
```

你可能非常熟悉之前使用 Nginx、Apache 或其他 Web 服务器软件时的联合日志格式。然而，逐一了解每个联合日志行中的项目，可能会给你带来一些意想不到的见解。让我们解析这个示例记录，并在这个过程中了解一些关于这些变量的事实：

|

```
$remote_addr 85.90.193.224
```

| 这是向我们的服务器发起请求的计算机的 IP 地址。绝对不要将其解析为由点分隔的四个十进制整数。即使是 `[0–9.]+` 的正则表达式也不够好。你能猜出原因吗？原因如下：

```
2001:470:1f10:1::2 - - [28/Jan/2015:02:28:19 +0300] "HEAD / HTTP/1.1" 200...
```

我们正生活在生产环境中使用 IPv6 的时代。大网站的 1–7% 流量来自 IPv6（数据来自 2015 年末）。Nginx 已完全准备好，所以确保你的日志解析器也做好了准备。

|

```
"- -"
```

| 第一个破折号是遗留部分。当这个特定的日志格式在很久以前诞生时，远在 Nginx 之前，有一种名为 `ident` 的有趣协议，它允许主机向客户端计算机发起连接并请求发起特定 TCP 连接的用户的名字。如果你感兴趣，可以查看 RFC 1413（[`tools.ietf.org/html/rfc1413`](https://tools.ietf.org/html/rfc1413)），但我们应该说 `ident` 已经死掉了，现在除了 IRC 网络之外没有地方使用。Nginx 甚至没有实现它；这个字段应该始终硬编码为 `-`。下一个破折号是“远程用户”，由 HTTP 认证机制标识。这比 ident 略微流行一些，但差距不大。HTTP 认证相对常用的一个场景是关闭网站测试版本，以防止被窥探（比如：GoogleBot 和其他不加区分的爬虫）。如果你想了解如何配置 HTTP 认证，请参考在线文档：[`nginx.org/en/docs/http/ngx_http_auth_basic_module.html`](http://nginx.org/en/docs/http/ngx_http_auth_basic_module.html)。 |
| --- |

|

```
"[01/Feb/2016:12:01:34 +0400]" $time_local
```

| 这是日志记录的日期/时间戳。肯定不是最方便解析的日期/时间格式。在处理时区时要小心。它仍然允许前缀匹配，你可能经常执行类似于：**% fgrep "01/Feb/2016:12:01:" /var/log/nginx/access.log** 这样的命令来筛选在特定分钟内处理的所有页面访问。这是一个更复杂的版本，应该是你工具包中的一部分：

```
% cat /var/log/nginx/access.log &#124; awk '{print $4}' &#124; awk -F : '{print $2 ":" $3}' &#124; uniq -c

```

它会打印出每天每分钟的点击次数。通过这个命令，你可以识别出可能表明存在问题的流量高峰。有趣的是，原始版本要简单一些：**% cat /var/log/nginx/access.log &#124; awk -F : '{print $2 ":" $3}' &#124; uniq -c**，但 IPv6 进入了我们的生活。

|

```
"GET / HTTP/1.0" "$request"
```

| 这是整个 HTTP 请求的字符串表示形式。要注意什么？你会惊讶地发现，除了 `GET` 和 `POST`，你还会看到 `HEAD` 请求。它是一个很少被讨论的“GET 的小弟”，它不应该返回实际的响应体——仅返回响应的头部。你不会经常看到 `HTTP/1.0` 作为协议。现代浏览器会发出 `HTTP/1.1` 请求。这里的其他值应该引起警觉。你会看到诸如 `SIP/2.0` 或 `RTSP/1.0` 之类的东西；这些确实是合法的协议，但如果在网站上而不是在 `SIP` 或 `RTSP` 端点上看到这些请求，那很可能是恶意行为者（或研究人员）在扫描。 |
| --- |

|

```
200  $status
```

| 这是 HTTP 状态码。除了 2xx 或 3xx，任何其他状态码都表示错误。要获取 HTTP 状态码的完整、现代且权威的列表，请参考 RFC 7231 ([`tools.ietf.org/html/rfc7231`](https://tools.ietf.org/html/rfc7231))——这是对 HTTP/1.1 规范的一个相对较新且期待已久的更新，发布于 2014 年 6 月。 |
| --- |

|

```
137426 $body_bytes_sent
```

| 这个不需要解释。我们应该补充说明，它已经考虑到了任何压缩。它也可以作为后端问题的快速指示器。经过一段时间后，你会学会发现异常小的响应大小，这意味着后端出现了问题，生成了一个短的错误页面而不是正常的响应。正确的后端也会发送非 2xx 状态码，但并不是所有（甚至不是许多）后端都会这样做。这个小的 Perl 脚本会搜索小于该 URL 平均响应大小十分之一的响应，且小于某个硬编码的块大小阈值，通常用于下载文件的一部分：[`kapranoff.ru/~kappa/nginx-troubleshooting/blips.pl`](http://kapranoff.ru/~kappa/nginx-troubleshooting/blips.pl)。我们不会逐行讲解；它只是一个示例而已。其思路是对日志进行两次处理。第一次是计算每个 URI 的平均字节数，第二次是实际寻找异常值。 |
| --- |

|

```
"http://example.com/" "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:33.0) Gecko/20100101 Firefox/33.0" '"$http_referer" "$http_user_agent"'
```

| 这些直接来源于 HTTP 请求头部；它们是由 HTTP 客户端（通常是浏览器）发送的。这使得它们很有趣，但也不可靠。它们基本上是通过网络发送到服务器的字符串。你不能相信客户端发送的任何东西。你会经常看到一些奇怪的用户代理字符串，声称来自未来或过去。你还会看到一些指向完全虚假的网站的引荐 URL，这些网站上没有指向你网站的链接，反而试图通过各种当时流行的恶意软件感染你。值得一提的是，我们仍然记得在 2007 年夏末，第一次在我们的访问日志中看到 iPhone 的兴奋时刻，那真是太有趣了。 |
| --- |

你可以通过使用 Nginx 在处理每个请求时提供的不同变量，向访问日志中添加大量信息。

这些变量的完整列表请参见[`nginx.org/en/docs/varindex.html`](http://nginx.org/en/docs/varindex.html)。

还有一些变量仅在日志记录生成期间可用，这些变量在`log_format`指令的描述中列出，详细内容请参见[`nginx.org/en/docs/http/ngx_http_log_module.html#log_format`](http://nginx.org/en/docs/http/ngx_http_log_module.html#log_format)。

推荐继续以`combined`格式保存日志，以便使用社区多年来创建的大量工具。除了这些，你还可以创建一些扩展日志，包含更多数据，帮助你调试问题。

以下是一些通常有用，但不包含在默认`combined`格式中的变量列表：

|

```
$gzip_ratio
```

| 压缩响应大小与原始响应大小的比率，或者如果响应未压缩则为`"-"`。这看起来似乎不重要，但它使得`$body_bytes_sent`更加有用。拥有这个变量可以帮助你发现不支持 gzip 压缩的客户端。对于这些客户端，`$body_bytes_sent`的值会比平时高。 |
| --- |

|

```
$msec
```

| 精确的时间戳，精确到毫秒。这与`$time_local`提供的人类可读时间相同，但在每秒有大量请求时，毫秒的精度非常重要。 |
| --- |

|

```
$request_length
```

| HTTP 请求的大小。GET 请求通常较短，但一旦超过一千字节，你就应该考虑是否每个请求携带了过多的 cookie。POST 请求可以是任何大小，如果你的应用需要接收用户提交的重要数据，例如文件或填写的表单，你将希望监控这些请求的大小。后面本章会介绍一种记录 POST 请求内容的技术。 |
| --- |

|

```
$request_time
```

| 请求开始到响应结束之间的时间。基本上，这是你的性能数据原子，包括网络延迟和处理延迟。 |
| --- |

|

```
$sent_http_content_type
```

| 这是响应的内容类型，通常以`text/html`或`application/pdf`的形式呈现。它不是必需的，但在查看现代 Web 应用程序的日志时非常有用，可以帮助你发现某个 JSON 处理器突然输出了一个简单的 text/html 响应。它也有助于计算按数据类型划分的总流量。这里提到的 MIME 类型也在第一章中讨论，*Nginx 配置中的问题排查*。 |
| --- |

|

```
$cookie_*
```

| 星号应该替换为你某个 cookie 的名称。大多数现代网站都有某种机制来管理有状态的用户会话。通常，会有一个名为 `session` 或 `session_id` 的 cookie，用于恢复一个用户在单个会话内发出的请求链。当分析标准的组合格式日志时，会使用远程 IP 地址，但当多个用户共享同一个 IP 地址，或同一用户在不同 IP 地址之间跳转时，这种方法就会失败（这两种情况都是非常正常的）。 |
| --- |

|

```
$host
```

| 这个字段包含了处理请求的主机名。它看起来可能有些冗余，因为通常不同的主机会将日志记录到不同的文件中。然而，你会惊讶地发现，来自多个主机的日志经常被一起处理，不论是在同一个日志存储集群中，还是使用相同的日志分析软件。将主机名直接写入日志可以避免关心日志文件名的麻烦，而当你不再愿意每次都运行 `grep` 来查找文件并将所有内容加载到数据库中时，你会记得是你决定加入 `$host` 并感激自己。 |
| --- |

## 记录 POST 请求

一旦你开始通过访问日志追踪用户请求和应用响应来调试在 Nginx 实例后运行的 Web 应用程序的问题，你会发现 GET/HEAD 请求会被完整记录，而 POST 请求的日志记录仅包含数据被提交的 URI，没有任何其他信息。这是许多系统管理员常见的问题，特别是在仅尝试使用 `tcpdumps` 时。`tcpdump` 是一个非常棒的协议跟踪瑞士军刀，但它需要在需要跟踪的事件发生时进行积极的参与。而且，用 `tcpdump` 跟踪 HTTPS 是非常困难的。

Nginx 能够记录 POST 请求的正文以及更多内容。你应该已经具备足够的能力，至少可以尝试自己实现这种日志记录。

记得我们讨论过自定义日志格式并使用变量记录请求和响应的状态。如果你查看请求处理过程中可用的变量列表，你会看到一个名为 `$request_body` 的变量。请参见 [`nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body`](http://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body)。

让我们发明一个简单的日志格式，其中包括 `$request_body`：

```
log_format request_body_log 'body: "$request_body"';
```

现在我们通过添加以下指令来启用这种格式的日志记录：

```
access_log /var/log/nginx/requests.log request_body_log;
```

记住，`log_format` 指令应该在较高的上下文中使用，例如 `http` 上下文。可能会有多个 `access_log` 指令作用于所有请求，因此我们不需要在 `request_body_log` 格式的模板中指定其他变量。你通常预配置的组合格式日志仍然会被写入。

对于一些简单的 GET 请求，下载几个静态文件时，我们会在 `requests.log` 中看到什么？

```
body: "-"
body: "-"
body: "-"
```

确保在继续之前你已经理解了结果。

现在，我们需要 POST 请求。而针对静态文件的 POST 请求是没用的。实际上，它们根本不会发生。客户端将数据 POST 到 Web 应用程序，对于 Nginx 管理员而言，Web 应用程序是一个上游，Nginx 将请求代理到该上游，并从中代理回响应。

假设我们构建一个这样的应用程序。它将是一个非常简单的 Perl Dancer 应用，接受一个简单的 POST 请求并响应一段*动态 HTML*。

源代码在 [`kapranoff.ru/~kappa/nginx-troubleshooting/simple-post.pl`](http://kapranoff.ru/~kappa/nginx-troubleshooting/simple-post.pl)：

![日志记录 POST 请求](img/B04329_02_01.jpg)

现在，我们将在 Nginx 实例中设置代理：

```
location /simple-post {
    proxy_pass http://localhost:3000/;
}
```

我们将浏览器指向`http://localhost/simple-post`。

如果 Dancer 应用程序正在运行，你将看到一个简单的表单，包含一个字段和一个按钮。输入内容，点击按钮，然后赶紧查看你的`requests.log`：

```
body: "-"
body: "a=Nginx+rules%21"
```

第一行是 GET 请求的空体，用于表单，而第二行包含了通过浏览器帮助生成的 POST 体。HTML 表单可以有两种方式将数据编码为 POST 体；这一个是默认的**application/x-www-form-urlencoded**。另一种是**multipart/form-data**；它广泛用于允许文件上传的表单。这已经超出了本书的讨论范围。值得一提的是，表单编码正在迅速成为过去式，因为越来越多的 POST 体是由客户端 JavaScript 和浏览器本身构建的。

这里重要的是，你现在有了一种简单的方式来记录通过 POST 请求传来的数据。

## 条件日志记录

这个示例还将展示一个较新的 Nginx 日志功能，名为*条件日志记录*。

指令`access_log`有多个可选参数，其中之一是参数`if`，它指定了在某个条件下将记录附加到此特定访问日志。当我们在前一节配置请求体日志时，结果仍然是一个充满了“-”;这些是所有非 POST 请求的空体。现在让我们来修复这个问题。首先，我们向`access_log`指令添加一个条件：

```
access_log /var/log/nginx/requests.log request_body_log if=$method_is_post;
```

我们使用的条件是一个简单的自定义变量。我们故意使用与官方文档中非常相似的语法来展示这一技术，文档地址为：[`nginx.org/en/docs/http/ngx_http_log_module.html#access_log`](http://nginx.org/en/docs/http/ngx_http_log_module.html#access_log)。

所以下一步是创建这个变量。Nginx 中有几种方法可以创建变量。最直接的方法是在`if`上下文内使用`set`指令。但每当你看到 Nginx 配置文件中的`if`指令时，最好都要谨慎。`if`应该始终是最后的选择。记住，配置文件中并没有编程的功能，一切都应该尽可能声明式。

并且有一种很好的声明式方法来创建变量：

```
map $request_method $method_is_post {
    POST 1;
    default 0;
}
```

这就是启用条件日志记录所需要做的一切。如果你的 Nginx 版本足够新，从现在开始你只会在`requests.log`中记录 POST 请求的请求体。

可能你的 Nginx 版本不够新（至少需要 1.7.0）。使用`nginx -t`来测试配置。你能想出一种在不升级 Nginx 的情况下绕过这个问题的方法吗？这不是一个假设性问题。推荐使用由你的发行版提供的 Nginx 包进行安装，这些包通常会比较旧。

## 记录大请求体

关于记录请求体，还有一件事要告诉你。实际上，有两件事在具体表现上完全相同，但原因不同。

变量`$request_body`即使在数据有效的 POST 请求情况下，也不能保证一定有内容。`$request_body`为空的第一个可能原因是 Nginx 判断不需要解析请求体，并因此进行了优化。这是一种文档中有说明的行为，往往在最意想不到的时候发生。文档中清楚地指出：

> *“变量的值会在由 proxy_pass、fastcgi_pass、uwsgi_pass 和 scgi_pass 指令处理的位置中提供。”*

自行查看：[`nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body`](http://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body)。

这四种情况是 Nginx 填充`$request_body`变量的唯一方式。幸运的是，POST 请求如果没有包含任何这些指令的 location 非常罕见。POST 请求的目的是接收客户端的数据，并将其传递给 Nginx 作为代理的服务器应用程序。

小心不要在调试一些不常见的 POST 请求配置时被空请求体所困扰，尤其是在该上下文中没有代理指令的情况下。

`$request_body`为空的另一个原因是请求太大。如果请求体的大小超过了`client_body_buffer_size`指令设置的值，那么就不能通过`$request_body`变量访问请求体。相反，整个请求体会被保存在文件系统的临时文件中，并且其文件名会被写入新的`$request_body_file`变量。

还有一个非常有趣的指令叫做`client_body_in_file_only`，它提供了一种总是将请求保存到文件中的方式。它可以完全替代我们之前展示的机制！你需要将`$request_body_file`添加到你的某个日志格式中，并启用`client_body_in_file_only`。启用后，Nginx 会创建一个不断增长的文件存储，包含所有你的请求体。不要忘记通过 crontab 清理这些文件，否则它们会填满文件系统。

# 创建日志周围的基础设施

好的，来做些算术。假设你有一个相当受欢迎的网站，虽然还没有达到全球规模（但会有的），每天有大约 50,000 次访问。这是一个经理们在聚会中常常炫耀的数字；他们从某些分析软件中获取这个数字。对你来说，它几乎没有任何意义。因为访问到底是什么？假设你有一个电商网站，卖一些非季节性商品，例如电动工具。你的平均访问者会浏览一到两页，选择并购买某些商品时，页面浏览量会飙升到十几页。假设每次访问平均浏览三页。什么是页面？对你来说，它是一系列的 HTTP 响应——主文档和所有嵌入的对象。人们常常低估现代网页的庞大规模。可以大胆地说，你的网页平均包含 100 个对象（HTML 文档、图片、脚本、样式表等），这些加起来的大小超过了一兆字节。

这将是 100 x 3 x 50,000 次访问/天，或者 15,000,000 / 24 / 3600 = 平均每秒 174 次请求（RPS）。如果你只是在白天平均 RPS，这个数字几乎没有意义，除非你在全球所有时区都有运营，而对于销售实际商品的网站来说，这并不常见。估算峰值有一个不错的启发式方法——将平均值乘以 10。

现在我们有了你的日常访问日志中的行数（1500 万行）和你必须处理的日志速率的一个非常粗略的上限（每秒一千五百行）。这些数字意味着你需要工具，因为一个人不可能及时消化所有这些信息。

## 配置日志轮换

使日志数据量更易于管理的主要且最简单的工具就是日志轮换。你可能已经设置好了它。许多 Linux 发行版中都包含了一个非常标准的日志旋转工具，名为`logrotate`。它在 FreeBSD 中的对应工具是`newsyslog`。

这里展示了`logrotate`和`newsyslog`中 Nginx 日志轮换配置的示例。

这是一个来自 Linux 主机的`logrotate`配置示例：

![配置日志轮换](img/B04329_02_02.jpg)

这是一个来自相当现代的 FreeBSD 服务器的`newsyslog`示例配置：

![配置日志轮换](img/B04329_02_03.jpg)

它们的做法是通过根据当前文件的时间和大小创建旧记录的归档来处理巨大的日志文件。这并不是很复杂，但至少有几个陷阱是通过数字吸引人的。

首先，一定要进行磁盘空间监控，并且还要监控你的磁盘空间监控。磁盘空间不足是导致重大故障的一个令人惊讶的常见原因。正如出版社曾警告我们，在我们写这本书时，硬盘可能会出现故障，因为它们总是会出现故障，我们也冒昧地提醒你，至少在你的一生职业生涯中，磁盘会因为日志而被填满。通常，这会导致一些非常不愉快的后果，但很容易修复。

那么，预防措施是什么？建立一个日志存储。它应该是几台配备大容量、廉价（带旋转部件）镜像磁盘的独立机器，用于无限期存储日志。它们的目标是将你的实际 web 服务器从存储日志归档和运行繁重的 `grep` 操作中解放出来，从而避免影响性能。而且你的旋转程序应该包括在创建日志归档后，将每个归档文件复制到日志存储库中。你的过程可能会变得更加复杂，因为你最当前的日志仍然分布在 web 服务器上，而较旧的数据已经归档到日志存储中，但这绝对是值得的。

此外，使用比默认的 gzip 更好的压缩算法。在日志的这个特定情况下，通过从 gzip 切换过来，你可能能节省多达 50% 的空间。`logrotate`支持指定用于压缩的命令，而`newsyslog`原生支持 bzip2 和 xz 压缩。xz 通常更好。使用 xz 的唯一缺点是对内存的高要求；请记住这一点。再次强调，独立的日志存储非常有用。它还可以配置为将已压缩的 gzip 文件重新压缩为 xz，从而节省空间而不牺牲 web 服务器的性能。其思路是先在 web 服务器上使用 gzip 压缩日志，然后将它们移到日志存储集群，再进行解压缩，然后使用 xz 重新压缩。

日志轮换的第二个重要部分是在实际轮换过程中不丢失任何记录。最优的算法如下：

1.  首先，假设 Nginx 正在运行，并将日志记录写入某些`access.log`文件。

1.  启动日志旋转程序，`access.log`根据大小或时间选择进行处理。

1.  日志旋转程序根据轮换方案重命名`access.log`，例如，将其重命名为`access.log.0`。

1.  日志旋转程序创建一个新的空`access.log`文件。

1.  现在，Nginx 不会丢失对旧文件的访问，因为它已经拥有文件描述符，而文件名在文件被进程打开后就不再重要。所以，Nginx 会继续向`access.log.0`文件中写入记录。

1.  日志旋转程序无法压缩旧文件，因为它仍在写入，因此它通知 Nginx 释放旧的文件描述符并通过文件名重新打开日志文件。

1.  Nginx 很乐意配合。新的空的 `access.log` 会被打开，并开始接收新的日志记录，而旧文件则准备在压缩后被删除。

1.  日志旋转工具运行压缩程序，在删除旧日志的同时创建一个新的文件 `access.log.0.xz`。

看起来这项看似简单的操作实际上非常复杂。原因在于步骤 4、5 和 6，它们保证了日志不会在 Nginx 不知情的情况下被重命名或删除。

这里没有任何 Nginx 特有的内容。恰好作者们考虑到了这个问题，并在 Nginx 中实现了特殊的 `reopen` 命令，通过向主进程发送 USR1 信号来启动。

如果你的日志旋转工具完全省略了该命令，日志旋转将完全无法工作——Nginx 会一直写入旧的日志，而不会察觉你已重命名它。而试图压缩一个正在被附加内容的文件，则可能丢失一些行。

如果你的日志旋转工具在每次旋转时都会重新启动 Nginx，那么你的日志会没问题，但如果你进行优雅重启（使用 SIGHUP 信号），可能会损失一些性能。如果进行硬重启（老式的 `apachectl restart` 重启方式，虽然 Nginx 可执行文件不支持，但可以通过操作系统的 init 脚本来实现），你甚至可能丢失一些请求。

## 处理大量日志数据

一旦你的 Nginx 安装每天的用户量超过几千人，你或你的管理者一定会希望从这些日志中获得更多的洞察。你的工作就是为此提供基础设施并排查问题。你还可以借此机会，最终实现一个比传统的 `grep` 更高效的日志实时搜索系统。

日志分析的发展历程是一个有趣且庞大的话题，大多超出了本书的范围。我们中的许多人记得（或许还记得）臭名昭著的 Webalizer 和 AWStats 工具包。顺便说一下，即使有些过时，它们仍然能正常工作。不过，对于现代网站来说，不建议继续投入这些工具。它们效率不高，且你很难增加当今期望的功能。

市面上一些较新的解决方案总结如下。无论如何，请进行你自己的研究。这本身是一个庞大的话题：

+   logstash/ElasticSearch/kibana 堆栈是由基于 Java 的工具组合而成，每个工具都值得单独撰写一本书。一个正常部署的系统可以让你将所有日志存储在一个经过索引的数据库中，方便各种查询和报告。该堆栈中的 kibana 部分提供了基于时间的数据的精美可视化展示。日志正是这种数据，完全契合。维护一个实例可能很快会变成一份全职工作。

+   Scribe 是一个由 Facebook 开发、开源并最终弃用的中央日志解决方案。它仅具历史意义。Facebook 已经不再使用 Scribe，如果你仍然有 Scribe 安装或继承了 Scribe，你就麻烦了。一个较为简单的替代方案是 Fluentd。

+   **Fluentd** 是一个现代化的集中式日志系统，使用 Ruby 编写。它可以与第一堆栈中的 logstash 部分进行比较。它具有可插拔的输入和输出。配置好以消费 Nginx 日志后，它可以将结果传递给 ElasticSearch 实例。

+   **Apache Flume** 是 Apache Hadoop 技术栈中的一个较旧项目。它用于将数据收集到你的 HDFS（Hadoop 的存储系统）中。有时也用于 Web 日志。

+   **Splunk** 是一个商业的全栈解决方案，用于收集、解析、存储和查询日志。它自称为“你的日志搜索引擎”，我们对此不做评论。Splunk 很有趣，因为它也广泛用于对传入的日志进行实时监控。一个典型的应用场景是入侵检测。

## 阅读日志

对许多读者来说，最有趣的部分是我们将展示来自真实 Nginx 日志文件的不同记录示例，并分析每个案例中发生了什么以及如何修复它们。这些将是相对简单的情况，其中许多对经验丰富的 Web 系统管理员来说可能是熟悉的，或者可以从信息中显而易见。

我们仍然建议你跟随每一个示例。有时候，人们会对自己不完全理解的事物产生一种选择性失明的现象。跳过不明部分并尝试从周围的内容推测其意义是很自然的——这就是语言学习对儿童和成年人来说都如此有效的原因。可惜的是，人类语言高度冗余，因此特别适合非完美的、损失性理解。而日志通常不是这样。

让我们从一个非常简单且非常著名的 404 错误开始——并从错误日志和访问日志两个角度来看它的表现。

错误日志中的记录：

```
2016/01/29 02:25:14 [error] 18876#0: *1 "/home/kappa/books/index.html" is not found (2: No such file or directory), client: 127.0.0.1, server: localhost, request: "GET /books/ HTTP/1.1", host: "kantara"
```

现在是来自 `combined` 格式访问日志中关于同一事件的记录：

```
127.0.0.1 - - [29/Jan/2016:02:25:14 +0300] "GET /books/ HTTP/1.1" 404 151 "-" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:35.0) Gecko/20100101 Firefox/35.0"
```

我们现在将详细解析这两者。

### 错误日志记录

|

```
"2016/01/29 02:25:14"
```

| 这显然是一个时间戳，但请注意，它没有包含任何时区信息。这是服务器在其配置的时区下看到的本地时间。这个小细节意味着，当你将此日志文件传输到另一个时区并且没有在某处保存时区信息时，软件可能会变得困惑，并应用新的本地时区。之后，将这个时间戳与来自 `access_log` 的时间戳进行比较就会出错。 |
| --- |

|

```
"[error]"
```

| 这是消息的严重性级别。记得在本章前面我们讨论过`error_log`指令的格式，其中有第二个参数，即阈值。好吧，这个字段就是用来与配置的阈值进行比较，以确定某条消息是否严重到需要打扰系统管理员处理。其他可能的值包括从`debug`到`emerg`（紧急）。查看`error_log`指令的文档：[`nginx.org/en/docs/ngx_core_module.html#error_log`](http://nginx.org/en/docs/ngx_core_module.html#error_log)。 |
| --- |

|

```
"18876#0:"
```

| 现在，这一部分很多人并不理解。那对数字提供了关于哪个 Nginx 进程路径将此记录写入日志的信息。`#`前面的数字是 PID，表示进程标识符，第二个数字是线程标识符（TID）。在当前版本的 Nginx Linux 上，TID 通常是`0`。在 Windows 上，它可能是一个较大的数字。当前版本的 Nginx 不使用多线程。关于 Nginx 2.0 版本，已经有传言说所有平台上的线程会更加突出。 |
| --- |

|

```
"*1"
```

| 这是在发生错误的连接上下文中的标识符。实际上，它是一个整数计数器，允许你按连接分组错误。顺便说一句，很多 Nginx 用户并不认识连接编号和前一项中的 TID 部分。你可以在某次机会给你的同事们一个惊讶，看看他们是否知道这些内容，纯粹是为了好玩。 |
| --- |

|

```
"/home/kappa/books/index.html" is not found (2: No such file or directory)
```

| 这是 Nginx 生成的实际错误消息，后面跟着操作系统级别的`errno`编号（在此案例中为`ENOENT`）和括号中的`strerror`消息。 |
| --- |

|

```
"client: 127.0.0.1, server: localhost"
```

| 这是连接两端的地址。我们在工作站上运行 Nginx。这就是为什么我们看到通过回环连接的原因。Nginx 出于性能原因选择不对客户端地址进行反向 DNS 解析，而服务器名称是预先已知的。这就是为什么我们在 IP 和域名形式中看到相同的地址。 |
| --- |

|

```
request: "GET /books/ HTTP/1.1", host: "kantara"
```

| 现在，这是关于实际请求的数据。首先是请求本身的字符串表示，然后是从浏览器发送的 Host: HTTP 请求头中获取的主机值。 |
| --- |

有趣的是，除了记录中的第一个项目，其他的内容或多或少是自由格式的，且不是必须的。时间戳显然总是存在的，pid 和 tid 也是（特别是当它是常量`0`时），但连接并不总是处于连接状态，当然，如果没有连接，也可能没有当前的请求。

错误日志因其机器可读性差而著名。除非你确保整个记录是通过已知且固定的模板写入的，否则永远不要依赖记录中存在某种类型的数据。例如，解析所有的`ENOENT`消息相对容易，但创建所有错误类型的汇总将会更困难。

相反，访问日志是为了便于解析而设计的。我们再来看一遍这个记录：

```
127.0.0.1 - - [29/Jan/2016:02:25:14 +0300] "GET /books/ HTTP/1.1" 404 151 "-" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:35.0) Gecko/20100101 Firefox/35.0"
```

我们之前已经分析过一个合并记录，因此这里不再重复。我们只看两个有趣的部分。

我们提到过那个奇怪的历史日期/时间戳格式，但至少它包含了时区，并且是完全不含糊的。我们还可以看到著名的`404`代码出现在第六个字段中，这是唯一的错误标识！除此之外，这是一个完全正常的 HTTP 请求，并且得到了一个恰到好处的 151 字节的 HTTP 响应。

当你启动一个新的网站时，日志中会有两个非常流行的 404 错误：

```
2016/02/09 19:09:11 [error] 39110#0: *1019042 open() "/site/example.com/www/robots.txt" failed (2: No such file or directory), client: 157.55.39.200, server: example.com, request: "GET /robots.txt HTTP/1.1", host: "example.com"
2010/10/17 22:44:05 [error] 44858#0: *809 open() "/site/example.com/favicon.ico" failed (2: No such file or directory), client: 95.26.237.86, server: example.com, request: "GET /favicon.ico HTTP/1.1", host: "example.com"
```

这些就是所谓的*常见*文件，HTTP 客户端会请求并使用这些文件。至少为了你自己的理智，你应该为你的网站准备一些`robots.txt`文件和一些 favicon。欲了解更多有关这些文件的信息，请参考[`www.robotstxt.org/`](http://www.robotstxt.org/)和[`en.wikipedia.org/wiki/Favicon`](https://en.wikipedia.org/wiki/Favicon)。

是时候再看看一些错误了：

```
2016/02/09 13:19:00 [error] 39110#0: *1014628 kevent() reported that connect() failed (61: Connection refused) while connecting to upstream, client: 204.8.105.53, server: example.com, request: "GET /admin.php HTTP/1.0", upstream: "http://127.0.0.1:3000/admin.php", host: "example.com"
```

你应该几乎不费力地阅读这些内容。这是 Nginx 作为代理的一个例子，而这无疑是它最常见的使用方式。作为代理，这个 Nginx 实例试图代表客户端连接到上游。遇到问题的上游在日志的最后列出，位于熟悉的主机项之前。提到的`kevent()`是所谓的*实现细节*，它不应该泄露到这里，但事实就是如此。它是 Nginx 在 FreeBSD、Mac OS X 和其他 BSD 操作系统中用于处理网络连接的机制的一部分。

在 Linux 系统上，同样的记录会是这样的：

```
2014/07/29 10:18:41 [error] 14243#0: *100053182 connect() failed (111: Connection refused) while connecting to upstream, client: 37.73.249.120, server: example.com, request: "GET /example.com/404 HTTP/1.1", upstream: "http://[2c32:6d8:0:172a::318]:8080/", host: "example.com"
```

那个记录中有什么有趣的地方？首先，没有`kevent()`。其次，`errno`代码发生了变化！事实上，我们的 FreeBSD 和 Linux 系统分别为`ECONNREFUSED`提供了 61 和 111 的错误码。所以不，你不能依赖这个代码，更不能依赖`Connection refused`这个字符串。在 Windows 系统中，同样的错误可能会显示这个信息：**10060：连接尝试失败，因为连接方在一段时间后没有正确响应，或者已建立的连接因为连接主机未响应而失败**。

其次，上游正在使用 IPv6，这可能会破坏一些脚本，特别是如果它们在第一个冒号后查找 TCP 端口号的话。

我们想向你展示另一种特殊的**文件未找到**错误，这些错误是现代时代的标志：

```
2016/01/24 18:28:09 [error] 39111#0: *755667 open() "/site/example.com/www/wp-login.php" failed (2: No such file or directory), client: 109.198.238.60, server: example.com, request: "GET /wp-login.php HTTP/1.1", host: "www.example.com"
2016/01/24 18:27:01 [error] 39111#0: *755651 open() "/site/example.com/www/administrator/index.php" failed (2: No such file or directory), client: 82.199.126.95, server: example.com, request: "GET /administrator/index.php HTTP/1.1", host: "example.com"
```

这些部分之所以有趣，是因为它们来自一些试图攻击你系统的机器人。它们非常坚持地尝试一些看起来像是管理或登录脚本的 URL，而这些脚本从未在你的网站上出现过。

对他们来说，随便尝试互联网上的任何主机都太便宜了，而不管是否有一个记录失败尝试的数据库。他们会来自成千上万不同的 IP 地址，其中许多看起来完全无害，因为这些计算机遍布全球，都是被集中控制的感染机器。它们已经成为常态；你通常不需要采取任何对策（除非你运行的是一个旧版的 WordPress 安装，在这种情况下，你可能已经被黑客入侵，并且通过为这些人提供一些色情广告赚取收益）。

这是一个包含较少信息的错误：

```
2014/07/29 00:00:18 [info] 14238#0: *95951600 client 77.205.98.18 closed keepalive connection
```

你能猜到为什么吗？因为，正如我们前面提到的，错误是时常发生的，即使没有正在处理的请求。正是这种情况：客户端关闭了一个在请求/响应成功配对后仍保持打开的连接，这样可以优化随后的请求。这种方式叫做 KeepAlive。Nginx 非常乐意通过一个连接服务多个请求，但客户端可以随时关闭该连接。现在你应该明白为什么这个信息显示的是`[info]`而不是`[error]`了。是否应该对此采取措施的问题留给你自己思考。

```
2014/07/29 00:02:11 [info] 14241#0: *95959742 client timed out (110: Connection timed out) while waiting for request, client: 62.90.94.31, server: 0.0.0.0:443
```

一条类似的消息没有任何关于请求的信息，因为实际上它是因为无法在超时前获取请求而发生的错误。

```
2014/07/29 00:00:18 [info] 14238#0: *95951764 SSL_read() failed (SSL: error:14094412:SSL routines:SSL3_READ_BYTES:sslv3 alert bad certificate:SSL alert number 42) while waiting for request, client: 176.115.120.138, server: 0.0.0.0:443
```

这是一个相当神秘的错误信息，你可能无法对其做任何处理。SSL 代码非常复杂，而且有许多奇怪的 SSL 实现。某些地方出错了。你应该注意，并尝试重现或等待更多相同的错误。

```
2014/07/29 00:02:24 [info] 14240#0: *95968051 client sent too long URI while reading client request line, client: 87.244.170.11, server: example.com, request: "GET /log_error?login=takoe&error=<some very-very long string>
```

我们手动裁剪了这个，因为它几乎占据了整个屏幕。请求头的总大小是有限制的。这个限制可以通过`large_client_header_buffers`指令来更改。有关更多信息，请参见 [`nginx.org/en/docs/http/ngx_http_core_module.html#large_client_header_buffers`](http://nginx.org/en/docs/http/ngx_http_core_module.html#large_client_header_buffers)。这肯定是一个你可以通过增加配置值来修复的问题，但我们不建议这样做，应该与应用程序开发团队沟通。看起来他们为自己的任务选择了错误的工具。如此大的请求应该使用 POST 方法，而不是 GET。

这里还有另一个错误，我们想展示一下作为一些大型网站有时面临的挑战：

```
2013/05/16 12:21:11 [crit] 21947#0: *31843937 open() "/usr/local/nginx/html/50x.html" failed (24: Too many open files), client: 88.2.3.44, server: example.com, request: "GET /file/images/background.jpg HTTP/1.1", upstream: "http://10.10.4.1:81//file/images/background.jpg", host: "example.com"
```

你现在应该能够读取并理解这个信息中的每一个字符了。**24: Too many open files**到底是什么？这是对单个进程可以打开的文件数量的限制。通常，这个限制是非常大的。运行以下命令查看你当前的 shell 限制：

```
% ulimit -Sn

```

一旦您的 Nginx 同时提供的文件超出了这个数量，这个错误就会出现在错误日志中。Nginx 有办法自动增加限制，参见[`nginx.org/en/docs/ngx_core_module.html#worker_rlimit_nofile`](http://nginx.org/en/docs/ngx_core_module.html#worker_rlimit_nofile)。增加所有进程的硬限制取决于操作系统。在 Linux 上，您需要将类似`fs.file-max = 50000`的内容添加到`/etc/sysctl.conf`中，然后运行以下代码：

```
% sysctl -p

```

### 提示

**下载示例代码**

您可以从您的账户下载本书的示例代码文件，网址为[`www.packtpub.com`](http://www.packtpub.com)。如果您在其他地方购买了本书，您可以访问[`www.packtpub.com/support`](http://www.packtpub.com/support)并注册，以便将文件直接通过电子邮件发送给您。

您可以通过以下步骤下载代码文件：

1\. 使用您的电子邮件地址和密码登录或注册我们的网站。

2\. 将鼠标指针悬停在顶部的**支持**标签上。

3\. 点击**代码下载与勘误**。

4\. 在**搜索**框中输入书名。

5\. 选择您要下载代码文件的书籍。

6\. 从下拉菜单中选择您购买本书的地方。

7\. 点击**代码下载**。

下载文件后，请确保使用以下最新版本解压或提取文件夹：

+   WinRAR/7-Zip for Windows

+   Zipeg/iZip/UnRarX for Mac

+   7-Zip/PeaZip for Linux

# 总结

在本章中，我们刷新了关于 Nginx 日志工作原理的知识。日志有两种类型；其中一种可以无限扩展，而另一种由于缺乏足够的结构，难以通过脚本解析。

我们花了一些时间讨论了特定主题，比如日志轮转和记录 POST 请求体（我们在本章中一步一步创建的小测试平台）。

我们还分析了几条来自真实错误日志的错误记录。

下一章将分析更多实际问题并进行故障排除。我们将展示一些人们在读取 Nginx 安装时遇到的实际问题，并尝试从头开始调试它们。
