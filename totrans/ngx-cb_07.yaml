- en: Reverse Proxy
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 反向代理
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍以下方案：
- en: Configuring NGINX as a simple reverse proxy
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置 NGINX 作为一个简单的反向代理
- en: Content caching with NGINX
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 NGINX 进行内容缓存
- en: Monitoring cache status
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控缓存状态
- en: Microcaching
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微缓存
- en: Serving from cache when your backend is down
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当后端系统不可用时，从缓存中提供服务
- en: SSL termination proxy
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SSL 终结代理
- en: Rate limiting
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 限流
- en: Introduction
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: One of the most powerful features of NGINX is its ability to act as a reverse
    proxy. As opposed to a forward proxy, which sits between the client and the internet,
    a reverse proxy sits between a server and the internet.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: NGINX 最强大的功能之一就是它能够作为反向代理。与客户端和互联网之间的正向代理不同，反向代理位于服务器和互联网之间。
- en: 'Here''s a visual representation:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个可视化示意图：
- en: '![](img/4848ed4f-ec12-4425-92da-4c6ca9e05f76.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4848ed4f-ec12-4425-92da-4c6ca9e05f76.png)'
- en: A reverse proxy can provide a multitude of features. It can load balance requests,
    cache content, rate limit, provide an interface to a **Web Application Firewall**
    (**WAF**), and lots more. Basically, you can greatly increase the number of features
    available to your system by running it through an advanced reverse proxy.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 反向代理可以提供多种功能。它可以负载均衡请求，缓存内容，限流，提供 **Web 应用防火墙**（**WAF**）接口，等等。基本上，通过让系统经过一个高级反向代理，你可以大大增加系统的功能。
- en: Configuring NGINX as a simple reverse proxy
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置 NGINX 作为一个简单的反向代理
- en: In this recipe, we'll look at the basic configuration of a simple reverse proxy
    scenario. If you've read the first few chapters, then this is how NGINX was configured
    in front of PHP-FPM and similar anyway.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方案中，我们将查看简单反向代理场景的基本配置。如果你已经阅读了前几章，你会发现这就是 NGINX 在 PHP-FPM 前的配置方式，差不多是一样的。
- en: Getting ready
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Before you can configure NGINX, you'll first need to ensure your application
    is listening on a different port than port `80`, and ideally on the `loopback`
    interface, to ensure it's properly protected from direct access.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在你配置 NGINX 之前，你首先需要确保你的应用程序监听的端口不是 `80`，并且最好是在 `loopback` 接口上，以确保它能够有效避免直接访问。
- en: How to do it...
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Here''s our `server` block directive to proxy all requests through to port
    `8000` on the localhost:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们的 `server` 块指令，用来将所有请求代理到本地的 `8000` 端口：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: How it works...
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: For all requests, the `location` block directive is set to proxy all connections
    to a specified address (`127.0.0.1:8000` in this instance). With the basic settings,
    NGINX doesn't manipulate any of the data, nor does it cache or load balance. Testing
    with a basic proxy method is always a good step before moving to a complicated
    configuration to ensure that your application or program will work as expected.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有请求，`location` 块指令将所有连接代理到指定的地址（此实例为 `127.0.0.1:8000`）。在基本配置下，NGINX 不会修改任何数据，也不会缓存或进行负载均衡。在转向复杂配置之前，使用基本代理方法进行测试总是一个好步骤，以确保你的应用程序或程序能按预期工作。
- en: To get around the fact that you don't want private information cached (and therefore
    potential information leakage), NGINX will check for both cookies and cache headers.
    For example, when you log in to a WordPress system, this login will return a `Set-Cookie`
    header and NGINX will therefore exclude this from being cached.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免缓存私人信息（从而可能导致信息泄漏），NGINX 会检查 Cookies 和缓存头。例如，当你登录到 WordPress 系统时，这次登录会返回一个
    `Set-Cookie` 头，因此 NGINX 会排除缓存该请求。
- en: There's more...
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'One thing to note when using a reverse proxy is that the headers back to your
    application will be based on the IP of the proxy. There are two choices here.
    The first is to use the logs from NGINX as the authoritative for reporting purposes.
    The second is to manipulate the headers so that we pass the correct IP through
    to the application. Here''s what our updated block directive looks like:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 使用反向代理时要注意的一点是，返回给你应用程序的头部将基于代理的 IP。这里有两个选择。第一个是使用 NGINX 的日志作为报告的权威来源。第二个是修改头部，以便将正确的
    IP 传递给应用程序。以下是我们更新后的块指令：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `X-Forwarded-For` header shows the full chain of servers which have proxied
    the packet, which could be multiple forward proxies. This is why we also have
    `X-Real-IP`, so that we ensure we have the real IP address of the client.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '`X-Forwarded-For` 头部显示了完整的服务器链，这些服务器可能是多个转发代理。正因如此，我们还需要 `X-Real-IP`，以确保我们获得客户端的真实
    IP 地址。'
- en: To ensure that the upstream hostname is sent through, we set the `Host` header
    field. This allows the upstream server to be name-based and can allow multiple
    hosts (that is, multiple websites) to be proxied under one configuration or one
    server.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保上游主机名能传递，我们设置了 `Host` 头字段。这使得上游服务器可以基于名称，并允许多个主机（即多个网站）在一个配置或一个服务器下进行代理。
- en: See also
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: 'Official NGINX proxy help: [http://nginx.org/en/docs/http/ngx_http_proxy_module.html](http://nginx.org/en/docs/http/ngx_http_proxy_module.html)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 官方 NGINX 代理帮助：[http://nginx.org/en/docs/http/ngx_http_proxy_module.html](http://nginx.org/en/docs/http/ngx_http_proxy_module.html)
- en: 'The NGINX proxy guide: [https://www.nginx.com/resources/admin-guide/reverse-proxy/](https://www.nginx.com/resources/admin-guide/reverse-proxy/)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NGINX 代理指南：[https://www.nginx.com/resources/admin-guide/reverse-proxy/](https://www.nginx.com/resources/admin-guide/reverse-proxy/)
- en: Content caching with NGINX
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 NGINX 进行内容缓存
- en: In addition to simply proxying the data through, we can use NGINX to cache the
    proxied content. By doing this, we can reduce the amount of calls to your backend
    service, assuming that the calls are able to be cached.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 除了简单地将数据代理通过外，我们还可以使用 NGINX 来缓存代理的内容。通过这样做，我们可以减少对后端服务的调用，前提是这些调用可以被缓存。
- en: Getting ready
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: As the caching is part of the standard NGINX platform, no additional prerequisites
    are required.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 由于缓存是 NGINX 平台的标准部分，因此不需要额外的先决条件。
- en: How to do it...
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'In order to enable the cache, first we need to define where to store the cached
    files. This needs to be set outside the `server` block directive and is best stored
    in the main `nginx.conf` file. Here''s the directive required:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了启用缓存，首先需要定义存储缓存文件的位置。此设置需要放在 `server` 块指令之外，最好存储在主 `nginx.conf` 文件中。所需的指令如下：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Make sure you create the directory and that NGINX has write access.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你创建了该目录并且 NGINX 拥有写入权限。
- en: 'Then, we can create a block directive to use this cache:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以创建一个块指令来使用这个缓存：
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: How it works...
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Firstly, the first parameter to the `proxy_cache_path` directive is the location
    of the cache files. You can choose any directory which makes sense to your server
    structure, but ensure that the NGINX user on your server has write access.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，`proxy_cache_path` 指令的第一个参数是缓存文件的位置。你可以选择任何符合服务器结构的目录，但请确保服务器上的 NGINX 用户具有写入权限。
- en: The `levels` parameter specifies how the cache is written to the system. In
    our recipe, we have specified `1:2`. This means that the files are stored in a
    two-level hierarchy. The reason this is configurable is due to potential slowdowns
    when there are thousands of files within a single directory. Having two levels
    is a good way to ensure this never becomes an issue.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`levels` 参数指定缓存如何写入系统。在我们的示例中，我们指定了 `1:2`。这意味着文件将存储在二级层次结构中。之所以可以配置这个，是因为当单个目录中有成千上万的文件时，可能会导致性能下降。设置两级结构是确保这个问题永远不会出现的好方法。'
- en: The third parameter, `keys_zone`, sets aside memory to store metadata about
    the cached content. Rather than a potentially expensive (system resource wise)
    call to see whether the file exists or not, NGINX will map the file and use in-memory
    metadata for tracking. In our recipe, we have allocated 2 MB and this should be
    sufficient for up to 16,000 records.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个参数 `keys_zone` 分配内存用于存储缓存内容的元数据。与其进行可能消耗系统资源的调用来检查文件是否存在，NGINX 将映射文件并使用内存中的元数据进行跟踪。在我们的示例中，我们分配了
    2 MB，这应该足够存储最多 16,000 条记录。
- en: There's more...
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: While writing the cache to disk may seem counter-intuitive from a performance
    perspective, you need to take into account that the Linux kernel will cache file
    access to memory. With enough free memory, the file will be read once and then
    each subsequent calls will be direct from RAM. While this may take more memory
    than a standard configuration, a typical website can be as little as 64 MB in
    total, which is trivial by modern standards.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管从性能角度来看将缓存写入磁盘似乎是违背直觉的，但你需要考虑到 Linux 内核会将文件访问缓存到内存中。只要有足够的空闲内存，文件会被读取一次，然后每次后续的调用都会直接从
    RAM 中获取。虽然这可能会占用比标准配置更多的内存，但一个典型的网站总内存仅为 64 MB，这在现代标准下是微不足道的。
- en: Having the cache disk-based means that it's also persistent between reboots
    or restarts of NGINX. One of the biggest issues with the cold start of a server
    is the load on the system until it has had a chance to warm the cache. If you
    need to ensure that the loading of any cache file from disk is as fast as possible,
    I'd recommend ensuring that the cache is stored on a high-speed **Solid State
    Drive** (**SSD**).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 将缓存存储在磁盘上意味着它也能在 NGINX 重启或重启后保持持久性。服务器冷启动时的最大问题之一就是在缓存被加热之前系统的负载。如果您需要确保从磁盘加载缓存文件的速度尽可能快，建议将缓存存储在高速
    **固态硬盘**（**SSD**）上。
- en: See also
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: "The NGINX caching guide: [https://www.nginx.com/blog/nginx-caching-guide/\uFEFF\
    ](https://www.nginx.com/blog/nginx-caching-guide/)"
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: "NGINX 缓存指南：[https://www.nginx.com/blog/nginx-caching-guide/\uFEFF](https://www.nginx.com/blog/nginx-caching-guide/)"
- en: Monitoring cache status
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控缓存状态
- en: When developing complex sites or rapidly changing content, one key aspect is
    to monitor where the content was served from. Essentially, we need to know whether
    we hit the cache or whether it was a miss.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发复杂的网站或快速变化的内容时，一个关键方面是监控内容的来源。基本上，我们需要知道是命中了缓存，还是未命中缓存。
- en: This helps us ensure that, if there are issues, or on seeing incorrect content,
    we know where to look. It can also be used to ensure the caching is working on
    pages where it's expected and being bypassed for areas where it shouldn't be.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这帮助我们确保，如果出现问题或看到不正确的内容时，我们知道该去哪里查找。它还可以用于确保缓存按预期工作，在应绕过缓存的区域不被缓存。
- en: Getting ready
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: As the caching is part of the standard NGINX platform, no additional prerequisites
    are required.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 由于缓存是标准 NGINX 平台的一部分，因此不需要额外的前置条件。
- en: How to do it...
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'One of the easiest ways is to simply add an additional header. To do this,
    we add the additional directive to our existing proxy configuration within the
    `location` block directive:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的方法之一是简单地添加一个额外的头部。为此，我们在现有的 `location` 配置块指令中添加额外的指令：
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: How it works...
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'NGINX internally tracks the status of the request (`$upstream_cache_status`),
    so by exposing it as a header, we can now see it from the client side. If we use
    Google DevTools or a utility such as `httpstat` to see the headers, you should
    see an output like this:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: NGINX 会在内部跟踪请求的状态（`$upstream_cache_status`），因此通过将其作为头部暴露，我们现在可以从客户端看到它。如果我们使用
    Google 开发者工具或类似的工具，如 `httpstat` 来查看头部信息，您应该会看到类似如下的输出：
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We can see by the `X-Cache-Status` header that the request was a hit, meaning
    it was served from the cache not the backend. Other than the basic hit and miss,
    there are also a number of other statuses which could be returned:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过 `X-Cache-Status` 头部看到请求是命中缓存，意味着它是从缓存中提供的，而不是从后端服务器提供的。除了基本的命中（hit）和未命中（miss）外，还有一些其他状态可能会被返回：
- en: '| **Status** | **Meaning** |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| **状态** | **含义** |'
- en: '| `HIT` | The request was a hit and therefore served from cache |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| `HIT` | 请求是命中缓存的，因此是从缓存中提供的 |'
- en: '| `MISS` | The request wasn''t found in cache and therefore had to be requested
    from the backend server |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| `MISS` | 请求未在缓存中找到，因此必须从后端服务器请求 |'
- en: '| `BYPASS` | The request was served from the backend server, as NGINX was explicitly
    told to bypass the cache for the request |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| `BYPASS` | 请求来自后端服务器，因为明确指示 NGINX 绕过该请求的缓存 |'
- en: '| `EXPIRED` | The request had expired in cache, so NGINX had to get a new copy
    from the backend server |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| `EXPIRED` | 请求在缓存中已过期，因此 NGINX 必须从后端服务器获取新副本 |'
- en: '| `STALE` | NGINX couldn''t talk to the backend server, but instead has been
    told to serve stale content |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| `STALE` | NGINX 无法与后端服务器通信，但已被指示提供过期内容 |'
- en: '| `UPDATING` | NGINX is currently awaiting an updated copy from the backend
    server, but has also been told to serve stale content in the interim |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| `UPDATING` | NGINX 当前正在等待来自后端服务器的更新副本，但也已被告知在此期间提供过期内容 |'
- en: '| `REVALUATED` | This relies on the use of `proxy_cache_revalidate` being enabled
    and checks the cache control headers from the backend server to determine if the
    content has expired |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| `REVALUATED` | 这依赖于启用 `proxy_cache_revalidate`，并检查来自后端服务器的缓存控制头部，以确定内容是否已过期
    |'
- en: See also
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: 'NGINX HTTP upstream variables: [http://nginx.org/en/docs/http/ngx_http_upstream_module.html#variables](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#variables)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NGINX HTTP 上游变量：[http://nginx.org/en/docs/http/ngx_http_upstream_module.html#variables](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#variables)
- en: 'The `httpstat` utility: [https://github.com/reorx/httpstat](https://github.com/reorx/httpstat)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`httpstat` 工具：[https://github.com/reorx/httpstat](https://github.com/reorx/httpstat)'
- en: Microcaching
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微缓存
- en: Caching is a great way to speed up performance, but some situations mean that
    you will be either continually invalidating the content (which means you'll need
    more server resources) or serving stale content. Neither scenario is ideal, but
    there's an easy way to get a good compromise between performance and functionality.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存是加速性能的好方法，但在某些情况下，你可能会不断使内容失效（这意味着你需要更多的服务器资源）或提供过期的内容。这两种情况都不理想，但有一种简单的方法可以在性能和功能之间找到良好的折中。
- en: With microcaching, you can set the timeout to be as low as one second. While
    this may not sound like a lot, if you're running a popular site, then trying to
    dynamically serve 50+ requests per second can easily bring your server to its
    knees. Instead, microcaching will ensure that the majority of your requests (that
    is, 49 out of the 50) are served direct from cache, yet will only be 1 second
    old.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 通过微缓存，你可以将超时时间设置为低至一秒。虽然这听起来不算很多，但如果你运行的是一个热门网站，那么每秒尝试动态处理50多个请求很容易就会让服务器崩溃。相反，微缓存将确保大部分请求（也就是50个请求中的49个）直接从缓存中提供，且缓存数据的年龄仅为1秒。
- en: Getting ready
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: As the caching is part of the standard NGINX platform, no additional prerequisites
    are required.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 由于缓存是标准NGINX平台的一部分，因此不需要额外的前提条件。
- en: How to do it...
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: To take advantage of microcaching, we expand on our previous recipe to reduce
    the timeout of the cache.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 为了利用微缓存，我们在之前的方案基础上进行了扩展，减少缓存的超时时间。
- en: '[PRE6]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: When you first look at it, 1 second timeouts seem like they won't provide any
    help. For a busy site, the reduction of requests which have to hit the backend
    server can be significantly dropped. It also means that your burst ability is
    greatly increased, allowing your site to handle a spike in traffic without issue.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 当你首次看到时，1秒的超时似乎不会带来任何帮助。对于一个繁忙的网站，减少必须访问后台服务器的请求数量可以显著减少。而且这也意味着你的网站的突发能力大大增强，使你能够在流量激增时轻松应对。
- en: 'As shown in the following diagram, the higher the **Requests Per Second** (**RPS**)
    the greater the advantage microcaching will provide:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如下图所示，**每秒请求数**（**RPS**）越高，微缓存提供的优势越大：
- en: '![](img/80d07109-3a18-4ff1-9454-a70063ed70d8.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/80d07109-3a18-4ff1-9454-a70063ed70d8.png)'
- en: How it works...
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: We set the `proxy_cache_valid` directive to cache the `200` responses and set
    them to be valid for 1 second (`1s`).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设置`proxy_cache_valid`指令来缓存`200`响应，并将其有效期设置为1秒（`1s`）。
- en: The validation value can be as low as your minimum content refresh. If you need
    changes to be live instantly, a 1 second timeout for the validation can be used.
    If you have less frequent changes, then setting 10-20 seconds can also be acceptable
    for many sites.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 验证值可以设置为你最小的内容刷新间隔。如果你需要即时生效的变化，可以使用1秒的超时来验证。如果更新不那么频繁，那么为许多网站设置10到20秒的超时也是可以接受的。
- en: HTTP response codes of `200` represent an OK response, meaning it was a successful
    response from the server. We could also cache `404` requests (Not Found) as well,
    especially knowing that some of these can be quite resource intensive if they
    involve database searches.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '`200`的HTTP响应码表示OK响应，意味着这是来自服务器的成功响应。我们也可以缓存`404`请求（未找到），尤其是考虑到其中一些请求可能涉及数据库查询，消耗的资源较多。'
- en: Serving from cache when your backend is down
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 当后台服务器宕机时从缓存中提供服务
- en: While we don't want to see a scenario where your backend server is down, expecting
    to maintain 100 percent uptime simply isn't realistic. Whether it's unexpected
    or planned upgrades, having the ability to still serve content is a great feature.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们不希望看到你的后台服务器出现宕机的情况，但期望保持100%的正常运行时间显然不现实。无论是意外的还是计划中的升级，能够在后台服务器不可用时继续提供内容是一个非常有用的功能。
- en: With NGINX, we can tell it to serve stale cache data when it can't reach your
    backend server. Having a page which is slightly out-of-date is (in most scenarios)
    a far better outcome than sending the client a `502` HTTP error (Bad Gateway).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 使用NGINX时，当无法连接到后台服务器时，我们可以让其提供过期的缓存数据。在大多数情况下，提供稍微过期的页面比返回`502` HTTP错误（错误网关）要好得多。
- en: Getting ready
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: As the caching is part of the standard NGINX platform, no additional prerequisites
    are required.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 由于缓存是标准NGINX平台的一部分，因此不需要额外的前提条件。
- en: How to do it...
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Building on our previous recipes, we take the existing proxy setup and add
    an additional directive:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 基于我们之前的方案，我们在现有的代理设置上添加了一个额外的指令：
- en: '[PRE7]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: How it works...
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: With the `proxy_cache_use_stale` directive, we specify which cases should use
    a stale copy of the cache. For this recipe, we've specified that when we have
    an error, timeout, `500` (Internal Server Error), `502` (Bad Gateway), `503` (Service
    Unavailable), and `504` (Gateway Timeout) errors from the backend server that
    the stale copy can be used.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`proxy_cache_use_stale`指令时，我们可以指定在哪些情况下使用过期的缓存副本。对于这个方法，我们指定了当后端服务器出现错误、超时、`500`（内部服务器错误）、`502`（错误网关）、`503`（服务不可用）和`504`（网关超时）错误时，可以使用过期的缓存副本。
- en: If any of these scenarios trigger, we take the less abrupt option of serving
    the content. Especially, if you've got short cache times (such as microcaching),
    the users of the site won't even notice the difference.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果出现这些情况，我们会选择较不突兀的方式来提供内容。特别是，如果你设置了较短的缓存时间（如微缓存），网站的用户甚至不会察觉到差异。
- en: There's more...
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多…
- en: One thing you don't want to do is queue thousands of requests as your backend
    system comes online. With a busy site, it's easy to overwhelm your system the
    moment it becomes available again. Especially since a big update or restart usually
    means local object caches within the backend are also cold, care needs to be taken
    when bringing it back online.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 你不希望做的事之一是，当你的后端系统重新上线时，排队数千个请求。对于一个繁忙的网站，系统一旦恢复可用，立刻就有可能被压垮。尤其是因为大更新或重启通常意味着后端的本地对象缓存也会变冷，因此在恢复上线时需要格外小心。
- en: 'One great feature NGINX has is to lock the cache to ensure only one request
    per unique key is sent through. Here''s an updated configuration to use this lock:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: NGINX有一个很棒的功能，可以锁定缓存，确保每个唯一的键只会发送一个请求。以下是更新的配置，用于启用此锁定：
- en: '[PRE8]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The `proxy_cache_lock` directive ensures that only one request (if there's a
    cache `MISS`) is sent through to the backend/upstream server. All other requests
    are either served from the cache (and stale if using this recipe) until the timeout
    directive (`proxy_cache_lock_timeout`) is triggered, and if the cache status is
    still a `MISS`, then it will try again. The timeout value needs to be sufficient
    to allow the backend to be ready to serve pages; for some .NET-based or Java systems,
    this could be as high as 120 seconds.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`proxy_cache_lock`指令确保只有一个请求（如果出现缓存`MISS`）会被发送到后端/上游服务器。所有其他请求要么从缓存中提供（如果使用此方法，可能是过期的），直到超时指令（`proxy_cache_lock_timeout`）被触发，如果缓存状态仍为`MISS`，则会再次尝试。超时值需要足够长，以便让后端准备好提供页面；对于一些基于.NET或Java的系统，这个值可能高达120秒。'
- en: This combination greatly lowers the peak impact on the backend after a cold
    start and helps to avoid overwhelming the system. By ensuring only one request
    per URI can be directed at the backend, we help ensure it has time to properly
    process requests as the cache warms again.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这种组合大大减少了冷启动后的后端峰值影响，帮助避免系统被压垮。通过确保每个URI只允许一个请求发送到后端，我们确保它有足够的时间在缓存重新加热时正确处理请求。
- en: See also
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: 'The proxy module: [http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_use_stale](http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_use_stale)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代理模块：[http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_use_stale](http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_use_stale)
- en: 'The cache lock documentation: [http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_lock](http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_lock)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缓存锁文档：[http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_lock](http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_lock)
- en: SSL termination proxy
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SSL终端代理
- en: 'One of the first use cases that I tried NGINX out for was simply as an SSL
    termination proxy. If you have an application which can''t directly produce HTTPS
    (encrypted) output, you can use NGINX as a proxy to do this. Content is served
    from your backend in plain text, then the connection between NGINX and the browser
    is encrypted. To help explain, here''s a diagram covering the scenario:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我最初尝试NGINX的用例之一就是作为一个SSL终端代理。如果你有一个应用程序无法直接生成HTTPS（加密）输出，你可以使用NGINX作为代理来实现。内容以明文形式从后端提供，然后NGINX与浏览器之间的连接会被加密。为了更好地解释，以下是涵盖这一场景的示意图：
- en: '![](img/57ae3cf9-82dc-4504-a75b-f546c45e6088.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](img/57ae3cf9-82dc-4504-a75b-f546c45e6088.png)'
- en: The advantage is that you also get to make use of all the other NGINX feature
    sets too, especially when it comes to caching. In fact, if you've used the Cloudflare
    service to achieve a similar outcome, then you may be surprised to know that it's
    NGINX-based as well.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 其优点在于，你还能利用NGINX的其他功能集，特别是在缓存方面。事实上，如果你使用过Cloudflare服务来实现类似的效果，那么你可能会惊讶地发现它也是基于NGINX的。
- en: Getting ready
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: This recipe involves the use of SSL certificates. If you haven't currently generated
    any for your deployment, see [Chapter 4](ec61d6cb-64ef-4260-bb9d-d606dd47ebef.xhtml),
    *All About SSLs*, for hints and tips.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 本方案涉及使用 SSL 证书。如果您当前还没有为部署生成证书，请参考[第 4 章](ec61d6cb-64ef-4260-bb9d-d606dd47ebef.xhtml)，*关于
    SSL 的一切*，了解相关提示和技巧。
- en: How to do it...
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Similar to some of our previous recipes, we use NGINX to combine the SSL encryption
    side and the proxy components:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们之前的一些方案类似，我们使用 NGINX 来结合 SSL 加密和代理组件：
- en: '[PRE9]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The following are some useful tips you should keep in mind:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些有用的提示，您应该牢记：
- en: One thing to note is that most SSL certificates are only valid for a single
    domain, unless they're a wildcard or **Subject Alternative Name** (**SAN**). If
    you're intending to use NGINX as an SSL terminator to multiple hosts, you'll need
    to have a `server` block or a SAN certificate mapped for each host.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有一点需要注意的是，大多数 SSL 证书仅对单一域名有效，除非它们是通配符证书或 **主题备用名称**（**SAN**）。如果您打算将 NGINX 用作多个主机的
    SSL 终止器，您需要为每个主机设置 `server` 块或为其映射 SAN 证书。
- en: Be careful with internal redirects within your application, especially if you
    tell it to enforce HTTPS. When using NGINX for SSL termination, this needs to
    be done at the NGINX level to avoid redirect loops.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小心应用程序中的内部重定向，尤其是在强制执行 HTTPS 时。当使用 NGINX 进行 SSL 终止时，这需要在 NGINX 层面完成，以避免重定向循环。
- en: See also
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: 'The NGINX SSL termination guide: [https://www.nginx.com/resources/admin-guide/nginx-ssl-termination/](https://www.nginx.com/resources/admin-guide/nginx-ssl-termination/)'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: NGINX SSL 终止指南：[https://www.nginx.com/resources/admin-guide/nginx-ssl-termination/](https://www.nginx.com/resources/admin-guide/nginx-ssl-termination/)
- en: Rate limiting
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 速率限制
- en: If you have an application or site where there's a login or you want to ensure
    fair use between different clients, rate limiting can help to help protect your
    system from being overloaded.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有一个包含登录的应用程序或网站，或者希望确保不同客户端之间的公平使用，速率限制可以帮助保护您的系统免于过载。
- en: By limiting the number of requests (done per IP with NGINX), we lower the peak
    resource usage of the system, as well as limit the effectiveness of attacks which
    are attempting to brute force your authentication system.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 通过限制请求的数量（每个 IP 使用 NGINX 进行限制），我们降低了系统的峰值资源使用，同时也限制了试图暴力破解身份验证系统的攻击效果。
- en: How to do it...
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Follow these steps for rate limiting:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 请按照以下步骤进行速率限制：
- en: 'Firstly, we need to define a shared memory space to use for tracking the IP
    addresses. This needs to be added in the main configuration file, outside the
    standard `server` block directive. Here''s our code:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要定义一个共享内存空间，用于跟踪 IP 地址。这需要在主配置文件中添加，位于标准 `server` 块指令之外。以下是我们的代码：
- en: '[PRE10]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Then, within the `server` block, you can set which location you wish to limit.
    Here''s what our `server` block directive looks like:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，在 `server` 块中，您可以设置希望限制的访问位置。以下是我们的 `server` 块指令：
- en: '[PRE11]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We can run Apache Benchmark (a simple web benchmarking tool) under a few different
    scenarios to test the effectiveness. The first is to use a single connection and
    make 200 requests:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以在不同的场景下运行 Apache Benchmark（一种简单的 Web 性能基准测试工具）来测试其有效性。第一个测试是使用单个连接并进行 200
    次请求：
- en: '[PRE12]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This gives us the following results:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们带来了以下结果：
- en: '[PRE13]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: As the results show, we didn't receive any errors and averaged 9.98 requests
    per second.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如结果所示，我们没有收到任何错误，平均每秒请求 9.98 次。
- en: 'In the next test, we''ll increase the number of concurrent requests to `4`
    at a time:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一个测试中，我们将同时增加并发请求的数量，设置为 `4` 次：
- en: '[PRE14]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This gives us the following results:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们带来了以下结果：
- en: '[PRE15]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Even with the increased request rate, we still received responses at a rate
    of 10 requests per second.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 即使请求速率增加，我们仍然以每秒 10 次请求的速度接收到响应。
- en: How it works...
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: There are a number of aspects to this recipe to consider. The first is the `limit_req_zone`
    directive within the main NGINX configuration file. We can create multiple zones
    for tracking and base them on different tracking parameters. In our recipe, we
    used `$binary_remote_addr` to track the remote IP address. The second parameter
    is then the name of the zone and the memory to allocate. We called the `basiclimit`
    zone and allocated 10 MB to it, which is sufficient to track up to 160,000 IP
    addresses. The third parameter is the rate, which we set to 10 requests per second
    (`10r/s`).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方案有几个方面需要考虑。第一个是主 NGINX 配置文件中的 `limit_req_zone` 指令。我们可以创建多个区域来跟踪，并根据不同的跟踪参数进行区分。在我们的方案中，我们使用
    `$binary_remote_addr` 来跟踪远程 IP 地址。第二个参数是区域的名称和分配的内存。我们将该区域命名为 `basiclimit`，并为其分配了
    10 MB 内存，这足以跟踪最多 160,000 个 IP 地址。第三个参数是速率，我们将其设置为每秒 10 次请求（`10r/s`）。
- en: If you need to have different rate limits for different sections (for example,
    a lower rate limit for an admin login area), you can define multiple zones with
    different names.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要为不同的部分设置不同的速率限制（例如，为管理员登录区域设置较低的速率限制），你可以定义多个具有不同名称的区域。
- en: To utilize the zone, we then added it to one of the existing location directives
    using `limit_req`. For our recipe, we specified the zone we created (`basiclimit`)
    and also gave it a burst ability of `5`. This burst allows for a small buffer
    over the specified limit before errors are returned and helps to smooth out responses.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用这个区域，我们将它添加到现有的某个 location 指令中，使用 `limit_req`。在我们的方案中，我们指定了我们创建的区域（`basiclimit`），并且为它设置了
    `5` 的突发能力。这个突发能力允许在返回错误之前有一个小的缓冲区，帮助平滑响应。
- en: There's more...
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'The soft delay is a nice way to handle rate limiting in a way which is the
    least disruptive to most users. However, if you''re running an API-based service
    and want to ensure the requesting application is notified of any request which
    hits the limit, you can add the `nodelay` parameter to the `limit_req` directive.
    Consider this example:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 软延迟是一种很好地处理速率限制的方式，它对大多数用户的影响最小。然而，如果你正在运行基于 API 的服务，并希望确保请求的应用程序能够收到任何达到限制的请求通知，你可以将
    `nodelay` 参数添加到 `limit_req` 指令中。考虑这个示例：
- en: '[PRE16]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Instead of seeing the connections queued, they''re immediately returned with
    a 503 (Service Unavailable) HTTP error. If we rerun the same initial Apache Benchmark
    call (even with a single connection), we now see this:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 与排队连接不同，它们会立即返回一个 503（服务不可用）HTTP 错误。如果我们重新运行相同的初始 Apache Benchmark 调用（即使只使用一个连接），我们现在会看到以下情况：
- en: '[PRE17]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Not all our requests returned with a status of `200`, and instead any requests
    over the limit immediately received a `503`. This is why our benchmark only shows
    46 successful requests per second, as 152 of these were `503` errors.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有请求都返回了 `200` 状态码，相反，任何超出限制的请求都会立即收到 `503` 错误。这就是为什么我们的基准测试只显示每秒 46 个成功请求，因为其中
    152 个是 `503` 错误。
- en: See also
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: 'The NGINX `ngx_http_limit_req_module`: [http://nginx.org/en/docs/http/ngx_http_limit_req_module.html](http://nginx.org/en/docs/http/ngx_http_limit_req_module.html)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: NGINX `ngx_http_limit_req_module`：[http://nginx.org/en/docs/http/ngx_http_limit_req_module.html](http://nginx.org/en/docs/http/ngx_http_limit_req_module.html)
