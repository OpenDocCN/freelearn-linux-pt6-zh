<html><head></head><body><div class="chapter" title="Chapter&#xA0;2.&#xA0;Searching for Problems in Log Files"><div class="titlepage"><div><div><h1 class="title"><a id="ch02"/>Chapter 2. Searching for Problems in Log Files</h1></div></div></div><p>Nginx really is <a class="indexterm" id="id38"/>a breakthrough technology powering a great part of modern Web. And as with all great technologies, it stands on the shoulders of giants. Nginx would not be possible without Apache. One very important Unix tradition that Nginx embraces fully is thorough logging.</p><p>Logs are <a class="indexterm" id="id39"/>what you turn to the moment there is a problem with your Nginx instance. For a daemon, there are not really many ways to communicate its state to the administrator in a simple, reliable, and guaranteed to work way other than logs.</p><p>You will find the following topics in this chapter:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">A comprehensive description of how Nginx logging is configured and what mistakes could be made in the configuration</li><li class="listitem" style="list-style-type: disc">A special section on how to log POST request bodies</li><li class="listitem" style="list-style-type: disc">A section on how log rotation works and why there is some potential for problems</li><li class="listitem" style="list-style-type: disc">A series of real-life error records from logs with analysis</li></ul></div><div class="section" title="Configuring Nginx logging"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec12"/>Configuring Nginx logging</h1></div></div></div><p>There are <a class="indexterm" id="id40"/>two types of logs that Nginx may write. One could also say that there are infinite types because of the <code class="literal">log_format</code> directive that allows you to create your own types of logs.</p><p>To refresh your memory about what directives are used to configure Nginx logging, here they are:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The <code class="literal">error_log</code> directive configures the logging of exceptional events that the developers of Nginx consider worth noting. Usually, this is all kinds of errors.<p>The format of the directive is this:</p><div class="informalexample"><pre class="programlisting">error_log &lt;destination&gt; &lt;log level&gt;;</pre></div><div class="note" style="" title="Note"><div class="inner"><h3 class="title"><a id="note03"/>Note</h3><p>The first parameter is usually a path to the file with the log. Recent versions of Nginx starting with 1.7.1 also support logging via syslog, to a local or remote syslog server. There is also a rarely used misnamed special value <code class="literal">stderr</code>, which, by the way, does not redirect logging to <code class="literal">stderr</code> (the third standard <code class="literal">stdio</code> stream or <code class="literal">&amp;2</code> in shell terms) because it does not make much sense to log to <code class="literal">stderr</code> from a daemon—daemonization involves closing all standard file descriptors. The <code class="literal">stderr</code> value means "log into the file that was configured during compilation time" and that depends on the package or even the OS distribution you use. You will mostly want to specify an actual file instead of <code class="literal">stderr</code> just to be sure where it ends. By the way, to make things more confusing, there is a way to specify logging to actual <code class="literal">stderr</code> during compile time. It is not very useful for daemons; you will not probably ever use it.</p><p>You often want several error logs. Remember that in <a class="link" href="ch01.html" title="Chapter 1. Searching for Problems in Nginx Configuration">Chapter 1</a>, <span class="emphasis"><em>Searching for Problems in Nginx Configuration</em></span>, we discussed multiline configuration directives named contexts. They provide a topic, that is, a narrow scope for the directives inside them. You may (and that is usually a very good idea) have different log files in different contexts. And using <code class="literal">stderr</code> prevents that because everything will get written to the same place.</p></div></div><p>The <code class="literal">log level</code> parameter of the <code class="literal">error_log</code> directive is a way of specifying <a class="indexterm" id="id41"/>a threshold of severity of events that end up in the log. Most of the time, you will want to set this to <code class="literal">warn</code>, but feel free to increase up to <code class="literal">debug</code> whenever you have a reproducible problem that you want more information about.</p><p>The <code class="literal">debug</code> level requires a special compile-time switch. The reason for this is that <code class="literal">debug</code> logging makes some performance compromises and the code for it should not be included in production systems, ideally. Unless Nginx is <a class="indexterm" id="id42"/>really your bottleneck (a rare situation), you may safely use <code class="literal">--with-debug</code> when compiling Nginx. See a little more about it at <a class="ulink" href="http://nginx.org/en/docs/debugging_log.html">http://nginx.org/en/docs/debugging_log.html</a>.</p></li><li class="listitem" style="list-style-type: disc">The other logging directive is <code class="literal">access_log</code>. And it includes much more functionality than <code class="literal">error_log</code> and also more potential for mistakes. Let's look at it more closely.<p>This is how access logs are configured:</p><div class="informalexample"><pre class="programlisting">access_log &lt;destination&gt; &lt;log format&gt; &lt;misc arguments&gt;</pre></div><p>The idea of access log is to have a journal of all request-response pairs processed by Nginx. As opposed to the error log, the records in access logs have a thoroughly specified format, usually a chain of whitespace-delimited values that contain some information about the current<a class="indexterm" id="id43"/> request-response pair or general state of Nginx. All access log records have this format. Access logs and error logs work together. In case Nginx has something unusual to say about a request it processes, you will find a strictly formatted line of data in your access log and then some warnings or errors of mostly free text nature in your error log.</p><p>The <code class="literal">destination</code> parameter takes the same values as the respective parameter of the <code class="literal">error_log</code> directive. You may still log to syslog or a file.</p><div class="note" style="" title="Note"><div class="inner"><h3 class="title"><a id="note04"/>Note</h3><p>Modern Nginx also has an interesting performance feature of buffered access logging. You <a class="indexterm" id="id44"/>will find more information about turning buffered logging on with flush or gzip arguments at <a class="ulink" href="http://nginx.org/en/docs/http/ngx_http_log_module.html#access_log">http://nginx.org/en/docs/http/ngx_http_log_module.html#access_log</a>. Do understand what buffering means before turning it on. One of the expected features of all error reporting mechanisms is being real time and buffered logs are exactly the opposite, that is, log records are not written to disk and not made available for inspection immediately. They are held in the buffer for some time. You will need this only in high-load scenarios where writing logs starts to take noticeable time because of the disk waits.</p></div></div><p>The <code class="literal">log format</code> parameter of the <code class="literal">access_log</code> directive is the heart of access logging. It expects a name of a template that models each record in the log. You create such templates with the <code class="literal">log_format</code> directive. There is a predefined format named <code class="literal">combined</code>, which is also a good example to show here:</p><div class="informalexample"><pre class="programlisting">log_format combined '$remote_addr - $remote_user [$time_local] '
                    '"$request" $status $body_bytes_sent '
                    '"$http_referer" "$http_user_agent"';</pre></div></li></ul></div><p>As you can see, the <code class="literal">log_format</code> directive's second argument is a long line of variables with "talking" names. All characters between and around variables will be included in the log. Variables will be evaluated at the time of logging, and their values will take their places.</p><p>Let's look at a real example of a log record generated with this very template:</p><div class="informalexample"><pre class="programlisting">85.90.193.224 - - [01/Feb/2016:12:01:34 +0400] "GET / HTTP/1.0" 200 137426 "http://example.com/" "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:33.0) Gecko/20100101 Firefox/33.0"</pre></div><p>You are <a class="indexterm" id="id45"/>probably very familiar with the combined log format from previous experience with Nginx, Apache, or some other web server software. Still, going through the individual items of each combined log line with us may provide you with some nonobvious insights. Let's parse the example record and learn some facts about those variables along the way:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><tbody><tr><td style="text-align: left" valign="top">
<p>
</p><div class="informalexample"><pre class="programlisting">$remote_addr 85.90.193.224</pre></div><p>
</p>
</td><td style="text-align: left" valign="top">
<p>This is the IP address of the computer that made the request to our server. Never ever parse it as four decimal integers delimited by dots. Even the <code class="literal">[0–9.]+</code> regexp is not good enough. Can you guess the reason? Here it is:</p>
<p>
</p><div class="informalexample"><pre class="programlisting">2001:470:1f10:1::2 - - [28/Jan/2015:02:28:19 +0300] "HEAD / HTTP/1.1" 200...</pre></div><p>
</p>
<p>We are living in the age of IPv6 in production. Big websites see 1–7% of their traffic on IPv6 (data from the end of 2015). Nginx is fully ready, so make sure your log parsers are too.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
</p><div class="informalexample"><pre class="programlisting">"- -"</pre></div><p>
</p>
</td><td style="text-align: left" valign="top">
<p>The first dash is legacy. When this particular log format was born long ago and long before Nginx, there was this interesting protocol named <code class="literal">ident</code>, which allowed a host to make a connection back to the client computer and ask for the name of the user that initiated a particular<a class="indexterm" id="id46"/> TCP connection. See RFC 1413 (<a class="ulink" href="https://tools.ietf.org/html/rfc1413">https://tools.ietf.org/html/rfc1413</a>) if you are curious, but we should say that <code class="literal">ident</code> is long dead and not used anywhere but IRC networks. Nginx didn't even bother with implementing it; this field should be hardcoded to <code class="literal">-</code> always.</p>
<p>The next dash is for "remote user" as identified by the HTTP auth mechanism. Which is a bit more popular than ident but not by a big margin. There<a class="indexterm" id="id47"/> is one case where HTTP auth is used relatively often, that is, closing test versions of websites from prying eyes (read: GoogleBot and other less discriminating crawlers). See the online documentation for how to configure HTTP auth at <a class="ulink" href="http://nginx.org/en/docs/http/ngx_http_auth_basic_module.html">http://nginx.org/en/docs/http/ngx_http_auth_basic_module.html</a>.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
</p><div class="informalexample"><pre class="programlisting">"[01/Feb/2016:12:01:34 +0400]" $time_local</pre></div><p>
</p>
</td><td style="text-align: left" valign="top">
<p>This is the date/timestamp of the log record. Not the most convenient date/time format to parse, for sure. Be careful dealing with time zones. It still allows prefix matching, and you probably often do something along the lines of:</p>
<p>
<span class="strong"><strong>% fgrep "01/Feb/2016:12:01:" /var/log/nginx/access.log</strong></span> to filter all the page hits processed during a particular minute.</p>
<p>This is a more complex version that should be in your toolkit too:</p>
<p>
</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong>% cat /var/log/nginx/access.log | awk '{print $4}' | awk -F : '{print $2 ":" $3}' | uniq -c</strong></span>
</pre></div><p>
</p>
<p>It will print the number of hits you had during each minute of the day. With this command, you can identify spikes that may signal a problem.</p>
<p>Interestingly, the original version of this was easier:</p>
<p>
<span class="strong"><strong>% cat /var/log/nginx/access.log | awk -F : '{print $2 ":" $3}' | uniq -c</strong></span> but then again, IPv6 came into our lives.</p>
</td></tr><tr><td style="text-align: left" valign="top">
<p>
</p><div class="informalexample"><pre class="programlisting">"GET / HTTP/1.0" "$request"</pre></div>
</td><td style="text-align: left" valign="top">
<p>This is a string representation of the whole HTTP request. What to look for? You will be surprised by how often, along with <code class="literal">GET</code> and <code class="literal">POST</code>, you will see <code class="literal">HEAD</code> requests. It is a rarely discussed younger brother of GET, which is not supposed to return an actual body—only the headers of the response.</p>
<p>You will not see <code class="literal">HTTP/1.0</code> as a protocol very often. Modern browsers will issue <code class="literal">HTTP/1.1</code> requests. All other values here should raise a flag. You will see things such as <code class="literal">SIP/2.0</code> or <code class="literal">RTSP/1.0</code> there; these are legitimate protocols indeed but requests for those on a website and not a <code class="literal">SIP</code> or <code class="literal">RTSP</code> endpoint are signs of scanning from malicious actors (or researchers).</p>
</td></tr><tr><td style="text-align: left" valign="top"><p>
</p><div class="informalexample"><pre class="programlisting">200  $status</pre></div>
</td><td style="text-align: left" valign="top">
<p>This is <a class="indexterm" id="id48"/>the HTTP status code. Anything besides 2xx or 3xx here indicates an error. For a comprehensive, modern, and authoritative list of HTTP status codes, please look no further than RFC 7231 (<a class="ulink" href="https://tools.ietf.org/html/rfc7231">https://tools.ietf.org/html/rfc7231</a>)—a rather new and long-awaited <a class="indexterm" id="id49"/>update on the HTTP/1.1 specification released in June 2014.</p>
</td></tr><tr><td style="text-align: left" valign="top"><p>
</p><div class="informalexample"><pre class="programlisting">137426 $body_bytes_sent</pre></div>
</td><td style="text-align: left" valign="top">
<p>This one does not need an explanation. We should add that it already accounts for any compression. It may also be used as a quick indicator of problems on the backend. After some time, you will learn to spot unusually small response sizes, which mean that the backend tumbled and generated a short error page instead of a normal response. Proper backends will also send a non-2xx status code but not all (and not even many) backends behave.</p>
<p>This small Perl script searches for response sizes that are less than a tenth of the average for that URL and also less than some hard-coded chunk size threshold that is commonly used to download a part of a file: <a class="ulink" href="http://kapranoff.ru/~kappa/nginx-troubleshooting/blips.pl">http://kapranoff.ru/~kappa/nginx-troubleshooting/blips.pl</a>.</p>
<p>We will not go over it line by line; it is just an example anyway. The idea is to make two passes of the log. First, to calculate the average bytes sent for each URI served, and second, to actually find outsiders.</p>
</td></tr><tr><td style="text-align: left" valign="top"><p>
</p><div class="informalexample"><pre class="programlisting">"http://example.com/" "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:33.0) Gecko/20100101 Firefox/33.0" '"$http_referer" "$http_user_agent"'</pre></div>
</td><td style="text-align: left" valign="top">
<p>These are taken directly from HTTP request headers; they are sent by the HTTP client, usually a browser. This makes them interesting, but also non-reliable. They are, basically, strings sent to your server over the network. You cannot trust anything sent by the client. You will routinely see some fantastic user agent strings claiming to be from the future or from the past. You will also see referrer URLs that point to some totally bogus websites that do not contain any links to your site and instead try to infect you with all kinds of malware du jour.</p>
<p>On the bright side, we do remember the excitement of seeing the first iPhones in our access logs during the late summer of 2007. That was fun.</p>
</td></tr></tbody></table></div><p>There is<a class="indexterm" id="id50"/> a lot of information that you can add to your access logs <a class="indexterm" id="id51"/>using different variables that Nginx provides during processing of each request.</p><p>The whole list of them is at <a class="ulink" href="http://nginx.org/en/docs/varindex.html">http://nginx.org/en/docs/varindex.html</a>.</p><p>There are also several variables that are available only during log record generation and are listed in <a class="indexterm" id="id52"/>the description of the <code class="literal">log_format</code> directive at <a class="ulink" href="http://nginx.org/en/docs/http/ngx_http_log_module.html#log_format">http://nginx.org/en/docs/http/ngx_http_log_module.html#log_format</a>.</p><p>The recommendation is to keep saving logs in the <code class="literal">combined</code> format to be able to use a huge number of tools that community has created over the years. In addition to these, you may create some extended logs with more data to help you debug problems.</p><p>Here is a list of variables that are often useful but not included in the default <code class="literal">combined</code> format:</p><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><tbody><tr><td style="text-align: left" valign="top"><p>
</p><div class="informalexample"><pre class="programlisting">$gzip_ratio</pre></div>
</td><td style="text-align: left" valign="top">
<p>The ratio of compressed response size to the original or <code class="literal">"-"</code> if the response was not compressed. This does not seem important, but it makes <code class="literal">$body_bytes_sent</code> more useful. Having this variable helps you to spot clients that do not support gzip compression. For them, <code class="literal">$body_bytes_sent</code> will be higher than usual.</p>
</td></tr><tr><td style="text-align: left" valign="top"><p>
</p><div class="informalexample"><pre class="programlisting">$msec</pre></div>
</td><td style="text-align: left" valign="top">
<p>The exact timestamp up to milliseconds. This is the same information that is available in human-readable form with <code class="literal">$time_local</code>, but milliseconds are important once you have a lot of hits each second.</p>
</td></tr><tr><td style="text-align: left" valign="top"><p>
</p><div class="informalexample"><pre class="programlisting">$request_length</pre></div>
</td><td style="text-align: left" valign="top">
<p>The size of the HTTP <a class="indexterm" id="id53"/>request. GET requests are generally short, but once they get beyond a kilobyte, you should think about having too many cookies accompanying each request. POST requests may be of any size and if your application has to accept important data from users, such as files or filled forms, you will want to monitor the size of those requests. A technique to log the contents of POST requests is described later in this chapter.</p>
</td></tr><tr><td style="text-align: left" valign="top"><p>
</p><div class="informalexample"><pre class="programlisting">$request_time</pre></div>
</td><td style="text-align: left" valign="top">
<p>The time between the beginning of the request and the end of the response phases. Basically, this is your atom of performance data that includes both the network and processing delays.</p>
</td></tr><tr><td style="text-align: left" valign="top"><p>
</p><div class="informalexample"><pre class="programlisting">$sent_http_content_type</pre></div>
</td><td style="text-align: left" valign="top">
<p>This is the content type of the response in the familiar form of something like <code class="literal">text/html</code> or <code class="literal">application/pdf</code>. It is not essential but helps when looking at logs of modern web applications and spotting that some JSON handler suddenly emitted a simple text/html response. It is also useful to calculate the total traffic divided by types of data. There is a whole family of <code class="literal">$sent_http_*</code> variables that correspond to the generated HTTP response headers. You may want to research what else is there.</p>
<p>MIME types that we mention here are also discussed in <a class="link" href="ch01.html" title="Chapter 1. Searching for Problems in Nginx Configuration">Chapter 1</a>, <span class="emphasis"><em>Searching for Problems in Nginx Configuration</em></span>.</p>
</td></tr><tr><td style="text-align: left" valign="top"><p>
</p><div class="informalexample"><pre class="programlisting">$cookie_*</pre></div>
</td><td style="text-align: left" valign="top">
<p>The asterisk should be replaced by the name of one of your cookies. Most modern websites have some mechanism of stateful user sessions. Usually, there is a cookie named <code class="literal">session</code> or <code class="literal">session_id</code> that allows the restoration of a chain of requests that were made by one user inside one session. The remote IP address is used for that when analyzing standard combined format logs, but this may and will fail on users with the same IP or the same user hopping between IP addresses (both are absolutely normal situations).</p>
</td></tr><tr><td style="text-align: left" valign="top"><p>
</p><div class="informalexample"><pre class="programlisting">$host</pre></div>
</td><td style="text-align: left" valign="top">
<p>This one contains the <a class="indexterm" id="id54"/>hostname that processed the request. It may seem redundant because, generally, different hosts will log in to different files. However, you would be surprised to know how often logs from several hosts are processed together whether just on the same log storage cluster or even using the same log analyzer software. Having the hostname right there in the logs creates some additional freedom of not caring about filenames of the logs, and once you get tired of running greps against files and load everything into a database, you will remember the time you decided to include <code class="literal">$host</code> and thank yourself.</p>
</td></tr></tbody></table></div><div class="section" title="Logging POST requests"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec18"/>Logging POST requests</h2></div></div></div><p>Once you<a class="indexterm" id="id55"/> start debugging a problem with a web application that runs behind one of your Nginx instances by tracing user requests and application responses via access logs, you will see that GET/HEAD requests are logged fully while POST request log records lack any information except the URI to which the data was posted. This is one of the questions that many system administrators ask, especially after trying to get away with <code class="literal">tcpdumps</code> only. <code class="literal">tcpdump</code> is a wonderful Swiss army knife of protocol tracing, but it requires active participation during the events that need to be traced. And tracing HTTPS with <code class="literal">tcpdump</code> is very hard.</p><p>Nginx is able to log POST request bodies and many more. You should already be fully equipped to at least try to implement such a logging yourself.</p><p>Remember that we talked about custom log formats and using variables to record the state of requests and responses. If you search through the list of variables available during request processing, you<a class="indexterm" id="id56"/> will see the variable named <code class="literal">$request_body</code>. See <a class="ulink" href="http://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body">http://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body</a>.</p><p>Let's invent a simple log format including <code class="literal">$request_body</code>:</p><div class="informalexample"><pre class="programlisting">log_format request_body_log 'body: "$request_body"';</pre></div><p>Now we enable logging with this format by adding this directive:</p><div class="informalexample"><pre class="programlisting">access_log /var/log/nginx/requests.log request_body_log;</pre></div><p>Remember that the <code class="literal">log_format</code> directive should be used in one of the higher contexts, for example, the <code class="literal">http</code> context. Multiple <code class="literal">access_log</code> directives may be in effect for all the requests, and<a class="indexterm" id="id57"/> because of this, we do not need to specify the rest of the variables in the template for the <code class="literal">request_body_log</code> format. Your usual preconfigured combined-formatted logs will still get written to.</p><p>What would we see in <code class="literal">requests.log</code> for some simple GET requests to download a couple of static files?</p><div class="informalexample"><pre class="programlisting">body: "-"
body: "-"
body: "-"</pre></div><p>Make sure that you understand the result before proceeding.</p><p>Now, we need POST requests. And POST requests to static files are useless. They never happen in real life. Clients POST data to web applications, and for Nginx administrators, a web application is an upstream to which Nginx proxies the requests and from which it proxies back the responses.</p><p>Suppose that we build something like this. It will be a very simple Dancer application in Perl accepting a simple POST and responding with a piece of <span class="emphasis"><em>dynamic HTML</em></span>.</p><p>The source code is  at <a class="ulink" href="http://kapranoff.ru/~kappa/nginx-troubleshooting/simple-post.pl">http://kapranoff.ru/~kappa/nginx-troubleshooting/simple-post.pl</a>:</p><div class="mediaobject"><img alt="Logging POST requests" src="graphics/B04329_02_01.jpg"/></div><p>Now we will set up a proxy inside our Nginx instance:</p><div class="informalexample"><pre class="programlisting">location /simple-post {
    proxy_pass http://localhost:3000/;
}</pre></div><p>We will<a class="indexterm" id="id58"/> point our browser to <code class="literal">http://localhost/simple-post</code>.</p><p>If the <a class="indexterm" id="id59"/>Dancer app is running, you will see a simple form of one field and a button. Type in something, click on the button and rush to your <code class="literal">requests.log</code>:</p><div class="informalexample"><pre class="programlisting">body: "-"
body: "a=Nginx+rules%21"</pre></div><p>The first line is the empty body of the GET request for the form, whereas the second contains the body of the POST that the form generated with the help of your browser. There are two ways an HTML form may be encoded into a POST body; this one is the default <span class="strong"><strong>application/x-www-form-urlencoded</strong></span>. The other one is <span class="strong"><strong>multipart/form-data;</strong></span> it is widely used for forms that allow file uploads. This is a little bit out of scope of this book already. We should add that form encodings are quickly becoming a thing of the past because more and more POST bodies are constructed by the client-side JavaScript and the browsers themselves.</p><p>What is<a class="indexterm" id="id60"/> important here is that you now have a simple way to log what is coming your way via POST requests.</p></div><div class="section" title="Conditional logging"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec19"/>Conditional logging</h2></div></div></div><p>This<a class="indexterm" id="id61"/> example will also allow demonstration of one of the more recent Nginx logging features named <span class="emphasis"><em>conditional logging</em></span>.</p><p>The directive <code class="literal">access_log</code> has a number of optional parameters and among them is a parameter <code class="literal">if</code> that specifies a condition on which a record is appended to this particular access log. When we configured request body logging in the previous section, we still ended up with a log full of "-"<code class="literal">;</code> those are empty bodies of all the non-POST requests. Let's fix that. First, we add a condition to our <code class="literal">access_log</code> directive:</p><div class="informalexample"><pre class="programlisting">access_log /var/log/nginx/requests.log request_body_log if=$method_is_post;</pre></div><p>The condition that we use is a simple custom variable. We intentionally show this technique<a class="indexterm" id="id62"/> using syntax very similar to what is documented in the official documentation at <a class="ulink" href="http://nginx.org/en/docs/http/ngx_http_log_module.html#access_log">http://nginx.org/en/docs/http/ngx_http_log_module.html#access_log</a>.</p><p>So the next step for us is to create this variable. There are several ways to create a variable in Nginx. The most straightforward is using the <code class="literal">set</code> directive inside an <code class="literal">if</code> context. But it is a good habit to cringe any time you see an <code class="literal">if</code> directive in Nginx configuration. <code class="literal">if</code> should always be the last choice. Remember that there is no programming inside configuration files; everything should be as declarative as possible.</p><p>And there is a good declarative way to create a variable:</p><div class="informalexample"><pre class="programlisting">map $request_method $method_is_post {
    POST 1;
    default 0;
}</pre></div><p>This is everything you need to do to enable conditional logging. If your Nginx version is modern enough, you will get only bodies of POST requests in your <code class="literal">requests.log</code> from now on.</p><p>There is a probability that your Nginx is not modern enough (at least 1.7.0 is required). Use <code class="literal">nginx -t</code> to test the configuration. Can you think of a way to work around the problem without upgrading Nginx? This is not a hypothetical question. Running Nginx installed from packages provided by your distribution is highly recommended, and they are notoriously not up to date.</p></div><div class="section" title="Logging big request bodies"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec20"/>Logging big request bodies</h2></div></div></div><p>There is one more thing to tell you about logging request bodies. Actually, two things that will manifest in exactly the same way while having different reasons.</p><p>The <a class="indexterm" id="id63"/>variable <code class="literal">$request_body</code> is not guaranteed to have any content even in the case of a good POST request with data inside. The first possible reason for an empty <code class="literal">$request_body</code> is a situation where Nginx has decided that parsing the body is not needed and optimized it away. That is a documented behavior that still strikes in the least expected moments. The documentation says clearly:</p><div class="blockquote"><blockquote class="blockquote"><p><span class="emphasis"><em>"The variable's value is made available in locations processed by the proxy_pass, fastcgi_pass, uwsgi_pass, and scgi_pass directives."</em></span></p></blockquote></div><p>See for <a class="indexterm" id="id64"/>yourself: <a class="ulink" href="http://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body">http://nginx.org/en/docs/http/ngx_http_core_module.html#var_request_body</a>.</p><p>These are the only four cases in which Nginx populates the <code class="literal">$request_body</code> variable. Fortunately, POST requests to locations that do not contain any of those directives are very rare. POSTs are intended to accept data from clients and feed to server applications for which Nginx is acting as a proxy.</p><p>Be careful not to harm yourself debugging empty request bodies for some uncommon configuration with POST requests and no proxying directives in that context.</p><p>The other reason for empty <code class="literal">$request_body</code> is the request being too large. If the size of the request body exceeds the value set up by the <code class="literal">client_body_buffer_size</code> directive, it is not available via <code class="literal">$request_body</code> variable. Instead, the whole body is saved to a temporary file on the file system, and its name is written into the new <code class="literal">$request_body_file</code> variable.</p><p>There is also another very interesting directive named <code class="literal">client_body_in_file_only</code> that provides a way to always save requests to files. It may be used instead of the mechanism that we showed earlier altogether! You will add <code class="literal">$request_body_file</code> to one of your log formats and turn on <code class="literal">client_body_in_file_only</code>. After this, Nginx will create an ever-growing store of files containing all your request bodies. Do not forget to clean them up from a crontab or they will fill the filesystem.</p></div></div></div>
<div class="section" title="Creating infrastructure around logs"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec13"/>Creating infrastructure around logs</h1></div></div></div><p>Okay, let's do <a class="indexterm" id="id65"/>some arithmetic. Suppose that you have a rather popular but not on a world scale (yet) website with about 50,000 visits per day. This is a number that managers brag about during their meetups; they get it from some analytics software. It almost means nothing regarding your job. Because what is a visit? Let's say that what you have is an e-commerce site; you sell some nonseasonal stuff, for example, power tools. Your average visitor will look at one to two pages with spikes to early tens when actually choosing and buying something. Let it be three pages per visit on average. What is a page? For you, it is a series of HTTP responses—the main document and all the embedded objects. People notoriously underestimate the sheer size of modern web pages. It would be a safe bet to say that your pages include on average 100 objects (HTML documents, images, scripts, style sheets, and so on) amounting to the size of over a megabyte.</p><p>This will<a class="indexterm" id="id66"/> be 100 x 3 x 50,000 per day or 15,000,000 / 24 / 3600 = 174 requests per second (RPS) on average. Averaging RPS during the day will render a rather useless number unless you operate in all world's time zones and that is not very common for websites selling actual material stuff. There is a good enough heuristic to estimate peaks—multiply average by 10.</p><p>Now we have a number of lines in your daily access log (15 million) and a very rough upper limit of logging rate that you will have to deal with (a thousand and a half lines a second). These numbers all mean that you need tools because a human being is not able to consume all this information in time.</p><div class="section" title="Configuring log rotation"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec21"/>Configuring log rotation</h2></div></div></div><p>The main <a class="indexterm" id="id67"/>and simplest tool to make the amount of logging data more manageable is log rotation. You probably have it set up already. There is a pretty standard log rotator included in many Linux distributions uninventively named <code class="literal">logrotate</code>. Its FreeBSD counterpart is <code class="literal">newsyslog</code>.</p><p>Examples of Nginx log rotation configuration in <code class="literal">logrotate</code> and <code class="literal">newsyslog</code> are shown here.</p><p>This is an example of <code class="literal">logrotate</code> configuration from a Linux box:</p><div class="mediaobject"><img alt="Configuring log rotation" src="graphics/B04329_02_02.jpg"/></div><p>And this<a class="indexterm" id="id68"/> is a sample configuration of <code class="literal">newsyslog</code> from a rather modern FreeBSD server:</p><div class="mediaobject"><img alt="Configuring log rotation" src="graphics/B04329_02_03.jpg"/></div><p>What they <a class="indexterm" id="id69"/>do is take care of huge logs by creating an archive of old records based on time and size of current files. It is not exactly rocket science, but there are at least several pitfalls attracting people by the numbers.</p><p>First, do have free space monitoring. And also do have monitoring of your free space monitoring. It is a surprisingly popular cause of major malfunctions. Just as the publisher warned us that the hard drive will fail while we are writing this book, because they always do, we will take the liberty of warning you that at least once in your career, disks will become totally filled up with logs. Usually, this leads to some very unpleasant effects but is easily fixable.</p><p>What are preventing measures? Set up a log store. It should be a couple of separate machines with huge and cheap (with rotating parts) mirrored disks that store your logs indefinitely. Their goal is to relieve your workhorses, actual web servers from storing log archives and from running heavy greps and messing with performance. And your rotation procedures should include copying each archive to the log store after it is created. Your processes will get a little more complex because you will have your most current log still spread out on your web servers, whereas older data will already be archived away to the log store, but it is totally worth it.</p><p>Also, move to a better compression algorithm than the default gzip. In this particular case of logs, you may save up to 50% of space just by switching from gzip. logrotate supports specifying the command it will use for compression while newsyslog has native support for both bzip2 and xz compression. xz is usually better. The only downside of using xz is high memory requirements; keep this in mind. A separate log store, again, is very useful. It may also<a class="indexterm" id="id70"/> be configured to recompress gzipped files into xz thus saving space without sacrificing performance on the web servers. The idea is to gzip the logs on the web servers, move them to the log store cluster, decompress them, and compress again with xz.</p><p>The second important part to log rotation is not losing a single record during the actual rotation. The optimal algorithm looks like this:</p><div class="orderedlist"><ol class="orderedlist arabic"><li class="listitem">First of all, imagine that Nginx is up and running and writing log records to some <code class="literal">access.log</code> files.</li><li class="listitem">A log rotator is fired and the <code class="literal">access.log</code> is chosen for either size or age reason.</li><li class="listitem">The log rotator renames the <code class="literal">access.log</code> according to the rotation scheme, for example, to <code class="literal">access.log.0</code>.</li><li class="listitem">The log rotator creates a new empty <code class="literal">access.log</code>.</li><li class="listitem">Now, Nginx does not lose any access to the older file because it has its descriptor and the filename does not matter after the file is open by a process. So, Nginx continues to write records to <code class="literal">access.log.0</code> file.</li><li class="listitem">The log rotator cannot compress the old file because it is still written to, so it signals Nginx to release the old file descriptor and to reopen the log file by its name again.</li><li class="listitem">Nginx is happy to oblige. The new empty <code class="literal">access.log</code> gets opened and starts to receive new log records, whereas the old file is ready to be removed after compression.</li><li class="listitem">The log rotator runs the compressor that creates a new file <code class="literal">access.log.0.xz</code> while deleting the old log.</li></ol></div><p>It looks surprisingly complex for a seemingly simple procedure. The reason is steps 4, 5, and 6, which guarantee that logs are not renamed and deleted without Nginx knowing.</p><p>There is nothing Nginx-specific here. It just so happens that the authors thought about this problem and implemented the special <code class="literal">reopen</code> command in Nginx, which is initiated by the USR1 signal to the master process.</p><p>If your log rotator omits the command altogether, the rotation will not work at all—Nginx will always write to the old log without noticing that you renamed it. And trying to compress a file that is currently appended to is a recipe for losing some lines.</p><p>If your log rotator will restart Nginx on each rotation, then your logs will be okay, but you may lose some performance if you do graceful restarts (with the SIGHUP signal). You may even lose some requests if you do hard restarts (the old <code class="literal">apachectl restart</code> command-style <a class="indexterm" id="id71"/>restarts are not supported by Nginx executable but could be implemented with init scripts of your OS).</p></div><div class="section" title="Working with a lot of log data"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec22"/>Working with a lot of log data</h2></div></div></div><p>Once <a class="indexterm" id="id72"/>your Nginx installation starts to get more than several thousands of users a day, you or your managers will definitely want to get more insights from those logs. Your job will be to provide an infrastructure for that and troubleshoot problems. You can also piggyback on that endeavor to end up with a great real-time search of all your logs much more efficient than the good old grep.</p><p>The evolution of log analytics through the years is an interesting and huge topic mostly outside the scope of this book. Many of us remember the (in)famous Webalizer and AWStats packages. They are still perfectly functional, by the way, even if a bit rusty. It is not recommended to invest in these tools for modern websites though. They are not very efficient, and you will have a hard time adding the features that are expected these days.</p><p>Some of the newer solutions that are available on the market are summarized below. By all means do your own research. This is really a giant topic in itself:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The logstash/ElasticSearch/kibana stack is a combination of Java-based tools, each<a class="indexterm" id="id73"/> of which deserves a whole book devoted to it. A working <a class="indexterm" id="id74"/>deployment allows you to store all your logs <a class="indexterm" id="id75"/>in a database indexed for all needed types of queries and reports. The kibana part of the stack provides gorgeous visualizations of time-based data. Logs are exactly that and fit perfectly. Maintaining an instance may quickly become a full-time job.</li><li class="listitem" style="list-style-type: disc">Scribe is a <a class="indexterm" id="id76"/>central logging solution developed, open sourced, and then abandoned by Facebook. It is of historical interest only. Facebook has moved on from Scribe and if you still have a Scribe installation or have inherited one, you are in trouble. One of the easier alternatives is fluentd.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Fluentd</strong></span> is<a class="indexterm" id="id77"/> a modern centralized logging system written in Ruby. It may be compared to the logstash part of the first stack. It has pluggable inputs and outputs. Once you have it configured to consume Nginx logs, it may feed the results to an ElasticSearch instance.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Apache Flume</strong></span> is<a class="indexterm" id="id78"/> an older project in the family of Apache Hadoop stack of technologies. It is used to collect data into your HDFS (which is the storage for Hadoop). It is sometimes used for web logs too.</li><li class="listitem" style="list-style-type: disc"><span class="strong"><strong>Splunk</strong></span> is a commercial full-stack solution in order to collect, parse, store, and query logs. It calls itself "Google for your logs", and we will not comment on that. Splunk is interesting because it is also widely used to do real-time<a class="indexterm" id="id79"/> monitoring of incoming logs. A good <a class="indexterm" id="id80"/>example of such a task is intrusion detection.</li></ul></div></div><div class="section" title="Reading logs"><div class="titlepage"><div><div><h2 class="title"><a id="ch02lvl2sec23"/>Reading logs</h2></div></div></div><p>The most<a class="indexterm" id="id81"/> interesting part for many readers ahead is that we will show you examples of different records from real Nginx log files and analyze what happened and how to fix it in each case. These will be rather simple situations many of which could be either familiar to a seasoned web system administrator or evident from the message.</p><p>We still recommend following each and every example. Sometimes, people develop a kind of selective blindness to things they do not understand fully. It is also very natural to skip unknown parts and to try to deduce their meaning from what they are surrounded with—this is how language learning works both for children and adults. Alas, human languages are highly redundant and therefore are specially catered to nonperfect, lossy understanding. Logs are usually not.</p><p>Let's start with a very simple and very famous 404 error – and how it looks from two perspectives, error log and access log.</p><p>The record from error log:</p><div class="informalexample"><pre class="programlisting">2016/01/29 02:25:14 [error] 18876#0: *1 "/home/kappa/books/index.html" is not found (2: No such file or directory), client: 127.0.0.1, server: localhost, request: "GET /books/ HTTP/1.1", host: "kantara"</pre></div><p>And now the record about the same event from the access log in <code class="literal">combined</code> format:</p><div class="informalexample"><pre class="programlisting">127.0.0.1 - - [29/Jan/2016:02:25:14 +0300] "GET /books/ HTTP/1.1" 404 151 "-" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:35.0) Gecko/20100101 Firefox/35.0"</pre></div><p>We will break them both down now.</p><div class="section" title="Error log record"><div class="titlepage"><div><div><h3 class="title"><a id="ch02lvl3sec01"/>Error log record</h3></div></div></div><div class="informaltable"><table border="1"><colgroup><col style="text-align: left"/><col style="text-align: left"/></colgroup><tbody><tr><td style="text-align: left" valign="top"><p>
</p><div class="informalexample"><pre class="programlisting">"2016/01/29 02:25:14"</pre></div>
</td><td style="text-align: left" valign="top">
<p>This is <a class="indexterm" id="id82"/>obviously a timestamp, but note that it does not contain any time zone information. It is local time as seen by the server in its configured timezone. This minor fact means that when you transfer this log file into another timezone and do not save timezone information somewhere, your software may become confused and apply the new local timezone. After this, comparing this timestamp with the timestamp from <code class="literal">access_log</code> would be wrong.</p>
</td></tr><tr><td style="text-align: left" valign="top"><p>
</p><div class="informalexample"><pre class="programlisting">"[error]"</pre></div>
</td><td style="text-align: left" valign="top">
<p>This is the severity level of the message. Remember that earlier in this chapter we discussed the format of the <code class="literal">error_log</code> directive and there was this second parameter, the threshold. Well, this is the field that gets compared to the configured<a class="indexterm" id="id83"/> threshold to determine whether a particular message is serious enough to bother this particular system administrator with. Other possible values include things from <code class="literal">debug</code> to <code class="literal">emerg</code> (short for emergency). See<a class="indexterm" id="id84"/> the <code class="literal">error_log</code> directive documentation  at <a class="ulink" href="http://nginx.org/en/docs/ngx_core_module.html#error_log">http://nginx.org/en/docs/ngx_core_module.html#error_log</a>.</p>
</td></tr><tr><td style="text-align: left" valign="top"><p>
</p><div class="informalexample"><pre class="programlisting">"18876#0:"</pre></div>
</td><td style="text-align: left" valign="top">
<p>Now, this part is not understood by many people. The pair of numbers gives information about which path of the Nginx ensemble of processes put this record into the log. The number before <code class="literal">#</code> is the PID, the identifier of the process, and the second number is the thread identifier or TID. TID is usually <code class="literal">0</code> on current Nginx on Linux. On Windows, it may be some big number. Nginx does not use multithreading in its current version. There are rumors that threads will be much more prominent on all platforms in Nginx 2.0.</p>
</td></tr><tr><td style="text-align: left" valign="top"><p>
</p><div class="informalexample"><pre class="programlisting">"*1"</pre></div>
</td><td style="text-align: left" valign="top">
<p>This is the identifier of the connection in the context of which this error happened. Actually, it is an integer counter, and it allows you to group errors by connections. By the way, the connection number and also the TID part of the previous item are not recognized by many Nginx users. Take some of your colleagues by surprise and ask about it sometime just for fun.</p>
</td></tr><tr><td style="text-align: left" valign="top"><p>
</p><div class="informalexample"><pre class="programlisting">"/home/kappa/books/index.html" is not found (2: No such file or directory)</pre></div>
</td><td style="text-align: left" valign="top">
<p>This is the actual error message formulated by Nginx accompanied by the OS-level <code class="literal">errno</code> number (<code class="literal">ENOENT</code> in this case) and <code class="literal">strerror</code> message in parentheses.</p>
</td></tr><tr><td style="text-align: left" valign="top"><p>
</p><div class="informalexample"><pre class="programlisting">"client: 127.0.0.1, server: localhost"</pre></div>
</td><td style="text-align: left" valign="top">
<p>This is the addresses of both sides of the connection. We have Nginx running right here on the workstation. This is why we see the connection over the loopback. Nginx has chosen not to do reverse DNS resolving of the client addresses for performance reasons, whereas the server name is known beforehand. This is why we see the same address in both IP and domain name forms.</p>
</td></tr><tr><td style="text-align: left" valign="top"><p>
</p><div class="informalexample"><pre class="programlisting">request: "GET /books/ HTTP/1.1", host: "kantara"</pre></div>
</td><td style="text-align: left" valign="top">
<p>Now, these are the data about the actual request. First, the string representation of the request itself and then the host value taken from the Host: HTTP request header sent by the browser.</p>
</td></tr></tbody></table></div><p>It is<a class="indexterm" id="id85"/> interesting that besides the very first items in the record everything is more or less free-form and not required. The timestamp is obviously always there as are the pid and the tid (especially if it is a constant <code class="literal">0</code>), but the connection is not always up and there, of course, may not be any current requests without the connection.</p><p>Error logs are notoriously not very machine-readable. You should never rely on existence of a certain type of data in a record unless you made sure that the whole record is written via a known and fixed template. For example, it is fairly easy to parse out all the <code class="literal">ENOENT</code> messages, but creating a summary of all types of errors will be harder.</p><p>The access log, on the contrary, is made for parsing. Let's see the record again:</p><div class="informalexample"><pre class="programlisting">127.0.0.1 - - [29/Jan/2016:02:25:14 +0300] "GET /books/ HTTP/1.1" 404 151 "-" "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:35.0) Gecko/20100101 Firefox/35.0"</pre></div><p>We already analyzed a combined record earlier in this chapter, so we won't do this again. Just look at two interesting parts.</p><p>We mentioned the weird historical date/timestamp format but at least it contains timezone and is totally unambiguous. We also see the famous <code class="literal">404</code> code in the sixth field, and that is the only sign of error here! Otherwise, it is a perfectly good HTTP request that was served with a fittingly perfect HTTP response of 151 bytes.</p><p>There will be two very popular 404 errors in your logs when you start a new website:</p><div class="informalexample"><pre class="programlisting">2016/02/09 19:09:11 [error] 39110#0: *1019042 open() "/site/example.com/www/robots.txt" failed (2: No such file or directory), client: 157.55.39.200, server: example.com, request: "GET /robots.txt HTTP/1.1", host: "example.com"
2010/10/17 22:44:05 [error] 44858#0: *809 open() "/site/example.com/favicon.ico" failed (2: No such file or directory), client: 95.26.237.86, server: example.com, request: "GET /favicon.ico HTTP/1.1", host: "example.com"</pre></div><p>These are the so-called <span class="emphasis"><em>well-known</em></span> files that HTTP clients request and use. You should get some <code class="literal">robots.txt</code> and<a class="indexterm" id="id86"/> some favicon for your sites at least for the sake of your own sanity. Refer to <a class="ulink" href="http://www.robotstxt.org/">http://www.robotstxt.org/</a> and <a class="ulink" href="https://en.wikipedia.org/wiki/Favicon">https://en.wikipedia.org/wiki/Favicon</a> for more information on these files.</p><p>It is time to see some more errors:</p><div class="informalexample"><pre class="programlisting">2016/02/09 13:19:00 [error] 39110#0: *1014628 kevent() reported that connect() failed (61: Connection refused) while connecting to upstream, client: 204.8.105.53, server: example.com, request: "GET /admin.php HTTP/1.0", upstream: "http://127.0.0.1:3000/admin.php", host: "example.com"</pre></div><p>You should read this almost effortlessly. This is an example of Nginx acting as a proxy, and this is certainly the most popular use for it. Being a proxy, this Nginx instance is trying to connect to an upstream on behalf of a client. The upstream that has problems is listed in the end before the familiar host item. The mentioned <code class="literal">kevent()</code> is the so-called <span class="emphasis"><em>implementation detail</em></span> that should not have leaked here but well, it has. It is a part of the mechanism Nginx uses to work with network connections under FreeBSD, Mac OS X, and other BSD operating systems.</p><p>On a <a class="indexterm" id="id87"/>Linux box, the same record would look like this:</p><div class="informalexample"><pre class="programlisting">2014/07/29 10:18:41 [error] 14243#0: *100053182 connect() failed (111: Connection refused) while connecting to upstream, client: 37.73.249.120, server: example.com, request: "GET /example.com/404 HTTP/1.1", upstream: "http://[2c32:6d8:0:172a::318]:8080/", host: "example.com"</pre></div><p>What is interesting in that record? First, no <code class="literal">kevent()</code>. Second, the <code class="literal">errno</code> code has changed! And indeed, our FreeBSD and Linux boxes have 61 and 111 for <code class="literal">ECONNREFUSED,</code> respectively. So no, you cannot rely on this code and more so you cannot rely on the <code class="literal">Connection refused</code> string. On Windows the same error may have this message: <span class="strong"><strong>10060: A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond</strong></span>.</p><p>And second, the upstream is using IPv6, which may break some scripts if they search for the TCP port number after the first colon.</p><p>We want to show you another special kind of <span class="strong"><strong>file not found</strong></span> errors that are a sign of modern times:</p><div class="informalexample"><pre class="programlisting">2016/01/24 18:28:09 [error] 39111#0: *755667 open() "/site/example.com/www/wp-login.php" failed (2: No such file or directory), client: 109.198.238.60, server: example.com, request: "GET /wp-login.php HTTP/1.1", host: "www.example.com"
2016/01/24 18:27:01 [error] 39111#0: *755651 open() "/site/example.com/www/administrator/index.php" failed (2: No such file or directory), client: 82.199.126.95, server: example.com, request: "GET /administrator/index.php HTTP/1.1", host: "example.com"</pre></div><p>These are only interesting because they come from bots that attempt to hack into your system. They are very persistent in trying some URLs that look like administration or login scripts and that never ever existed on your site.</p><p>It is too cheap for them to just try any host they see on the Internet without even having a database of unsuccessful attempts. They will come from thousands of different IP addresses many of which will look totally innocent because those are infected computers all over the world controlled centrally. They have become a norm already; you should not most of the time even bother with any countermeasures (unless of course you run some old installation of WordPress, and in this case, you are probably hacked already and earn money for these people by serving some porn ads to your users alongside your own content).</p><p>Here is an<a class="indexterm" id="id88"/> error that contains much less information:</p><div class="informalexample"><pre class="programlisting">2014/07/29 00:00:18 [info] 14238#0: *95951600 client 77.205.98.18 closed keepalive connection</pre></div><p>Can you guess why? Because, as we said a little bit earlier, errors happen all the time even when there is no request under processing. This is exactly the case: a client closed a connection that was left open after a successful request/response pair as a way to optimize the following requests. This is named KeepAlive. Nginx is happy to serve many requests in one connection consequently, but the client is free to close the connection at any time. Now you should understand why this information has <code class="literal">[info]</code> instead of <code class="literal">[error]</code>. Ideas about whether you should do anything about it are left as an exercise.</p><div class="informalexample"><pre class="programlisting">2014/07/29 00:02:11 [info] 14241#0: *95959742 client timed out (110: Connection timed out) while waiting for request, client: 62.90.94.31, server: 0.0.0.0:443</pre></div><p>A similar message not having any information about a request because it is actually an error of not being able to get the request before timeout.</p><div class="informalexample"><pre class="programlisting">2014/07/29 00:00:18 [info] 14238#0: *95951764 SSL_read() failed (SSL: error:14094412:SSL routines:SSL3_READ_BYTES:sslv3 alert bad certificate:SSL alert number 42) while waiting for request, client: 176.115.120.138, server: 0.0.0.0:443</pre></div><p>It is quite an enigmatic error message that you won't be able to do anything about. The SSL code is complex, and there are a lot of weird SSL implementations out there. Something went wrong. You should take note and either try to reproduce or wait for more of the same.</p><div class="informalexample"><pre class="programlisting">2014/07/29 00:02:24 [info] 14240#0: *95968051 client sent too long URI while reading client request line, client: 87.244.170.11, server: example.com, request: "GET /log_error?login=takoe&amp;error=&lt;some very-very long string&gt;</pre></div><p>We trimmed this one by hand because it took almost the whole screen. There is a limit on the total <a class="indexterm" id="id89"/>size of the request headers. It may be changed with the <code class="literal">large_client_header_buffers</code> directive. See <a class="ulink" href="http://nginx.org/en/docs/http/ngx_http_core_module.html#large_client_header_buffers">http://nginx.org/en/docs/http/ngx_http_core_module.html#large_client_header_buffers</a> for more information. This is definitely something that you may fix by increasing the configured value, but we would recommend against it and speak to your application developers team instead. It looks like they have chosen the wrong tool for their task here. Requests of such size should use the POST method instead of GET.</p><p>There is another error we wanted to show here as an example of what problems really big websites face sometimes:</p><div class="informalexample"><pre class="programlisting">2013/05/16 12:21:11 [crit] 21947#0: *31843937 open() "/usr/local/nginx/html/50x.html" failed (24: Too many open files), client: 88.2.3.44, server: example.com, request: "GET /file/images/background.jpg HTTP/1.1", upstream: "http://10.10.4.1:81//file/images/background.jpg", host: "example.com"</pre></div><p>You <a class="indexterm" id="id90"/>should be able to read and understand every single character of that message now. What exactly is <span class="strong"><strong>24: Too many open files</strong></span>? There is a limit on the number of files that any single process can hold open. Usually, the limit is really big. Run this command to see the limit your shell has:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong>% ulimit -Sn</strong></span>
</pre></div><p>Once you have your Nginx serving more files than that simultaneously, this error will appear in the error<a class="indexterm" id="id91"/> log. Nginx has a way of increasing the limit itself, see <a class="ulink" href="http://nginx.org/en/docs/ngx_core_module.html#worker_rlimit_nofile">http://nginx.org/en/docs/ngx_core_module.html#worker_rlimit_nofile</a>. Increasing the hard limits for all processes is OS-dependent. On Linux, you will need to add something like <code class="literal">fs.file-max = 50000</code> to your <code class="literal">/etc/sysctl.conf</code> and then run the following code:</p><div class="informalexample"><pre class="programlisting"><span class="strong"><strong>% sysctl -p</strong></span>
</pre></div><div class="note" style="" title="Note"><div class="inner"><h3 class="title"><a id="tip02"/>Tip</h3><p>
<span class="strong"><strong>Downloading the example code</strong></span>
</p><p>You can download the example code files for this book from your account at <a class="ulink" href="http://www.packtpub.com">http://www.packtpub.com</a>. If you purchased this book elsewhere, you can visit <a class="ulink" href="http://www.packtpub.com/support">http://www.packtpub.com/support</a>  and register to have the files e-mailed directly to you.</p><p>You can download the code files by following these steps:</p><p>1. Log in or register to our website using your e-mail address and password.</p><p>2. Hover the mouse pointer on the <span class="strong"><strong>SUPPORT</strong></span> tab at the top.</p><p>3. Click on <span class="strong"><strong>Code Downloads &amp; Errata</strong></span>.</p><p>4. Enter the name of the book in the <span class="strong"><strong>Search</strong></span> box.</p><p>5. Select the book for which you're looking to download the code files.</p><p>6. Choose from the drop-down menu where you purchased this book from.</p><p>7. Click on <span class="strong"><strong>Code Download</strong></span>.</p><p>Once the file is downloaded, please make sure that you unzip or extract the folder using the latest version of:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"> WinRAR/7-Zip for Windows</li><li class="listitem" style="list-style-type: disc"> Zipeg/iZip/UnRarX for Mac</li><li class="listitem" style="list-style-type: disc"> 7-Zip/PeaZip for Linux</li></ul></div></div></div></div></div></div>
<div class="section" title="Summary"><div class="titlepage"><div><div><h1 class="title"><a id="ch02lvl1sec14"/>Summary</h1></div></div></div><p>In this chapter, we refreshed our knowledge of how logging works in Nginx. There are two types of logs; one of them may be infinitely extended, whereas the other is hard to parse by scripts because it does not have enough structure.</p><p>We spent some time on special topics, such as log rotation and logging POST request bodies (with a small test stand that we created step by step in the chapter, no less).</p><p>We also analyzed several error records from some real error logs.</p><p>The next chapter will have more actual problems analyzed and troubleshot. We will present several cases of actual problems that people had with read Nginx installations and try to debug them from the ground up.</p></div></body></html>